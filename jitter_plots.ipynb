{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e25eb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from itertools import chain\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "results_path = os.path.normpath(os.path.join(notebook_dir, \"outputs\", \"results.csv\"))\n",
    "norms_path   = os.path.normpath(os.path.join(notebook_dir, \"data\", \"all_8bit_norms_with_dnf.csv\"))\n",
    "\n",
    "# Load CSVs\n",
    "results_df = pd.read_csv(results_path)\n",
    "norms_df   = pd.read_csv(norms_path, dtype={\"8bit_vector\": str})\n",
    "\n",
    "# --- Helpers to flatten ---\n",
    "def flatten_ebsn_to_str(ebsn):\n",
    "    # If it's a string, convert it\n",
    "    if isinstance(ebsn, str):\n",
    "        ebsn = ast.literal_eval(ebsn)\n",
    "\n",
    "    flat_list = list(chain.from_iterable(chain.from_iterable(ebsn)))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "def flatten_base_sn_to_str(base_sn):\n",
    "    if isinstance(base_sn, str):\n",
    "        base_sn = ast.literal_eval(base_sn)\n",
    "\n",
    "    return ''.join(str(int(b)) for b in chain.from_iterable(base_sn))\n",
    "\n",
    "def identify_base_norm(base_norm_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the base social norm (e.g. Image Scoring, Stern Judging, etc.)\n",
    "    from its 4-bit structure [[a,b], [c,d], ...] as stored in the dataframe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        norm = ast.literal_eval(base_norm_str)\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Flatten if nested\n",
    "    flat = [int(x) for pair in norm for x in pair]\n",
    "\n",
    "    mapping = {\n",
    "        (0, 0, 1, 1): \"Image Scoring\",\n",
    "        (1, 0, 0, 1): \"Stern Judging\",\n",
    "        (0, 0, 0, 1): \"Shunning\",\n",
    "        (1, 0, 1, 1): \"Simple Standing\",\n",
    "        (0, 0, 0, 0): \"All Bad\",\n",
    "        (1, 1, 1, 1): \"All Good\",\n",
    "    }\n",
    "\n",
    "    return mapping.get(tuple(flat), \"Unknown\")\n",
    "\n",
    "\n",
    "# Flatten columns in results\n",
    "results_df['8bit_vector'] = results_df['eb_social_norm'].apply(flatten_ebsn_to_str)\n",
    "results_df['4bit_orig']   = results_df['base_social_norm'].apply(eval).apply(flatten_base_sn_to_str)\n",
    "\n",
    "# Merge and include DNF columns\n",
    "merged_df = pd.merge(\n",
    "    results_df,\n",
    "    norms_df[[\"8bit_vector\", \n",
    "              \"Emotion_Leniency\", \"DNF\", \"DNF_literals\"]],\n",
    "    on=[\"8bit_vector\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure numeric\n",
    "merged_df[\"DNF_literals\"] = pd.to_numeric(merged_df[\"DNF_literals\"], errors=\"coerce\")\n",
    "merged_df[\"base_social_norm\"] = merged_df[\"base_social_norm\"].apply(identify_base_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a6dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>q</th>\n",
       "      <th>b</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>EmotionProfile.COMPETITIVE</th>\n",
       "      <th>EmotionProfile.COOPERATIVE</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Standing</td>\n",
       "      <td>[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>01010101</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple Standing</td>\n",
       "      <td>[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>01010101</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simple Standing</td>\n",
       "      <td>[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.14</td>\n",
       "      <td>01010101</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Simple Standing</td>\n",
       "      <td>[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>01010101</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Simple Standing</td>\n",
       "      <td>[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>01010101</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31275</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10000011</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(A &amp; R) | (~A &amp; ~E &amp; ~R)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31276</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>10000011</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(A &amp; R) | (~A &amp; ~E &amp; ~R)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31277</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>10000011</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(A &amp; R) | (~A &amp; ~E &amp; ~R)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31278</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10000011</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(A &amp; R) | (~A &amp; ~E &amp; ~R)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31279</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000011</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(A &amp; R) | (~A &amp; ~E &amp; ~R)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31280 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0      Simple Standing  [[(0, 1), (0, 1)], [(0, 1), (0, 1)]]  50   100  1.0   \n",
       "1      Simple Standing  [[(0, 1), (0, 1)], [(0, 1), (0, 1)]]  50   100  1.0   \n",
       "2      Simple Standing  [[(0, 1), (0, 1)], [(0, 1), (0, 1)]]  50   100  1.0   \n",
       "3      Simple Standing  [[(0, 1), (0, 1)], [(0, 1), (0, 1)]]  50   100  1.0   \n",
       "4      Simple Standing  [[(0, 1), (0, 1)], [(0, 1), (0, 1)]]  50   100  1.0   \n",
       "...                ...                                   ...  ..   ...  ...   \n",
       "31275    Stern Judging  [[(1, 0), (0, 0)], [(0, 0), (1, 1)]]  40   500  1.0   \n",
       "31276    Stern Judging  [[(1, 0), (0, 0)], [(0, 0), (1, 1)]]  40   500  1.0   \n",
       "31277    Stern Judging  [[(1, 0), (0, 0)], [(0, 0), (1, 1)]]  40   500  1.0   \n",
       "31278    Stern Judging  [[(1, 0), (0, 0)], [(0, 0), (1, 1)]]  40   500  1.0   \n",
       "31279    Stern Judging  [[(1, 0), (0, 0)], [(0, 0), (1, 1)]]  40   500  1.0   \n",
       "\n",
       "        chi   eps  alpha    q  b  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0      0.01  0.01    0.0  0.5  5  ...          0.00               0.080   \n",
       "1      0.01  0.01    0.0  0.5  5  ...          0.00               0.000   \n",
       "2      0.01  0.01    0.0  0.5  5  ...          0.14               0.000   \n",
       "3      0.01  0.01    0.0  0.5  5  ...          0.98               0.000   \n",
       "4      0.01  0.01    0.0  0.5  5  ...          0.98               0.020   \n",
       "...     ...   ...    ...  ... ..  ...           ...                 ...   \n",
       "31275  0.10  0.10    0.0  1.0  5  ...          0.00               0.000   \n",
       "31276  0.10  0.10    0.0  1.0  5  ...          0.85               0.000   \n",
       "31277  0.10  0.10    0.0  1.0  5  ...          0.00               0.925   \n",
       "31278  0.10  0.10    0.0  1.0  5  ...          0.00               0.950   \n",
       "31279  0.10  0.10    0.0  1.0  5  ...          1.00               0.000   \n",
       "\n",
       "       ALWAYS_DEFECT  EmotionProfile.COMPETITIVE  EmotionProfile.COOPERATIVE  \\\n",
       "0              0.900                        0.90                        0.10   \n",
       "1              1.000                        0.00                        1.00   \n",
       "2              0.860                        0.86                        0.14   \n",
       "3              0.020                        0.02                        0.98   \n",
       "4              0.000                        0.02                        0.98   \n",
       "...              ...                         ...                         ...   \n",
       "31275          0.975                        0.03                        0.97   \n",
       "31276          0.100                        0.15                        0.85   \n",
       "31277          0.000                        0.07                        0.93   \n",
       "31278          0.050                        0.05                        0.95   \n",
       "31279          0.000                        1.00                        0.00   \n",
       "\n",
       "       8bit_vector  4bit_orig  Emotion_Leniency                       DNF  \\\n",
       "0         01010101       1011              0.00                         E   \n",
       "1         01010101       1011              0.00                         E   \n",
       "2         01010101       1011              0.00                         E   \n",
       "3         01010101       1011              0.00                         E   \n",
       "4         01010101       1011              0.00                         E   \n",
       "...            ...        ...               ...                       ...   \n",
       "31275     10000011       1001              0.75  (A & R) | (~A & ~E & ~R)   \n",
       "31276     10000011       1001              0.75  (A & R) | (~A & ~E & ~R)   \n",
       "31277     10000011       1001              0.75  (A & R) | (~A & ~E & ~R)   \n",
       "31278     10000011       1001              0.75  (A & R) | (~A & ~E & ~R)   \n",
       "31279     10000011       1001              0.75  (A & R) | (~A & ~E & ~R)   \n",
       "\n",
       "       DNF_literals  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "31275             5  \n",
       "31276             5  \n",
       "31277             5  \n",
       "31278             5  \n",
       "31279             5  \n",
       "\n",
       "[31280 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44e587fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e117dd72e48a4019afc027b976d8f23c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e117dd72e48a4019afc027b976d8f23c.vega-embed details,\n",
       "  #altair-viz-e117dd72e48a4019afc027b976d8f23c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e117dd72e48a4019afc027b976d8f23c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e117dd72e48a4019afc027b976d8f23c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e117dd72e48a4019afc027b976d8f23c\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@6?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@6.1.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@7?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"6\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"6.1.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"7\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-1d31c370880fc70f2652b8724b2f7036\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.7, \"size\": 60}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"eb_social_norm\", \"title\": \"EB Norm\", \"type\": \"nominal\"}, {\"field\": \"average_cooperation\", \"format\": \".3f\", \"title\": \"Avg Coop\", \"type\": \"quantitative\"}, {\"field\": \"gamma_center\", \"title\": \"Gamma\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"gamma_center\", \"title\": \"Gamma Center\", \"type\": \"ordinal\"}, \"xOffset\": {\"field\": \"jitter\", \"scale\": {\"domain\": [-2, 2]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"average_cooperation\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Average Cooperation\", \"type\": \"quantitative\"}}, \"height\": 500, \"title\": \"EB-Extension Performance: Stern Judging\", \"transform\": [{\"calculate\": \"datum.gamma_center == 0 ? 0 : (random()-0.5)\", \"as\": \"jitter\"}], \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v6.1.0.json\", \"datasets\": {\"data-1d31c370880fc70f2652b8724b2f7036\": [{\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.2356836}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.7014321333333333}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.08362560000000001}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.46167986666666666}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.4366592}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.7172516}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.5951496000000001}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.7489558666666667}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.2033596}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6421737333333333}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(1, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.3272344}, {\"eb_social_norm\": \"[[(0, 0), (0, 0)], [(1, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.5918068000000001}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.08355039999999998}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.1832898}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.1765096}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5926734}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0833324}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6731598}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.099086}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.3301334}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.401944}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6516978}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.29729320000000004}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6752114}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.0938232}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6294372}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.188118}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5393408000000001}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0639624}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.1134052}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.33294359999999995}, {\"eb_social_norm\": \"[[(0, 0), (0, 1)], [(1, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.4864666}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0669372}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6091348979591836}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.10138583333333334}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6614755999999999}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0647656}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.1901818}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.1082588}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.502533}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.119648}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6350663999999999}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.062002800000000004}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.49624359999999995}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0634648}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0930348}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0638416}, {\"eb_social_norm\": \"[[(0, 0), (1, 0)], [(1, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.3507548}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.060896}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.530629}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0606688}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.1834942}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.121252}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.590644}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.061313200000000005}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.48359899999999995}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.061588000000000004}, {\"eb_social_norm\": \"[[(0, 0), (1, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.4904298}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6947044}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.8179972}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6096356}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.8551778333333334}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.3365568}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6617839999999999}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6885904}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.8783444155844156}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (1, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.11271708333333334}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (1, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.7098260000000001}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5441368}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.853103}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.2044332}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.7744504000000001}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(1, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.49749960000000004}, {\"eb_social_norm\": \"[[(0, 1), (0, 0)], [(1, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.8206286}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.42086640000000003}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5080974}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.5206184}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.770051}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.46635400000000005}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6149458}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.5718032000000001}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6580184}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.7872197826086957}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (1, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.223446}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (1, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.702228}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6185548}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.7694808000000001}, {\"eb_social_norm\": \"[[(0, 1), (0, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.6994688000000001}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.2451552}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.7209474}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0625704}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.7514292}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.31789439999999997}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.348775}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.5700064}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (1, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.0628484}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (1, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.657622}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.134366}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6501192}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.0639216}, {\"eb_social_norm\": \"[[(0, 1), (1, 0)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.7622094}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.27947479999999997}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.3269962}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.2298708}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6252662}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.0811688}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.7253314000000001}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.24891200000000002}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6385806}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.3712084}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6900069999999999}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (1, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.11164199999999999}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (1, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.5730474}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.25816}, {\"eb_social_norm\": \"[[(0, 1), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6538035999999999}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.2614424}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6631978}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.522072}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.827375}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0649136}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5692764}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.2483616}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.6962721999999999}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5828196}, {\"eb_social_norm\": \"[[(1, 0), (0, 0)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.7932598}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.2556372}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.250446}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.1360932}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.5003846}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.06268080000000001}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.7016722}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.0650956}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.3953548}, {\"eb_social_norm\": \"[[(1, 0), (0, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.7165935999999999}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.20020319999999997}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.5333482}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.3071244}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.646419}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.1167428}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"average_cooperation\": 0.2256328}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.19606200000000001}, {\"eb_social_norm\": \"[[(1, 0), (1, 0)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"average_cooperation\": 0.34711259999999994}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.24218879999999998}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.35519080000000003}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.122102}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5166458}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.08635440000000001}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 0), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6659242000000001}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.0830204}, {\"eb_social_norm\": \"[[(1, 0), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.3050598}, {\"eb_social_norm\": \"[[(1, 1), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6933163999999999}, {\"eb_social_norm\": \"[[(1, 1), (0, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.7843812121212121}, {\"eb_social_norm\": \"[[(1, 1), (0, 0)], [(0, 0), (1, 1)]]\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 1.0, \"average_cooperation\": 0.9155159999999999}, {\"eb_social_norm\": \"[[(1, 1), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6036532}, {\"eb_social_norm\": \"[[(1, 1), (0, 1)], [(0, 0), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.686225}, {\"eb_social_norm\": \"[[(1, 1), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6251323999999999}, {\"eb_social_norm\": \"[[(1, 1), (0, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.8461828}, {\"eb_social_norm\": \"[[(1, 1), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.5668567999999999}, {\"eb_social_norm\": \"[[(1, 1), (1, 0)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.8132670000000001}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.550956}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.77131}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.5726596}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (0, 0)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6166316}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.43545320000000004}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.703652}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.3116628}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(0, 1), (1, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.6838644897959184}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.1707544}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(1, 0), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"average_cooperation\": 0.6562048}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(1, 1), (0, 1)]]\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.1012544}, {\"eb_social_norm\": \"[[(1, 1), (1, 1)], [(1, 1), (0, 1)]]\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"average_cooperation\": 0.4371192}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_norms = [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 1, 1, 0, 1, 1], [0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1], [0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 1, 1, 0, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0], [0, 0, 1, 1, 0, 1, 0, 1], [0, 0, 1, 1, 0, 1, 1, 1], [0, 0, 1, 1, 1, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 1], [0, 1, 0, 0, 0, 1, 1, 0], [0, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 0, 1, 0, 1], [0, 1, 0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 0, 1, 1, 1], [0, 1, 0, 1, 1, 0, 0, 1], [0, 1, 1, 0, 0, 0, 0, 1], [0, 1, 1, 0, 0, 0, 1, 1], [0, 1, 1, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 1, 0, 1], [0, 1, 1, 0, 0, 1, 1, 0], [0, 1, 1, 0, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1], [0, 1, 1, 1, 0, 0, 1, 1], [0, 1, 1, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 1, 1, 1], [1, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1], [1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 0, 0, 0, 1], [1, 0, 1, 0, 0, 0, 1, 1], [1, 0, 1, 0, 0, 1, 0, 0], [1, 0, 1, 1, 0, 0, 0, 0], [1, 0, 1, 1, 0, 0, 0, 1], [1, 0, 1, 1, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 1], [1, 1, 0, 1, 0, 0, 0, 0], [1, 1, 0, 1, 0, 0, 0, 1], [1, 1, 1, 1, 0, 0, 0, 1], [1, 1, 1, 1, 0, 1, 0, 0], [1, 1, 1, 1, 0, 1, 0, 1], [1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 0, 1], [0, 0, 1, 0, 1, 1, 0, 1], [0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 0, 1, 0, 0, 1], [1, 0, 0, 0, 0, 1, 1, 1], [1, 0, 1, 0, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 1]]\n",
    "# 1. Convert unique_norms from list of ints to list of strings\n",
    "unique_norms_str = [\"\".join(map(str, norm)) for norm in unique_norms]\n",
    "# --- 1. Filter and Aggregate ---\n",
    "\n",
    "# Filter for the target gamma values\n",
    "target_gammas = [0, 0.5, 1]\n",
    "filtered_df = merged_df[merged_df['gamma_center'].isin(target_gammas)].copy()\n",
    "filtered_df = filtered_df[filtered_df.Z==40]\n",
    "filtered_df = filtered_df[filtered_df.q==1]\n",
    "filtered_df = filtered_df[\n",
    "    (filtered_df['Emotion_Leniency'] != 1) | (filtered_df['gamma_center'] == 0)\n",
    "]\n",
    "# Normalize the cooperation ratio from [0, 100] to [0, 1]\n",
    "filtered_df['average_cooperation'] = filtered_df['average_cooperation'] / 100.0\n",
    "\n",
    "mask = (filtered_df[\"8bit_vector\"].isin(unique_norms_str)) | (filtered_df['gamma_center'] == 0)\n",
    "filtered_df = filtered_df[mask]\n",
    "# Select the base norm you want to visualize (e.g., \"Stern Judging\")\n",
    "# You can wrap this in a loop if you want plots for all norms\n",
    "target_base_norm = \"Stern Judging\" \n",
    "plot_data = filtered_df[filtered_df['base_social_norm'] == target_base_norm].copy()\n",
    "\n",
    "# Aggregate: Get the mean cooperation for each EB social norm per gamma_center\n",
    "# This averages across all simulation runs/replicates for that specific norm configuration\n",
    "agg_df = plot_data.groupby(['eb_social_norm', 'gamma_center', 'Emotion_Leniency']).agg({\n",
    "    'average_cooperation': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# --- 2. Create the Altair Jitter Plot ---\n",
    "jitter_chart = alt.Chart(agg_df).mark_circle(size=60, opacity=0.7).encode(\n",
    "    x=alt.X('gamma_center:O', \n",
    "            title='Gamma Center',\n",
    "            axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('average_cooperation:Q', \n",
    "            title='Average Cooperation',\n",
    "            scale=alt.Scale(domain=[0, 1])),\n",
    "    # The xOffset channel still pulls from our 'jitter' variable\n",
    "    xOffset=alt.XOffset('jitter:Q', scale=alt.Scale(domain=[-2, 2])),    \n",
    "    color=alt.Color('Emotion_Leniency:O'),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('eb_social_norm', title='EB Norm'),\n",
    "        alt.Tooltip('average_cooperation', title='Avg Coop', format='.3f'),\n",
    "        alt.Tooltip('gamma_center', title='Gamma')\n",
    "    ]\n",
    ").transform_calculate(\n",
    "    # Logic: if gamma_center is 0, jitter is 0. Else, random jitter.\n",
    "    # 'datum.gamma_center' refers to the value in the current row.\n",
    "    jitter='datum.gamma_center == 0 ? 0 : (random()-0.5)'\n",
    ").properties(\n",
    "    title=f\"EB-Extension Performance: {target_base_norm}\",\n",
    "    width=400,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "jitter_chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63460b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>gamma_center</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>average_cooperation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[(0, 0), (0, 0)], [(0, 0), (0, 1)]]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.235684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[(0, 0), (0, 0)], [(0, 0), (0, 1)]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.701432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[(0, 0), (0, 0)], [(0, 1), (0, 0)]]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.083626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[(0, 0), (0, 0)], [(0, 1), (0, 0)]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.461680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[(0, 0), (0, 0)], [(0, 1), (0, 1)]]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.436659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[[(1, 1), (1, 1)], [(0, 1), (1, 1)]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.683864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 0), (0, 1)]]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.170754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 0), (0, 1)]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.656205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (0, 1)]]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.101254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (0, 1)]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.437119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eb_social_norm  gamma_center  Emotion_Leniency  \\\n",
       "0    [[(0, 0), (0, 0)], [(0, 0), (0, 1)]]           0.5              0.75   \n",
       "1    [[(0, 0), (0, 0)], [(0, 0), (0, 1)]]           1.0              0.75   \n",
       "2    [[(0, 0), (0, 0)], [(0, 1), (0, 0)]]           0.5              0.75   \n",
       "3    [[(0, 0), (0, 0)], [(0, 1), (0, 0)]]           1.0              0.75   \n",
       "4    [[(0, 0), (0, 0)], [(0, 1), (0, 1)]]           0.5              0.50   \n",
       "..                                    ...           ...               ...   \n",
       "166  [[(1, 1), (1, 1)], [(0, 1), (1, 1)]]           1.0              0.75   \n",
       "167  [[(1, 1), (1, 1)], [(1, 0), (0, 1)]]           0.5              0.50   \n",
       "168  [[(1, 1), (1, 1)], [(1, 0), (0, 1)]]           1.0              0.50   \n",
       "169  [[(1, 1), (1, 1)], [(1, 1), (0, 1)]]           0.5              0.75   \n",
       "170  [[(1, 1), (1, 1)], [(1, 1), (0, 1)]]           1.0              0.75   \n",
       "\n",
       "     average_cooperation  \n",
       "0               0.235684  \n",
       "1               0.701432  \n",
       "2               0.083626  \n",
       "3               0.461680  \n",
       "4               0.436659  \n",
       "..                   ...  \n",
       "166             0.683864  \n",
       "167             0.170754  \n",
       "168             0.656205  \n",
       "169             0.101254  \n",
       "170             0.437119  \n",
       "\n",
       "[171 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e814e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 high-performing EB-norms.\n"
     ]
    }
   ],
   "source": [
    "unique_norms = [[0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 1], [0, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 0, 0], [0, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 1, 0, 1, 1, 1], [0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 1, 1, 0, 1, 1], [0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 1, 1, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 1, 1], [0, 0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 1], [0, 0, 1, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 1, 1, 0, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0], [0, 0, 1, 1, 0, 1, 0, 1], [0, 0, 1, 1, 0, 1, 1, 1], [0, 0, 1, 1, 1, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 1], [0, 1, 0, 0, 0, 1, 1, 0], [0, 1, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 0], [0, 1, 0, 1, 0, 0, 0, 1], [0, 1, 0, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 0], [0, 1, 0, 1, 0, 1, 0, 1], [0, 1, 0, 1, 0, 1, 1, 0], [0, 1, 0, 1, 0, 1, 1, 1], [0, 1, 0, 1, 1, 0, 0, 1], [0, 1, 1, 0, 0, 0, 0, 1], [0, 1, 1, 0, 0, 0, 1, 1], [0, 1, 1, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 1, 0, 1], [0, 1, 1, 0, 0, 1, 1, 0], [0, 1, 1, 0, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1], [0, 1, 1, 1, 0, 0, 1, 1], [0, 1, 1, 1, 0, 1, 0, 0], [0, 1, 1, 1, 0, 1, 0, 1], [0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 1, 1, 1], [1, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 1, 0, 1], [1, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 0, 1], [1, 0, 0, 1, 0, 0, 1, 1], [1, 0, 0, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 1, 0, 0, 0, 0, 1], [1, 0, 1, 0, 0, 0, 1, 1], [1, 0, 1, 0, 0, 1, 0, 0], [1, 0, 1, 1, 0, 0, 0, 0], [1, 0, 1, 1, 0, 0, 0, 1], [1, 0, 1, 1, 0, 0, 1, 1], [1, 1, 0, 0, 0, 0, 0, 1], [1, 1, 0, 1, 0, 0, 0, 0], [1, 1, 0, 1, 0, 0, 0, 1], [1, 1, 1, 1, 0, 0, 0, 1], [1, 1, 1, 1, 0, 1, 0, 0], [1, 1, 1, 1, 0, 1, 0, 1], [1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 0, 0, 1], [1, 1, 1, 1, 1, 1, 0, 1], [0, 0, 1, 0, 1, 1, 0, 1], [0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 0, 1, 0, 0, 1], [1, 0, 0, 0, 0, 1, 1, 1], [1, 0, 1, 0, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 0, 0], [1, 1, 1, 0, 0, 0, 0, 1]]\n",
    "# 1. Convert unique_norms from list of ints to list of strings\n",
    "unique_norms_str = [\"\".join(map(str, norm)) for norm in unique_norms]\n",
    "\n",
    "def flatten_ebsn_to_str(ebsn):\n",
    "    # If it's a string, convert it\n",
    "    if isinstance(ebsn, str):\n",
    "        ebsn = ast.literal_eval(ebsn)\n",
    "\n",
    "    flat_list = list(chain.from_iterable(chain.from_iterable(ebsn)))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "\n",
    "def get_high_performing_norms(df, base_norm_name, gamma, threshold=80):\n",
    "    # Filter for base norm and gamma\n",
    "    subset = df[\n",
    "        (df['base_social_norm'] == base_norm_name) & \n",
    "        (df['gamma_center'] == gamma) &\n",
    "        (df.Z == 40) &\n",
    "        (df.q == 1) &\n",
    "        (df['Emotion_Leniency'] != 1)\n",
    "    ].copy()\n",
    "\n",
    "    # 2. Use .isin() to filter for your specific unique norms\n",
    "    # We use the '8bit_vector' column you already created in your main script\n",
    "    subset = subset[subset['8bit_vector'].isin(unique_norms_str)]\n",
    "\n",
    "    # 3. Aggregate\n",
    "    top_norms = subset.groupby('8bit_vector').agg({\n",
    "        'average_cooperation': 'mean',\n",
    "        'ALWAYS_COOPERATE': 'mean',\n",
    "        'DISCRIMINATE': 'mean',\n",
    "        'PARADOXICALLY_DISC': 'mean',\n",
    "        'ALWAYS_DEFECT': 'mean',\n",
    "        'EmotionProfile.COMPETITIVE': 'mean',\n",
    "        'EmotionProfile.COOPERATIVE': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 4. Filter for threshold\n",
    "    high_perf_df = top_norms[top_norms['average_cooperation'] > threshold].copy()    \n",
    "    return high_perf_df.sort_values(by='average_cooperation', ascending=False)\n",
    "\n",
    "# Example usage:\n",
    "elites = get_high_performing_norms(merged_df, \"Stern Judging\", 1)\n",
    "print(f\"Found {len(elites)} high-performing EB-norms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d30ae8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>32</th>\n",
       "      <th>30</th>\n",
       "      <th>34</th>\n",
       "      <th>79</th>\n",
       "      <th>60</th>\n",
       "      <th>36</th>\n",
       "      <th>29</th>\n",
       "      <th>80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8bit_vector</th>\n",
       "      <td>01000101</td>\n",
       "      <td>01000011</td>\n",
       "      <td>01000111</td>\n",
       "      <td>11010001</td>\n",
       "      <td>10000011</td>\n",
       "      <td>01001011</td>\n",
       "      <td>01000001</td>\n",
       "      <td>11100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_cooperation</th>\n",
       "      <td>87.834442</td>\n",
       "      <td>85.517783</td>\n",
       "      <td>85.3103</td>\n",
       "      <td>84.61828</td>\n",
       "      <td>82.7375</td>\n",
       "      <td>82.06286</td>\n",
       "      <td>81.79972</td>\n",
       "      <td>81.3267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.81375</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.787917</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <td>0.324026</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.10125</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <td>0.02013</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmotionProfile.COMPETITIVE</th>\n",
       "      <td>0.347532</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.3748</td>\n",
       "      <td>0.4304</td>\n",
       "      <td>0.655667</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmotionProfile.COOPERATIVE</th>\n",
       "      <td>0.652468</td>\n",
       "      <td>0.728667</td>\n",
       "      <td>0.6246</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.343667</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.7154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   32         30        34        79  \\\n",
       "8bit_vector                  01000101   01000011  01000111  11010001   \n",
       "average_cooperation         87.834442  85.517783   85.3103  84.61828   \n",
       "ALWAYS_COOPERATE             0.012987   0.079167      0.07    0.0605   \n",
       "DISCRIMINATE                 0.642857    0.81375    0.6225    0.4925   \n",
       "PARADOXICALLY_DISC           0.324026   0.097917    0.2975    0.3995   \n",
       "ALWAYS_DEFECT                 0.02013   0.009167      0.01    0.0475   \n",
       "EmotionProfile.COMPETITIVE   0.347532      0.271    0.3748    0.4304   \n",
       "EmotionProfile.COOPERATIVE   0.652468   0.728667    0.6246      0.57   \n",
       "\n",
       "                                  60        36        29        80  \n",
       "8bit_vector                 10000011  01001011  01000001  11100001  \n",
       "average_cooperation          82.7375  82.06286  81.79972   81.3267  \n",
       "ALWAYS_COOPERATE            0.070833    0.1355    0.0215    0.1265  \n",
       "DISCRIMINATE                0.787917    0.5075      0.88     0.364  \n",
       "PARADOXICALLY_DISC           0.10125     0.309     0.046    0.4175  \n",
       "ALWAYS_DEFECT                   0.04     0.048    0.0525     0.092  \n",
       "EmotionProfile.COMPETITIVE  0.655667     0.225    0.1594     0.284  \n",
       "EmotionProfile.COOPERATIVE  0.343667    0.7738    0.8406    0.7154  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elites.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7164bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>average_cooperation</th>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>EmotionProfile.COMPETITIVE</th>\n",
       "      <th>EmotionProfile.COOPERATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>01100101</td>\n",
       "      <td>89.93276</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.9716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>01001001</td>\n",
       "      <td>87.71868</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>11100001</td>\n",
       "      <td>81.87484</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.8644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>11110001</td>\n",
       "      <td>81.04168</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>01100011</td>\n",
       "      <td>80.99944</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>01000111</td>\n",
       "      <td>80.47312</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.1716</td>\n",
       "      <td>0.8272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   8bit_vector  average_cooperation  ALWAYS_COOPERATE  DISCRIMINATE  \\\n",
       "48    01100101             89.93276             0.007         0.971   \n",
       "35    01001001             87.71868             0.017         0.931   \n",
       "80    11100001             81.87484             0.011         0.959   \n",
       "81    11110001             81.04168             0.018         0.869   \n",
       "46    01100011             80.99944             0.090         0.806   \n",
       "34    01000111             80.47312             0.124         0.788   \n",
       "\n",
       "    PARADOXICALLY_DISC  ALWAYS_DEFECT  EmotionProfile.COMPETITIVE  \\\n",
       "48               0.007          0.015                      0.0284   \n",
       "35               0.006          0.046                      0.0436   \n",
       "80               0.010          0.020                      0.1352   \n",
       "81               0.045          0.068                      0.1792   \n",
       "46               0.017          0.087                      0.1220   \n",
       "34               0.015          0.073                      0.1716   \n",
       "\n",
       "    EmotionProfile.COOPERATIVE  \n",
       "48                      0.9716  \n",
       "35                      0.9564  \n",
       "80                      0.8644  \n",
       "81                      0.8204  \n",
       "46                      0.8768  \n",
       "34                      0.8272  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "574025be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EB Norm Sample Audit (Gamma > 0) ---\n",
      "                        Sample_Sizes_Found  Number_of_Unique_Norms\n",
      "gamma_center                                                      \n",
      "0.5                               [25, 24]                      83\n",
      "1.0           [75, 50, 49, 77, 26, 25, 56]                      87\n",
      "\n",
      "Found 86 norms with inconsistent sample sizes (Expected 25):\n",
      "     gamma_center 8bit_vector  n_samples\n",
      "17            0.5    00100011         24\n",
      "33            0.5    01000110         24\n",
      "83            1.0    00000001         75\n",
      "84            1.0    00000100         75\n",
      "85            1.0    00000101         75\n",
      "..            ...         ...        ...\n",
      "165           1.0    11110100         50\n",
      "166           1.0    11110101         50\n",
      "167           1.0    11110111         49\n",
      "168           1.0    11111001         50\n",
      "169           1.0    11111101         50\n",
      "\n",
      "[86 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Apply specific filters for EB-extensions\n",
    "mask = (\n",
    "    (merged_df['gamma_center'] > 0) & \n",
    "    (merged_df['Z'] == 40) & \n",
    "    (merged_df['q'] == 1) &\n",
    "    (merged_df['Emotion_Leniency'] != 1) &\n",
    "    (merged_df['8bit_vector'].isin(unique_norms_str)) &\n",
    "    (merged_df['base_social_norm']==\"Stern Judging\")\n",
    ")\n",
    "\n",
    "eb_data = merged_df[mask].copy()\n",
    "\n",
    "# 2. Count runs per norm per gamma\n",
    "# We use 8bit_vector as the ID since it represents the unique extension\n",
    "counts = eb_data.groupby(['gamma_center', '8bit_vector']).size().reset_index(name='n_samples')\n",
    "\n",
    "# 3. Quick Check\n",
    "summary = counts.groupby('gamma_center')['n_samples'].agg(['unique', 'count']).rename(\n",
    "    columns={'unique': 'Sample_Sizes_Found', 'count': 'Number_of_Unique_Norms'}\n",
    ")\n",
    "\n",
    "print(\"--- EB Norm Sample Audit (Gamma > 0) ---\")\n",
    "print(summary)\n",
    "\n",
    "# Display any norms that don't match the most common sample size\n",
    "mode_size = counts['n_samples'].mode()[0]\n",
    "mismatched = counts[counts['n_samples'] != mode_size]\n",
    "\n",
    "if not mismatched.empty:\n",
    "    print(f\"\\nFound {len(mismatched)} norms with inconsistent sample sizes (Expected {mode_size}):\")\n",
    "    print(mismatched)\n",
    "else:\n",
    "    print(f\"\\nAll {len(counts)} norm configurations have exactly {mode_size} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df563aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
