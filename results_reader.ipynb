{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e41aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from itertools import chain\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "results_path = os.path.normpath(os.path.join(notebook_dir, \"outputs\", \"updated_model_results.csv\"))\n",
    "norms_path   = os.path.normpath(os.path.join(notebook_dir, \"data\", \"all_8bit_norms_with_dnf.csv\"))\n",
    "\n",
    "# Load CSVs\n",
    "results_df = pd.read_csv(results_path)\n",
    "norms_df   = pd.read_csv(norms_path, dtype={\"8bit_vector\": str})\n",
    "\n",
    "# --- Helpers to flatten ---\n",
    "def flatten_ebsn_to_str(ebsn):\n",
    "    # If it's a string, convert it\n",
    "    if isinstance(ebsn, str):\n",
    "        ebsn = ast.literal_eval(ebsn)\n",
    "\n",
    "    flat_list = list(chain.from_iterable(chain.from_iterable(ebsn)))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "def flatten_base_sn_to_str(base_sn):\n",
    "    if isinstance(base_sn, str):\n",
    "        base_sn = ast.literal_eval(base_sn)\n",
    "\n",
    "    return ''.join(str(int(b)) for b in chain.from_iterable(base_sn))\n",
    "\n",
    "def identify_base_norm(base_norm_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the base social norm (e.g. Image Scoring, Stern Judging, etc.)\n",
    "    from its 4-bit structure [[a,b], [c,d], ...] as stored in the dataframe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        norm = ast.literal_eval(base_norm_str)\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Flatten if nested\n",
    "    flat = [int(x) for pair in norm for x in pair]\n",
    "\n",
    "    mapping = {\n",
    "        (0, 0, 1, 1): \"Image Scoring\",\n",
    "        (1, 0, 0, 1): \"Stern Judging\",\n",
    "        (0, 0, 0, 1): \"Shunning\",\n",
    "        (1, 0, 1, 1): \"Simple Standing\",\n",
    "        (0, 0, 0, 0): \"All Bad\",\n",
    "        (1, 1, 1, 1): \"All Good\",\n",
    "    }\n",
    "\n",
    "    return mapping.get(tuple(flat), \"Unknown\")\n",
    "\n",
    "\n",
    "# Flatten columns in results\n",
    "results_df['8bit_vector'] = results_df['eb_social_norm'].apply(flatten_ebsn_to_str)\n",
    "results_df['4bit_orig']   = results_df['base_social_norm'].apply(eval).apply(flatten_base_sn_to_str)\n",
    "\n",
    "# Merge and include DNF columns\n",
    "merged_df = pd.merge(\n",
    "    results_df,\n",
    "    norms_df[[\"8bit_vector\", \n",
    "              \"Emotion_Leniency\", \"DNF\", \"DNF_literals\"]],\n",
    "    on=[\"8bit_vector\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure numeric\n",
    "merged_df[\"DNF_literals\"] = pd.to_numeric(merged_df[\"DNF_literals\"], errors=\"coerce\")\n",
    "merged_df[\"base_social_norm\"] = merged_df[\"base_social_norm\"].apply(identify_base_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e07cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_center</th>\n",
       "      <th>average_cooperation</th>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.745</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.206</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.674</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.837</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60581</th>\n",
       "      <td>[[0, 0], [0, 0]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.532</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60582</th>\n",
       "      <td>[[0, 0], [0, 0]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.315</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60583</th>\n",
       "      <td>[[0, 0], [0, 0]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.302</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60584</th>\n",
       "      <td>[[0, 0], [0, 0]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>[[0, 0], [0, 0]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.649</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60586 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                 ...                                   ...  ..   ...  ...   \n",
       "60581  [[0, 0], [0, 0]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60582  [[0, 0], [0, 0]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60583  [[0, 0], [0, 0]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60584  [[0, 0], [0, 0]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60585  [[0, 0], [0, 0]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  gamma_center  average_cooperation  \\\n",
       "0      0.01  0.01    0.0  5  1  ...           0.0               37.745   \n",
       "1      0.01  0.01    0.0  5  1  ...           0.0               36.042   \n",
       "2      0.01  0.01    0.0  5  1  ...           0.0               17.206   \n",
       "3      0.01  0.01    0.0  5  1  ...           0.0               34.674   \n",
       "4      0.01  0.01    0.0  5  1  ...           0.0               18.837   \n",
       "...     ...   ...    ... .. ..  ...           ...                  ...   \n",
       "60581  0.01  0.01    0.0  5  1  ...           1.0                4.532   \n",
       "60582  0.01  0.01    0.0  5  1  ...           1.0                4.315   \n",
       "60583  0.01  0.01    0.0  5  1  ...           1.0                4.302   \n",
       "60584  0.01  0.01    0.0  5  1  ...           1.0                4.062   \n",
       "60585  0.01  0.01    0.0  5  1  ...           1.0                4.649   \n",
       "\n",
       "       ALWAYS_COOPERATE  DISCRIMINATE  PARADOXICALLY_DISC  ALWAYS_DEFECT  \\\n",
       "0                0.0000        0.5333              0.1333         0.3333   \n",
       "1                0.0000        0.1333              0.1333         0.7333   \n",
       "2                0.0333        0.0000              0.0333         0.9333   \n",
       "3                0.3667        0.2333              0.0000         0.4000   \n",
       "4                0.0333        0.0333              0.0000         0.9333   \n",
       "...                 ...           ...                 ...            ...   \n",
       "60581            0.0000        0.0200              0.3400         0.6400   \n",
       "60582            0.0000        0.0200              0.3800         0.6000   \n",
       "60583            0.0200        0.0400              0.6200         0.3200   \n",
       "60584            0.0000        0.0200              0.9600         0.0200   \n",
       "60585            0.0000        0.0000              0.8600         0.1400   \n",
       "\n",
       "       Competitive  Cooperative  8bit_vector  4bit_orig  \n",
       "0             0.87         0.13     00011111       0011  \n",
       "1             0.73         0.27     00011111       0011  \n",
       "2             0.07         0.93     00011111       0011  \n",
       "3             0.60         0.40     00011111       0011  \n",
       "4             0.93         0.07     00011111       0011  \n",
       "...            ...          ...          ...        ...  \n",
       "60581         0.24         0.76     11111111       0000  \n",
       "60582         0.62         0.38     11111111       0000  \n",
       "60583         0.36         0.64     11111111       0000  \n",
       "60584         0.04         0.96     11111111       0000  \n",
       "60585         0.14         0.86     11111111       0000  \n",
       "\n",
       "[60586 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98672db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60581</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60582</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60583</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60584</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60586 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                ...                                   ...  ..   ...  ...   \n",
       "60581          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60582          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60583          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60584          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60585          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0      0.01  0.01    0.0  5  1  ...        0.5333              0.1333   \n",
       "1      0.01  0.01    0.0  5  1  ...        0.1333              0.1333   \n",
       "2      0.01  0.01    0.0  5  1  ...        0.0000              0.0333   \n",
       "3      0.01  0.01    0.0  5  1  ...        0.2333              0.0000   \n",
       "4      0.01  0.01    0.0  5  1  ...        0.0333              0.0000   \n",
       "...     ...   ...    ... .. ..  ...           ...                 ...   \n",
       "60581  0.01  0.01    0.0  5  1  ...        0.0200              0.3400   \n",
       "60582  0.01  0.01    0.0  5  1  ...        0.0200              0.3800   \n",
       "60583  0.01  0.01    0.0  5  1  ...        0.0400              0.6200   \n",
       "60584  0.01  0.01    0.0  5  1  ...        0.0200              0.9600   \n",
       "60585  0.01  0.01    0.0  5  1  ...        0.0000              0.8600   \n",
       "\n",
       "       ALWAYS_DEFECT  Competitive  Cooperative  8bit_vector  4bit_orig  \\\n",
       "0             0.3333         0.87         0.13     00011111       0011   \n",
       "1             0.7333         0.73         0.27     00011111       0011   \n",
       "2             0.9333         0.07         0.93     00011111       0011   \n",
       "3             0.4000         0.60         0.40     00011111       0011   \n",
       "4             0.9333         0.93         0.07     00011111       0011   \n",
       "...              ...          ...          ...          ...        ...   \n",
       "60581         0.6400         0.24         0.76     11111111       0000   \n",
       "60582         0.6000         0.62         0.38     11111111       0000   \n",
       "60583         0.3200         0.36         0.64     11111111       0000   \n",
       "60584         0.0200         0.04         0.96     11111111       0000   \n",
       "60585         0.1400         0.14         0.86     11111111       0000   \n",
       "\n",
       "       Emotion_Leniency          DNF  DNF_literals  \n",
       "0                  0.75  A | (E & R)             3  \n",
       "1                  0.75  A | (E & R)             3  \n",
       "2                  0.75  A | (E & R)             3  \n",
       "3                  0.75  A | (E & R)             3  \n",
       "4                  0.75  A | (E & R)             3  \n",
       "...                 ...          ...           ...  \n",
       "60581              1.00         True             0  \n",
       "60582              1.00         True             0  \n",
       "60583              1.00         True             0  \n",
       "60584              1.00         True             0  \n",
       "60585              1.00         True             0  \n",
       "\n",
       "[60586 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78830fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_social_norm  eb_social_norm                      \n",
      "[[0, 0], [0, 1]]  [[(0, 0), (0, 0)], [(0, 0), (0, 0)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (0, 1)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (1, 0)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (1, 1)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 1), (0, 0)]]    30\n",
      "                                                          ..\n",
      "[[1, 0], [1, 1]]  [[(1, 1), (1, 1)], [(1, 0), (1, 1)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (0, 0)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (0, 1)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (1, 0)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]    26\n",
      "Length: 987, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter only runs that originate from this base norm\n",
    "filtered = results_df[results_df.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == 0.8]\n",
    "\n",
    "# Average all runs per emergent norm\n",
    "grouped = filtered.groupby([\"base_social_norm\", \"eb_social_norm\"])\n",
    "\n",
    "print(grouped.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e930e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Emergent Norms: DNF Complexity vs Cooperation  \n",
    "This section selects a **base social norm** (e.g., Image Scoring, Stern Judging) and visualizes how all **emergent 8-bit norms** derived from it perform.\n",
    "\n",
    "For each emergent norm:\n",
    "- All simulation runs are grouped.\n",
    "- The **mean cooperation ratio** is computed.\n",
    "- The **DNF complexity** (number of literals in simplified DNF) is retrieved.\n",
    "\n",
    "The scatterplot shows:\n",
    "- **x-axis:** DNF complexity  \n",
    "- **y-axis:** mean cooperation  \n",
    "- **each point:** one emergent 8-bit social norm  \n",
    "\n",
    "This helps reveal which evolved norms are both **simple** and **highly cooperative** under a chosen base norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b16cbe48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-5cd5396bc69649d29f0ac2d453bf394f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-5cd5396bc69649d29f0ac2d453bf394f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-5cd5396bc69649d29f0ac2d453bf394f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"color\": \"orange\", \"opacity\": 0.5, \"size\": 2}, \"encoding\": {\"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}, \"transform\": [{\"on\": \"DNF_literals\", \"regression\": \"mean_coop\", \"method\": \"poly\"}]}, {\"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotion Leniency\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-aaf4b1be5eaf7020acda79487ac5ee23\"}, \"height\": 300, \"title\": \"Base Norm: All Bad; Gamma: 1, Social Norms (Top 10%) \\u2014 Poly Regression + Max-Per-DNF Line\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-aaf4b1be5eaf7020acda79487ac5ee23\": [{\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 70.64335}, {\"8bit_vector\": \"01011111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.77785}, {\"8bit_vector\": \"10101111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.78535}, {\"8bit_vector\": \"01010111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 63.5395}, {\"8bit_vector\": \"10101011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 61.533849999999994}, {\"8bit_vector\": \"11010101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 85.9595}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 91.64455000000001}, {\"8bit_vector\": \"10001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 84.3349}, {\"8bit_vector\": \"10001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 81.97659999999999}, {\"8bit_vector\": \"11000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.6937}, {\"8bit_vector\": \"11001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.7978}, {\"8bit_vector\": \"11010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.40805}, {\"8bit_vector\": \"11100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.69460000000001}, {\"8bit_vector\": \"01000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.31755000000001}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.9682}, {\"8bit_vector\": \"11010111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.16900000000001}, {\"8bit_vector\": \"11101011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.5837}, {\"8bit_vector\": \"01000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.08075}, {\"8bit_vector\": \"10000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.4598}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.596}, {\"8bit_vector\": \"11001011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 90.99275}, {\"8bit_vector\": \"11010011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.0084}, {\"8bit_vector\": \"11100011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 85.4659}, {\"8bit_vector\": \"10101001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 58.547000000000004}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.18125}, {\"8bit_vector\": \"11001001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.9196}, {\"8bit_vector\": \"11010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.19865}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.70795000000001}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.99735}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"All Bad\"\n",
    "chosen_gamma = 1\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "filtered = filtered[filtered.Emotion_Leniency != 1]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0.9)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"DNF_literals\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"DNF_literals:Q\", title=\"DNF Complexity\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"Emotion_Leniency:N\", title=\"Emotion Leniency\"),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Polynomial regression (degree 2)\n",
    "poly_reg = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .transform_regression(\n",
    "        \"DNF_literals\",\n",
    "        \"mean_coop\",\n",
    "        method=\"poly\"\n",
    "    )\n",
    "    .mark_line(size=2, color=\"orange\", opacity=0.5)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\",\n",
    "        tooltip=[\"DNF_literals\", \"mean_coop\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (poly_reg + scatter)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Social Norms (Top 10%) â€” Poly Regression + Max-Per-DNF Line\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd12ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-33a552d69b9844db9e4189099398336c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-33a552d69b9844db9e4189099398336c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-33a552d69b9844db9e4189099398336c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-4b4d0b71d6636ecb340b9ca8bf124584\"}, \"mark\": {\"type\": \"line\", \"color\": \"gray\", \"opacity\": 0.8, \"point\": true, \"size\": 2}, \"encoding\": {\"tooltip\": [{\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-85146fdccc293e4dd0529def427bb570\"}, \"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotion Leniency\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}], \"height\": 300, \"title\": \"Base Norm: All Bad; Gamma: 1, Emotion Based Social Norms (All)\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4b4d0b71d6636ecb340b9ca8bf124584\": [{\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 70.64335}, {\"8bit_vector\": \"10101111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.78535}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 91.64455000000001}, {\"8bit_vector\": \"11000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.6937}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.9682}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.596}, {\"8bit_vector\": \"11001001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.9196}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.70795000000001}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.99735}], \"data-85146fdccc293e4dd0529def427bb570\": [{\"8bit_vector\": \"00000001\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.27225}, {\"8bit_vector\": \"00000010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.137}, {\"8bit_vector\": \"00000100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 8.64985}, {\"8bit_vector\": \"00000101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.3732}, {\"8bit_vector\": \"00000110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 14.1654}, {\"8bit_vector\": \"00000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 33.09665}, {\"8bit_vector\": \"00001000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 9.49045}, {\"8bit_vector\": \"00001001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 16.8412}, {\"8bit_vector\": \"00001010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 23.45515}, {\"8bit_vector\": \"00001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 36.27635}, {\"8bit_vector\": \"00001101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 17.813049999999997}, {\"8bit_vector\": \"00001110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 20.35975}, {\"8bit_vector\": \"00010000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1252}, {\"8bit_vector\": \"00010001\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.21785}, {\"8bit_vector\": \"00010010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.18285}, {\"8bit_vector\": \"00010011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.12035}, {\"8bit_vector\": \"00010100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.9529}, {\"8bit_vector\": \"00010101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 10.2182}, {\"8bit_vector\": \"00010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 6.063899999999999}, {\"8bit_vector\": \"00010111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.82825}, {\"8bit_vector\": \"00011000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.70685}, {\"8bit_vector\": \"00011001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.38915}, {\"8bit_vector\": \"00011010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.46955}, {\"8bit_vector\": \"00011011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.9386}, {\"8bit_vector\": \"00011100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.2472}, {\"8bit_vector\": \"00011101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.9548000000000005}, {\"8bit_vector\": \"00011110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.97905}, {\"8bit_vector\": \"00011111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.4596}, {\"8bit_vector\": \"00100000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.13305}, {\"8bit_vector\": \"00100001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.1637}, {\"8bit_vector\": \"00100010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.2446}, {\"8bit_vector\": \"00100011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1552999999999995}, {\"8bit_vector\": \"00100100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.1114}, {\"8bit_vector\": \"00100101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.54925}, {\"8bit_vector\": \"00100110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.468500000000001}, {\"8bit_vector\": \"00100111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.1149000000000004}, {\"8bit_vector\": \"00101000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.072}, {\"8bit_vector\": \"00101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.987299999999999}, {\"8bit_vector\": \"00101010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 9.6156}, {\"8bit_vector\": \"00101011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.55615}, {\"8bit_vector\": \"00101100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.2783}, {\"8bit_vector\": \"00101101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.412000000000001}, {\"8bit_vector\": \"00101110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 8.5026}, {\"8bit_vector\": \"00101111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.281750000000001}, {\"8bit_vector\": \"00110001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1781500000000005}, {\"8bit_vector\": \"00110010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.137449999999999}, {\"8bit_vector\": \"00110100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.5185}, {\"8bit_vector\": \"00110101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.1791}, {\"8bit_vector\": \"00110110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.41675}, {\"8bit_vector\": \"00110111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1923}, {\"8bit_vector\": \"00111000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.47105}, {\"8bit_vector\": \"00111001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.40945}, {\"8bit_vector\": \"00111010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.142}, {\"8bit_vector\": \"00111011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.14215}, {\"8bit_vector\": \"00111101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.2837499999999995}, {\"8bit_vector\": \"00111110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.40505}, {\"8bit_vector\": \"01000000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 23.26645}, {\"8bit_vector\": \"01000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.08075}, {\"8bit_vector\": \"01000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 18.5397}, {\"8bit_vector\": \"01000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.31755000000001}, {\"8bit_vector\": \"01000100\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 29.6834}, {\"8bit_vector\": \"01000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.78045}, {\"8bit_vector\": \"01000110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 34.12815}, {\"8bit_vector\": \"01000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.6864}, {\"8bit_vector\": \"01001000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.1406}, {\"8bit_vector\": \"01001001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 64.8989}, {\"8bit_vector\": \"01001010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.55655}, {\"8bit_vector\": \"01001011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 43.927749999999996}, {\"8bit_vector\": \"01001100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.9786}, {\"8bit_vector\": \"01001101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 62.103649999999995}, {\"8bit_vector\": \"01001110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.07555}, {\"8bit_vector\": \"01001111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 33.00145}, {\"8bit_vector\": \"01010000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.15785}, {\"8bit_vector\": \"01010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 59.53875000000001}, {\"8bit_vector\": \"01010010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 42.324400000000004}, {\"8bit_vector\": \"01010011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 54.733349999999994}, {\"8bit_vector\": \"01010100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 49.5909}, {\"8bit_vector\": \"01010101\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 67.25795}, {\"8bit_vector\": \"01010110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 54.869299999999996}, {\"8bit_vector\": \"01010111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 63.5395}, {\"8bit_vector\": \"01011000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 25.6918}, {\"8bit_vector\": \"01011001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 57.71785}, {\"8bit_vector\": \"01011010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 25.4422}, {\"8bit_vector\": \"01011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 40.8304}, {\"8bit_vector\": \"01011100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 26.86795}, {\"8bit_vector\": \"01011101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 52.06665}, {\"8bit_vector\": \"01011110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 27.602800000000002}, {\"8bit_vector\": \"01011111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.77785}, {\"8bit_vector\": \"01100000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.97105}, {\"8bit_vector\": \"01100001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.0179}, {\"8bit_vector\": \"01100010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.10285}, {\"8bit_vector\": \"01100011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.89255}, {\"8bit_vector\": \"01100100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.0045}, {\"8bit_vector\": \"01100101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.9445}, {\"8bit_vector\": \"01100110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.98935}, {\"8bit_vector\": \"01100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.20655}, {\"8bit_vector\": \"01101000\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.811249999999999}, {\"8bit_vector\": \"01101001\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.90275}, {\"8bit_vector\": \"01101010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.92525}, {\"8bit_vector\": \"01101011\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.8502}, {\"8bit_vector\": \"01101100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.0119}, {\"8bit_vector\": \"01101101\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.866684210526316}, {\"8bit_vector\": \"01101110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.0346}, {\"8bit_vector\": \"01101111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.075950000000001}, {\"8bit_vector\": \"01110000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.4271}, {\"8bit_vector\": \"01110001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.525}, {\"8bit_vector\": \"01110010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.1522}, {\"8bit_vector\": \"01110011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.18085}, {\"8bit_vector\": \"01110100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.14565}, {\"8bit_vector\": \"01110101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 6.2738}, {\"8bit_vector\": \"01110110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.5795}, {\"8bit_vector\": \"01110111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.18935}, {\"8bit_vector\": \"01111000\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.7216499999999995}, {\"8bit_vector\": \"01111001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 6.611199999999999}, {\"8bit_vector\": \"01111010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.287599999999999}, {\"8bit_vector\": \"01111011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.21275}, {\"8bit_vector\": \"01111100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.16525}, {\"8bit_vector\": \"01111101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.8656999999999995}, {\"8bit_vector\": \"01111110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.2274}, {\"8bit_vector\": \"01111111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.28425}, {\"8bit_vector\": \"10000000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 26.0373}, {\"8bit_vector\": \"10000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 21.7533}, {\"8bit_vector\": \"10000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.4598}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.9682}, {\"8bit_vector\": \"10000100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.5575}, {\"8bit_vector\": \"10000101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.2856000000000005}, {\"8bit_vector\": \"10000110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 74.2359}, {\"8bit_vector\": \"10000111\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 30.849849999999996}, {\"8bit_vector\": \"10001000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 34.558}, {\"8bit_vector\": \"10001001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 40.40289473684211}, {\"8bit_vector\": \"10001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 84.3349}, {\"8bit_vector\": \"10001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 81.97659999999999}, {\"8bit_vector\": \"10001100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.3568}, {\"8bit_vector\": \"10001101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.0038}, {\"8bit_vector\": \"10001110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 66.4858}, {\"8bit_vector\": \"10001111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 25.0666}, {\"8bit_vector\": \"10010000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.9716499999999995}, {\"8bit_vector\": \"10010001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.22755}, {\"8bit_vector\": \"10010010\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.05775}, {\"8bit_vector\": \"10010011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.97105}, {\"8bit_vector\": \"10010100\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.8157499999999995}, {\"8bit_vector\": \"10010101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.98485}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.99735}, {\"8bit_vector\": \"10010111\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.96415}, {\"8bit_vector\": \"10011000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.9669}, {\"8bit_vector\": \"10011001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.99695}, {\"8bit_vector\": \"10011010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 4.98785}, {\"8bit_vector\": \"10011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.95385}, {\"8bit_vector\": \"10011100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.8950000000000005}, {\"8bit_vector\": \"10011101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.9601999999999995}, {\"8bit_vector\": \"10011110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 4.9074}, {\"8bit_vector\": \"10011111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.169}, {\"8bit_vector\": \"10100000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 40.73585}, {\"8bit_vector\": \"10100001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 40.1956}, {\"8bit_vector\": \"10100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 64.18365}, {\"8bit_vector\": \"10100011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 50.31485}, {\"8bit_vector\": \"10100100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 26.0434}, {\"8bit_vector\": \"10100101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 24.7933}, {\"8bit_vector\": \"10100110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 57.52135}, {\"8bit_vector\": \"10100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 44.5933}, {\"8bit_vector\": \"10101000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 52.9981}, {\"8bit_vector\": \"10101001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 58.547000000000004}, {\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 70.64335}, {\"8bit_vector\": \"10101011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 61.533849999999994}, {\"8bit_vector\": \"10101100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 26.96785}, {\"8bit_vector\": \"10101101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 26.8567}, {\"8bit_vector\": \"10101110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 57.35875}, {\"8bit_vector\": \"10101111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.78535}, {\"8bit_vector\": \"10110000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 7.257949999999999}, {\"8bit_vector\": \"10110001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.24355}, {\"8bit_vector\": \"10110010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.8184}, {\"8bit_vector\": \"10110011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1564499999999995}, {\"8bit_vector\": \"10110100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.1017}, {\"8bit_vector\": \"10110101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.5026}, {\"8bit_vector\": \"10110110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 6.8212}, {\"8bit_vector\": \"10110111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.228}, {\"8bit_vector\": \"10111000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.7269000000000005}, {\"8bit_vector\": \"10111001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.98355}, {\"8bit_vector\": \"10111010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.626949999999999}, {\"8bit_vector\": \"10111011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.12315}, {\"8bit_vector\": \"10111100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.0417499999999995}, {\"8bit_vector\": \"10111101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.2204999999999995}, {\"8bit_vector\": \"10111110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.02805}, {\"8bit_vector\": \"10111111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1539}, {\"8bit_vector\": \"11000001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 81.82265}, {\"8bit_vector\": \"11000010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 84.56705}, {\"8bit_vector\": \"11000100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 61.419399999999996}, {\"8bit_vector\": \"11000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.6937}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.18125}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.596}, {\"8bit_vector\": \"11001000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 67.46347368421053}, {\"8bit_vector\": \"11001001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.9196}, {\"8bit_vector\": \"11001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.7978}, {\"8bit_vector\": \"11001011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 90.99275}, {\"8bit_vector\": \"11001101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 50.249199999999995}, {\"8bit_vector\": \"11001110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 49.20755}, {\"8bit_vector\": \"11010000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 31.07145}, {\"8bit_vector\": \"11010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.40805}, {\"8bit_vector\": \"11010010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 46.07505}, {\"8bit_vector\": \"11010011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.0084}, {\"8bit_vector\": \"11010100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 70.52090000000001}, {\"8bit_vector\": \"11010101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 85.9595}, {\"8bit_vector\": \"11010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.19865}, {\"8bit_vector\": \"11010111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.16900000000001}, {\"8bit_vector\": \"11011000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.0202}, {\"8bit_vector\": \"11011001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 38.07645}, {\"8bit_vector\": \"11011010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.69895}, {\"8bit_vector\": \"11011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 23.883249999999997}, {\"8bit_vector\": \"11011100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.98105}, {\"8bit_vector\": \"11011101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 33.963}, {\"8bit_vector\": \"11011110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.11555}, {\"8bit_vector\": \"11011111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 24.14315}, {\"8bit_vector\": \"11100000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 22.3311}, {\"8bit_vector\": \"11100001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 37.69665}, {\"8bit_vector\": \"11100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.69460000000001}, {\"8bit_vector\": \"11100011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 85.4659}, {\"8bit_vector\": \"11100100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.09315}, {\"8bit_vector\": \"11100101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.15325}, {\"8bit_vector\": \"11100110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 44.4363}, {\"8bit_vector\": \"11100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 18.849449999999997}, {\"8bit_vector\": \"11101000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 44.13565}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.70795000000001}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 91.64455000000001}, {\"8bit_vector\": \"11101011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.5837}, {\"8bit_vector\": \"11101100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.01605}, {\"8bit_vector\": \"11101101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.9758000000000004}, {\"8bit_vector\": \"11101110\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 34.205349999999996}, {\"8bit_vector\": \"11101111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 23.418699999999998}, {\"8bit_vector\": \"11110001\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 34.5944}, {\"8bit_vector\": \"11110010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 32.50805}, {\"8bit_vector\": \"11110100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 23.51935}, {\"8bit_vector\": \"11110101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.02475}, {\"8bit_vector\": \"11110110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 15.087549999999998}, {\"8bit_vector\": \"11110111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.0965}, {\"8bit_vector\": \"11111000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 20.26695}, {\"8bit_vector\": \"11111001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 13.4887}, {\"8bit_vector\": \"11111010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.02035}, {\"8bit_vector\": \"11111011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.10935}, {\"8bit_vector\": \"11111101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 9.2167}, {\"8bit_vector\": \"11111110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 9.308499999999999}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"All Bad\"\n",
    "chosen_gamma = 1\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "filtered = filtered[filtered.Emotion_Leniency != 1]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"DNF_literals\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"DNF_literals:Q\", title=\"DNF Complexity\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"Emotion_Leniency:N\", title=\"Emotion Leniency\"),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\",\n",
    "        tooltip=[\"DNF_literals\", \"mean_coop\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (topline + scatter)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Emotion Based Social Norms (All)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1a14a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-282609278c35417899382aa2fdd45ca4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-282609278c35417899382aa2fdd45ca4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-282609278c35417899382aa2fdd45ca4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"data\": {\"name\": \"data-7c8c95f728c811302032e71711142a5d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"gamma\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"gamma\", \"type\": \"nominal\"}, {\"field\": \"ACR\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"ACR\", \"scale\": {\"domain\": [0, 100]}, \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Best EB Norms \\u2014 Base Norm: Image Scoring\", \"width\": 550}, {\"data\": {\"name\": \"data-d8678cc4cdfee534703571572f64bd4c\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"delta_ACR\", \"scale\": {\"scheme\": \"blueorange\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"delta_ACR\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"delta_ACR\", \"type\": \"quantitative\"}}, \"height\": 250, \"title\": \"\\u0394 ACR (0.8 \\u2212 0.2)\", \"width\": 550}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-7c8c95f728c811302032e71711142a5d\": [{\"DNF_literals\": 0, \"ACR\": 20.919900000000002, \"gamma\": \"0.2\"}, {\"DNF_literals\": 1, \"ACR\": 47.01755, \"gamma\": \"0.2\"}, {\"DNF_literals\": 2, \"ACR\": 48.26175, \"gamma\": \"0.2\"}, {\"DNF_literals\": 3, \"ACR\": 54.363800000000005, \"gamma\": \"0.2\"}, {\"DNF_literals\": 4, \"ACR\": 64.4995, \"gamma\": \"0.2\"}, {\"DNF_literals\": 5, \"ACR\": 62.628600000000006, \"gamma\": \"0.2\"}, {\"DNF_literals\": 6, \"ACR\": 64.023, \"gamma\": \"0.2\"}, {\"DNF_literals\": 7, \"ACR\": 64.3848, \"gamma\": \"0.2\"}, {\"DNF_literals\": 9, \"ACR\": 56.14755, \"gamma\": \"0.2\"}, {\"DNF_literals\": 12, \"ACR\": 59.12515, \"gamma\": \"0.2\"}, {\"DNF_literals\": 0, \"ACR\": 6.58075, \"gamma\": \"0.8\"}, {\"DNF_literals\": 1, \"ACR\": 71.21085000000001, \"gamma\": \"0.8\"}, {\"DNF_literals\": 2, \"ACR\": 55.6425, \"gamma\": \"0.8\"}, {\"DNF_literals\": 3, \"ACR\": 74.8804, \"gamma\": \"0.8\"}, {\"DNF_literals\": 4, \"ACR\": 83.0274, \"gamma\": \"0.8\"}, {\"DNF_literals\": 5, \"ACR\": 82.6409, \"gamma\": \"0.8\"}, {\"DNF_literals\": 6, \"ACR\": 84.1315, \"gamma\": \"0.8\"}, {\"DNF_literals\": 7, \"ACR\": 70.0976, \"gamma\": \"0.8\"}, {\"DNF_literals\": 9, \"ACR\": 65.8934, \"gamma\": \"0.8\"}, {\"DNF_literals\": 12, \"ACR\": 6.4475, \"gamma\": \"0.8\"}], \"data-d8678cc4cdfee534703571572f64bd4c\": [{\"DNF_literals\": 0, \"best_mean_coop_02\": 20.919900000000002, \"gamma_02\": 0.2, \"best_mean_coop_08\": 6.58075, \"gamma_08\": 0.8, \"delta_ACR\": -14.339150000000002}, {\"DNF_literals\": 1, \"best_mean_coop_02\": 47.01755, \"gamma_02\": 0.2, \"best_mean_coop_08\": 71.21085000000001, \"gamma_08\": 0.8, \"delta_ACR\": 24.193300000000008}, {\"DNF_literals\": 2, \"best_mean_coop_02\": 48.26175, \"gamma_02\": 0.2, \"best_mean_coop_08\": 55.6425, \"gamma_08\": 0.8, \"delta_ACR\": 7.380749999999999}, {\"DNF_literals\": 3, \"best_mean_coop_02\": 54.363800000000005, \"gamma_02\": 0.2, \"best_mean_coop_08\": 74.8804, \"gamma_08\": 0.8, \"delta_ACR\": 20.51659999999999}, {\"DNF_literals\": 4, \"best_mean_coop_02\": 64.4995, \"gamma_02\": 0.2, \"best_mean_coop_08\": 83.0274, \"gamma_08\": 0.8, \"delta_ACR\": 18.527900000000002}, {\"DNF_literals\": 5, \"best_mean_coop_02\": 62.628600000000006, \"gamma_02\": 0.2, \"best_mean_coop_08\": 82.6409, \"gamma_08\": 0.8, \"delta_ACR\": 20.012299999999996}, {\"DNF_literals\": 6, \"best_mean_coop_02\": 64.023, \"gamma_02\": 0.2, \"best_mean_coop_08\": 84.1315, \"gamma_08\": 0.8, \"delta_ACR\": 20.108500000000006}, {\"DNF_literals\": 7, \"best_mean_coop_02\": 64.3848, \"gamma_02\": 0.2, \"best_mean_coop_08\": 70.0976, \"gamma_08\": 0.8, \"delta_ACR\": 5.712800000000001}, {\"DNF_literals\": 9, \"best_mean_coop_02\": 56.14755, \"gamma_02\": 0.2, \"best_mean_coop_08\": 65.8934, \"gamma_08\": 0.8, \"delta_ACR\": 9.745849999999997}, {\"DNF_literals\": 12, \"best_mean_coop_02\": 59.12515, \"gamma_02\": 0.2, \"best_mean_coop_08\": 6.4475, \"gamma_08\": 0.8, \"delta_ACR\": -52.67765}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "chosen_base_norm = \"Image Scoring\"\n",
    "\n",
    "df = merged_df[\n",
    "    (merged_df[\"base_social_norm\"] == chosen_base_norm) &\n",
    "    (merged_df[\"gens\"] == 1000) & (merged_df.Z == 50)\n",
    "].copy()\n",
    "\n",
    "# Step 1 â€” Average across replicate runs for each emergent norm\n",
    "avg_runs = (\n",
    "    df.groupby([\"8bit_vector\", \"DNF_literals\", \"gamma_center\"], as_index=False)\n",
    "      .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# Step 2 â€” For each gamma, pick the highest-performing emergent norm per DNF literals\n",
    "def best_per_dnf_gamma(avg_df, gamma_value):\n",
    "    sub = avg_df[avg_df[\"gamma_center\"] == gamma_value]\n",
    "    if len(sub) == 0:\n",
    "        return pd.DataFrame(columns=[\"DNF_literals\", \"best_mean_coop\"])\n",
    "\n",
    "    best = (\n",
    "        sub.groupby(\"DNF_literals\", as_index=False)\n",
    "           .agg(best_mean_coop=(\"mean_coop\", \"max\"))\n",
    "    )\n",
    "    best[\"gamma\"] = gamma_value\n",
    "    return best\n",
    "\n",
    "best_02 = best_per_dnf_gamma(avg_runs, 0.2)\n",
    "best_08 = best_per_dnf_gamma(avg_runs, 0.8)\n",
    "\n",
    "merged_best = pd.merge(best_02, best_08, on=\"DNF_literals\", suffixes=(\"_02\",\"_08\"))\n",
    "merged_best[\"delta_ACR\"] = merged_best[\"best_mean_coop_08\"] - merged_best[\"best_mean_coop_02\"]\n",
    "\n",
    "# Plot the ACR curves\n",
    "long = pd.DataFrame({\n",
    "    \"DNF_literals\": list(merged_best[\"DNF_literals\"]) * 2,\n",
    "    \"ACR\": list(merged_best[\"best_mean_coop_02\"]) + list(merged_best[\"best_mean_coop_08\"]),\n",
    "    \"gamma\": [\"0.2\"] * len(merged_best) + [\"0.8\"] * len(merged_best),\n",
    "})\n",
    "\n",
    "line_chart = (\n",
    "    alt.Chart(long)\n",
    "    .mark_line(point=True)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=alt.Y(\"ACR:Q\", scale=alt.Scale(domain=[0,100])),\n",
    "        color=\"gamma:N\",\n",
    "        tooltip=[\"DNF_literals\",\"gamma\",\"ACR\"]\n",
    "    )\n",
    "    .properties(width=550, height=300,\n",
    "                title=f\"Best EB Norms â€” Base Norm: {chosen_base_norm}\")\n",
    ")\n",
    "\n",
    "delta_chart = (\n",
    "    alt.Chart(merged_best)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"delta_ACR:Q\",\n",
    "        color=alt.Color(\"delta_ACR:Q\", scale=alt.Scale(scheme=\"blueorange\")),\n",
    "        tooltip=[\"DNF_literals\",\"delta_ACR\"]\n",
    "    )\n",
    "    .properties(width=550, height=250, title=\"Î” ACR (0.8 âˆ’ 0.2)\")\n",
    ")\n",
    "\n",
    "(line_chart & delta_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d34c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60581</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60582</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60583</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60584</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60585</th>\n",
       "      <td>All Bad</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60586 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                ...                                   ...  ..   ...  ...   \n",
       "60581          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60582          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60583          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60584          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "60585          All Bad  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0      0.01  0.01    0.0  5  1  ...        0.5333              0.1333   \n",
       "1      0.01  0.01    0.0  5  1  ...        0.1333              0.1333   \n",
       "2      0.01  0.01    0.0  5  1  ...        0.0000              0.0333   \n",
       "3      0.01  0.01    0.0  5  1  ...        0.2333              0.0000   \n",
       "4      0.01  0.01    0.0  5  1  ...        0.0333              0.0000   \n",
       "...     ...   ...    ... .. ..  ...           ...                 ...   \n",
       "60581  0.01  0.01    0.0  5  1  ...        0.0200              0.3400   \n",
       "60582  0.01  0.01    0.0  5  1  ...        0.0200              0.3800   \n",
       "60583  0.01  0.01    0.0  5  1  ...        0.0400              0.6200   \n",
       "60584  0.01  0.01    0.0  5  1  ...        0.0200              0.9600   \n",
       "60585  0.01  0.01    0.0  5  1  ...        0.0000              0.8600   \n",
       "\n",
       "       ALWAYS_DEFECT  Competitive  Cooperative  8bit_vector  4bit_orig  \\\n",
       "0             0.3333         0.87         0.13     00011111       0011   \n",
       "1             0.7333         0.73         0.27     00011111       0011   \n",
       "2             0.9333         0.07         0.93     00011111       0011   \n",
       "3             0.4000         0.60         0.40     00011111       0011   \n",
       "4             0.9333         0.93         0.07     00011111       0011   \n",
       "...              ...          ...          ...          ...        ...   \n",
       "60581         0.6400         0.24         0.76     11111111       0000   \n",
       "60582         0.6000         0.62         0.38     11111111       0000   \n",
       "60583         0.3200         0.36         0.64     11111111       0000   \n",
       "60584         0.0200         0.04         0.96     11111111       0000   \n",
       "60585         0.1400         0.14         0.86     11111111       0000   \n",
       "\n",
       "       Emotion_Leniency          DNF  DNF_literals  \n",
       "0                  0.75  A | (E & R)             3  \n",
       "1                  0.75  A | (E & R)             3  \n",
       "2                  0.75  A | (E & R)             3  \n",
       "3                  0.75  A | (E & R)             3  \n",
       "4                  0.75  A | (E & R)             3  \n",
       "...                 ...          ...           ...  \n",
       "60581              1.00         True             0  \n",
       "60582              1.00         True             0  \n",
       "60583              1.00         True             0  \n",
       "60584              1.00         True             0  \n",
       "60585              1.00         True             0  \n",
       "\n",
       "[60586 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a93ca888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['base_social_norm', 'eb_social_norm', 'Z', 'gens', 'mu', 'chi', 'eps',\n",
       "       'alpha', 'b', 'c', 'beta', 'generations', 'convergence_period',\n",
       "       'gamma_min', 'gamma_max', 'gamma_delta', 'gamma_center',\n",
       "       'average_cooperation', 'ALWAYS_COOPERATE', 'DISCRIMINATE',\n",
       "       'PARADOXICALLY_DISC', 'ALWAYS_DEFECT', 'Competitive', 'Cooperative',\n",
       "       '8bit_vector', '4bit_orig', 'Emotion_Leniency', 'DNF', 'DNF_literals'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3300f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['B', 'G'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_78592\\2864536289.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m grouped = (\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mfiltered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"8bit_vector\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DNF_literals\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Emotion_Leniency\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             .agg(\n\u001b[0;32m     28\u001b[0m                 \u001b[0mmean_coop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average_cooperation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 869\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36magg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# we require a list, but not a 'str'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mselection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m         \u001b[0marg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_dictlike_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"agg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mnormalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m                 \u001b[0mcols_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Column(s) {cols_sorted} do not exist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mis_aggregator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['B', 'G'] do not exist\""
     ]
    }
   ],
   "source": [
    "# 1. Choose base norm (must match identify_base_norm output)\n",
    "chosen_base_norm = \"All Bad\"   # â† adjust as needed\n",
    "chosen_gamma = 1\n",
    "\n",
    "# Filter only runs that originate from this base norm\n",
    "filtered = merged_df[\n",
    "    (merged_df[\"base_social_norm\"] == chosen_base_norm) &\n",
    "    (merged_df[\"Z\"] == 50) &\n",
    "    (merged_df[\"gens\"] == 1000) &\n",
    "    (merged_df[\"gamma_center\"] == chosen_gamma) &\n",
    "    (merged_df[\"Emotion_Leniency\"] != 1.0)\n",
    "].copy()\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "# Include strategy + emotion columns in the aggregation\n",
    "strategy_cols = [\n",
    "    \"ALWAYS_COOPERATE\", \"DISCRIMINATE\", \n",
    "    \"PARADOXICALLY_DISC\", \"ALWAYS_DEFECT\"\n",
    "]\n",
    "\n",
    "emotion_cols = [\"Competitive\", \"Cooperative\"]\n",
    "\n",
    "rep_cols = [\"G\", \"B\"]\n",
    "\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(\n",
    "                mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "                **{col: (col, \"mean\") for col in strategy_cols + emotion_cols + rep_cols}\n",
    "            )\n",
    ")\n",
    "\n",
    "# 3. Elite norms\n",
    "elites = grouped[grouped.mean_coop >= 80].copy()\n",
    "\n",
    "elites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbec4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>DNF_literals</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>mean_coop</th>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.20245</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.27225</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000010</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.13700</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000011</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.13845</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.64985</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>11111011</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.10935</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>11111100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.81070</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>11111101</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.21670</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>11111110</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.30850</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>11111111</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.20020</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    8bit_vector  DNF_literals  Emotion_Leniency  mean_coop  ALWAYS_COOPERATE  \\\n",
       "0      00000000             0              1.00    4.20245             0.007   \n",
       "1      00000001             3              0.75    4.27225             0.010   \n",
       "2      00000010             3              0.75    4.13700             0.015   \n",
       "3      00000011             2              1.00    4.13845             0.015   \n",
       "4      00000100             3              0.75    8.64985             0.043   \n",
       "..          ...           ...               ...        ...               ...   \n",
       "251    11111011             3              0.75    4.10935             0.014   \n",
       "252    11111100             2              1.00    8.81070             0.019   \n",
       "253    11111101             3              0.75    9.21670             0.029   \n",
       "254    11111110             3              0.75    9.30850             0.025   \n",
       "255    11111111             0              1.00    4.20020             0.014   \n",
       "\n",
       "     DISCRIMINATE  PARADOXICALLY_DISC  ALWAYS_DEFECT  Competitive  Cooperative  \n",
       "0           0.460               0.012          0.521        0.466        0.534  \n",
       "1           0.348               0.015          0.627        0.456        0.544  \n",
       "2           0.326               0.018          0.641        0.565        0.435  \n",
       "3           0.628               0.017          0.340        0.507        0.493  \n",
       "4           0.132               0.044          0.781        0.556        0.444  \n",
       "..            ...                 ...            ...          ...          ...  \n",
       "251         0.011               0.400          0.575        0.438        0.562  \n",
       "252         0.033               0.071          0.877        0.515        0.485  \n",
       "253         0.033               0.105          0.833        0.365        0.635  \n",
       "254         0.035               0.151          0.789        0.561        0.439  \n",
       "255         0.016               0.495          0.475        0.527        0.473  \n",
       "\n",
       "[256 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bf182b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>71</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>195</th>\n",
       "      <th>197</th>\n",
       "      <th>203</th>\n",
       "      <th>209</th>\n",
       "      <th>211</th>\n",
       "      <th>215</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>235</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8bit_vector</th>\n",
       "      <td>01000111</td>\n",
       "      <td>10000010</td>\n",
       "      <td>10000011</td>\n",
       "      <td>11000011</td>\n",
       "      <td>11000101</td>\n",
       "      <td>11001011</td>\n",
       "      <td>11010001</td>\n",
       "      <td>11010011</td>\n",
       "      <td>11010111</td>\n",
       "      <td>11100010</td>\n",
       "      <td>11100011</td>\n",
       "      <td>11101011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNF_literals</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_coop</th>\n",
       "      <td>90.888167</td>\n",
       "      <td>90.62524</td>\n",
       "      <td>91.18442</td>\n",
       "      <td>92.85692</td>\n",
       "      <td>90.86758</td>\n",
       "      <td>91.65362</td>\n",
       "      <td>90.92048</td>\n",
       "      <td>92.79214</td>\n",
       "      <td>90.08924</td>\n",
       "      <td>90.73274</td>\n",
       "      <td>92.1519</td>\n",
       "      <td>91.28856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4392</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Competitive</th>\n",
       "      <td>0.137667</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cooperative</th>\n",
       "      <td>0.862333</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.7948</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          71        130       131       195       197  \\\n",
       "8bit_vector          01000111  10000010  10000011  11000011  11000101   \n",
       "DNF_literals                4         6         5         4         4   \n",
       "Emotion_Leniency          0.5       0.5      0.75       1.0       0.5   \n",
       "mean_coop           90.888167  90.62524  91.18442  92.85692  90.86758   \n",
       "ALWAYS_COOPERATE        0.082    0.0072     0.096    0.0708    0.0088   \n",
       "DISCRIMINATE            0.869    0.9604    0.8876    0.4816    0.5452   \n",
       "PARADOXICALLY_DISC   0.033333    0.0064    0.0068      0.44    0.4392   \n",
       "ALWAYS_DEFECT        0.015667     0.026    0.0096    0.0076    0.0068   \n",
       "Competitive          0.137667    0.9808     0.874    0.5216    0.4492   \n",
       "Cooperative          0.862333    0.0192     0.126    0.4784    0.5508   \n",
       "\n",
       "                         203       209       211       215       226  \\\n",
       "8bit_vector         11001011  11010001  11010011  11010111  11100010   \n",
       "DNF_literals               6         4         6         5         4   \n",
       "Emotion_Leniency        0.75       0.5      0.75       0.5       0.5   \n",
       "mean_coop           91.65362  90.92048  92.79214  90.08924  90.73274   \n",
       "ALWAYS_COOPERATE      0.0176     0.082    0.0888    0.0152     0.078   \n",
       "DISCRIMINATE          0.2088    0.0456     0.008    0.0068    0.1052   \n",
       "PARADOXICALLY_DISC    0.7632    0.8472    0.8932     0.972    0.7876   \n",
       "ALWAYS_DEFECT         0.0104    0.0252      0.01     0.006    0.0292   \n",
       "Competitive           0.2216      0.87     0.864     0.978    0.2052   \n",
       "Cooperative           0.7784      0.13     0.136     0.022    0.7948   \n",
       "\n",
       "                         227       235  \n",
       "8bit_vector         11100011  11101011  \n",
       "DNF_literals               6         5  \n",
       "Emotion_Leniency        0.75       0.5  \n",
       "mean_coop            92.1519  91.28856  \n",
       "ALWAYS_COOPERATE      0.1012      0.01  \n",
       "DISCRIMINATE          0.0068      0.01  \n",
       "PARADOXICALLY_DISC    0.8832    0.9728  \n",
       "ALWAYS_DEFECT         0.0088    0.0072  \n",
       "Competitive           0.1192     0.024  \n",
       "Cooperative           0.8808     0.976  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elites.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76dceab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_Good</th>\n",
       "      <th>freq_Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_Good  freq_Bad\n",
       "0   0.666667  0.333333\n",
       "1   1.000000  0.000000\n",
       "2   0.000000  1.000000\n",
       "3   0.000000  1.000000\n",
       "4   0.000000  1.000000\n",
       "5   0.333333  0.666667\n",
       "6   1.000000  0.000000\n",
       "7   1.000000  0.000000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the bitstrings into columns\n",
    "bits = elites[\"8bit_vector\"].apply(lambda s: pd.Series(list(s))).astype(int)\n",
    "#bits.columns = [\"DBm\", \"DBn\", \"DGm\", \"DGn\", \"CBm\", \"CBn\", \"CGm\", \"CGn\"]\n",
    "\n",
    "# Frequency of 1s and 0s at each position\n",
    "bit_summary = pd.DataFrame({\n",
    "    \"freq_Good\": bits.mean(),\n",
    "    \"freq_Bad\": 1 - bits.mean()\n",
    "})\n",
    "\n",
    "# Optional: merge back if you want combined dataframe\n",
    "df_bits = pd.concat([elites, bits], axis=1)\n",
    "\n",
    "bit_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7196a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed details,\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f20cc1b8c19293d054dbb83ccc577b72\"}, \"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"freq_1\", \"scale\": {\"scheme\": \"reds\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"bit\", \"type\": \"nominal\"}, {\"field\": \"freq_1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"bit\", \"title\": \"Bit Position\", \"type\": \"nominal\"}, \"y\": {\"field\": \"freq_1\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Frequency of 1\", \"type\": \"quantitative\"}}, \"title\": \"Bit Frequency of High-performing norms on base Image Scoring; \\u03b3=0.8\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-f20cc1b8c19293d054dbb83ccc577b72\": [{\"bit\": \"bit_0\", \"freq_1\": 0.6666666666666666}, {\"bit\": \"bit_1\", \"freq_1\": 1.0}, {\"bit\": \"bit_2\", \"freq_1\": 0.0}, {\"bit\": \"bit_3\", \"freq_1\": 0.0}, {\"bit\": \"bit_4\", \"freq_1\": 0.0}, {\"bit\": \"bit_5\", \"freq_1\": 0.3333333333333333}, {\"bit\": \"bit_6\", \"freq_1\": 1.0}, {\"bit\": \"bit_7\", \"freq_1\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split bitstrings\n",
    "bits = elites[\"8bit_vector\"].apply(lambda s: pd.Series(list(s))).astype(int)\n",
    "bits.columns = [f\"bit_{i}\" for i in range(8)]\n",
    "freq = bits.mean().reset_index()\n",
    "freq.columns = [\"bit\", \"freq_1\"]\n",
    "\n",
    "heat_freq = (\n",
    "    alt.Chart(freq)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X(\"bit:N\", title=\"Bit Position\"),\n",
    "        y=alt.Y(\"freq_1:Q\", scale=alt.Scale(domain=[0,1]), title=\"Frequency of 1\"),\n",
    "        color=alt.Color(\"freq_1:Q\", scale=alt.Scale(scheme=\"reds\")),\n",
    "        tooltip=[\"bit\", \"freq_1\"]\n",
    "    )\n",
    "    .properties(title=f\"Bit Frequency of High-performing norms on base {chosen_base_norm}; Î³={chosen_gamma}\")\n",
    ")\n",
    "\n",
    "heat_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dc92529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed details,\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-916d14c762ef44ebbcc67fe075cec528\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-916d14c762ef44ebbcc67fe075cec528\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-916d14c762ef44ebbcc67fe075cec528\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e9bded0633f9946d70a054b064ec1de6\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"corr_with_coop\", \"scale\": {\"scheme\": \"blueorange\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"bit\", \"type\": \"nominal\"}, {\"field\": \"corr_with_coop\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"bit\", \"title\": \"Bit Position\", \"type\": \"nominal\"}, \"y\": {\"field\": \"corr_with_coop\", \"title\": \"Correlation\", \"type\": \"quantitative\"}}, \"title\": \"Base norm: Stern Judging; Gamma: 0.8; Bit\\u2013Cooperation Correlation\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-e9bded0633f9946d70a054b064ec1de6\": [{\"bit\": \"bit_0\", \"corr_with_coop\": 0.31608142051631294}, {\"bit\": \"bit_1\", \"corr_with_coop\": 0.3118265701814451}, {\"bit\": \"bit_2\", \"corr_with_coop\": -0.3040889787619574}, {\"bit\": \"bit_3\", \"corr_with_coop\": -0.30832920766746386}, {\"bit\": \"bit_4\", \"corr_with_coop\": -0.15075530001873966}, {\"bit\": \"bit_5\", \"corr_with_coop\": -0.15305577257339434}, {\"bit\": \"bit_6\", \"corr_with_coop\": 0.15510988629537784}, {\"bit\": \"bit_7\", \"corr_with_coop\": 0.14869775421647233}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = bits.apply(lambda col: col.corr(elites[\"mean_coop\"])).reset_index()\n",
    "corr.columns = [\"bit\", \"corr_with_coop\"]\n",
    "\n",
    "heat_corr = (\n",
    "    alt.Chart(corr)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"bit:N\", title=\"Bit Position\"),\n",
    "        y=alt.Y(\"corr_with_coop:Q\", title=\"Correlation\"),\n",
    "        tooltip=[\"bit\",\"corr_with_coop\"],\n",
    "        color=alt.Color(\"corr_with_coop:Q\", scale=alt.Scale(scheme=\"blueorange\"))\n",
    "    )\n",
    "    .properties(title=f\"Base norm: {chosen_base_norm}; Gamma: {chosen_gamma}; Bitâ€“Cooperation Correlation\")\n",
    ")\n",
    "\n",
    "heat_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80b2cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed details,\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-4276d876a4661acb91e1af80f69dbf77\"}, \"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"DNF_literals\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotional Leniency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-7d53f7e111883533d95293259bd3bbd8\"}, \"mark\": {\"type\": \"line\", \"color\": \"gray\", \"opacity\": 0.8, \"point\": true, \"size\": 2}, \"encoding\": {\"x\": {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}}], \"height\": 300, \"title\": \"Base Norm: Shunning; Gamma: 0.8, Social Norms (Top 10%) \\u2014 Poly Regression + Max-Per-Leniency Line\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-4276d876a4661acb91e1af80f69dbf77\": [{\"8bit_vector\": \"01010101\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 74.25256666666668}, {\"8bit_vector\": \"10101010\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 68.48956666666666}, {\"8bit_vector\": \"01000101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 72.85103333333333}, {\"8bit_vector\": \"01001001\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 9, \"mean_coop\": 71.765}, {\"8bit_vector\": \"01010001\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 70.01486666666666}, {\"8bit_vector\": \"10001010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 71.3493}, {\"8bit_vector\": \"10100010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 75.31400000000001}, {\"8bit_vector\": \"11010101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.33036666666666}, {\"8bit_vector\": \"11101010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.137}, {\"8bit_vector\": \"01000001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 6, \"mean_coop\": 88.0087}, {\"8bit_vector\": \"01000111\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 77.18900000000001}, {\"8bit_vector\": \"10000010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 6, \"mean_coop\": 87.31146666666667}, {\"8bit_vector\": \"11000101\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 84.9773}, {\"8bit_vector\": \"11001001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 7, \"mean_coop\": 76.1965}, {\"8bit_vector\": \"11001010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 82.98060000000001}, {\"8bit_vector\": \"11010001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 89.2706}, {\"8bit_vector\": \"11010111\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 5, \"mean_coop\": 79.96673333333334}, {\"8bit_vector\": \"11100010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 90.38993333333333}, {\"8bit_vector\": \"11101011\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 5, \"mean_coop\": 85.71173333333333}, {\"8bit_vector\": \"01000011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 84.90473333333333}, {\"8bit_vector\": \"10000011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 87.79356666666666}, {\"8bit_vector\": \"11000010\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 91.69476666666667}, {\"8bit_vector\": \"11000111\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 87.41186666666665}, {\"8bit_vector\": \"11001011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 90.80446666666667}, {\"8bit_vector\": \"11010011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 92.1654}, {\"8bit_vector\": \"11100011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 85.38473333333333}, {\"8bit_vector\": \"11000011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 4, \"mean_coop\": 92.6014}, {\"8bit_vector\": \"11110011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 2, \"mean_coop\": 82.64323333333333}], \"data-7d53f7e111883533d95293259bd3bbd8\": [{\"8bit_vector\": \"01010101\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 74.25256666666668}, {\"8bit_vector\": \"11010101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.33036666666666}, {\"8bit_vector\": \"11100010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 90.38993333333333}, {\"8bit_vector\": \"11010011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 92.1654}, {\"8bit_vector\": \"11000011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 4, \"mean_coop\": 92.6014}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"Shunning\"\n",
    "chosen_gamma = 0.8\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"Emotion_Leniency\", \"DNF_literals\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0.9)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"Emotion_Leniency\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"Emotion_Leniency\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"Emotion_Leniency:Q\", title=\"Emotional Leniency\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"DNF_literals:Q\", title=\"DNF Complexity\",\n",
    "                        scale=alt.Scale(scheme=\"viridis\")),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Polynomial regression (degree 2)\n",
    "poly_reg = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .transform_regression(\n",
    "        \"Emotion_Leniency\",\n",
    "        \"mean_coop\",\n",
    "        method=\"poly\"\n",
    "    )\n",
    "    .mark_line(size=2, color=\"orange\", opacity=0.5)\n",
    "    .encode(\n",
    "        x=\"Emotion_Leniency:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"Emotion_Leniency:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (scatter + topline)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Social Norms (Top 10%) â€” Poly Regression + Max-Per-Leniency Line\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffe88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf733f9",
   "metadata": {},
   "source": [
    "## Multiple Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6c403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick norm\n",
    "chosen_norm = \"SternJudging\"\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "norm_df[\"is_base\"] = norm_df[\"variant_id\"].str.endswith(\"_v1\")\n",
    "\n",
    "# If your results use a different name (e.g., \"gamma_gaussian_n\"),\n",
    "# rename it once so plots are consistent:\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Aggregate per variant & gamma, carry DNF info (constant per variant)\n",
    "agg_df = (\n",
    "    norm_df\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\", \"gamma_center\", \"is_base\"], as_index=False)\n",
    "    .agg(\n",
    "        avg_coop=(\"average_cooperation\", \"mean\"),\n",
    "        std_coop=(\"average_cooperation\", \"std\"),\n",
    "        DNF=(\"DNF\", \"first\")\n",
    "    )\n",
    "    .sort_values([\"variant_id\", \"gamma_center\"])\n",
    ")\n",
    "\n",
    "# Make a percent-friendly copy\n",
    "plot_df = agg_df.copy()\n",
    "\n",
    "# If avg_coop is in [0,1], convert to %; if already 0â€“100, keep as-is\n",
    "def to_percent(col):\n",
    "    arr = col.to_numpy(dtype=float)\n",
    "    # heuristic: if most values â‰¤ 1, treat as proportions\n",
    "    needs_scale = (np.nanmean(arr <= 1.0) > 0.5)\n",
    "    return arr * 100.0 if needs_scale else arr\n",
    "\n",
    "plot_df[\"avg_coop_percent\"] = to_percent(plot_df[\"avg_coop\"])\n",
    "plot_df[\"std_coop_percent\"] = to_percent(plot_df[\"std_coop\"])\n",
    "\n",
    "# Base lines (no selections; color by DNF_literals; dashed if base)\n",
    "line = alt.Chart(plot_df).mark_line().encode(\n",
    "    x=alt.X(\"gamma_center:Q\", title=\"Gamma value\"),\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            title=\"Average Cooperation (%)\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    color=alt.Color(\"Emotion_Leniency:O\",\n",
    "                    title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"bluepurple\")),\n",
    "    strokeDash=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value([5, 5]),    # dashed for base\n",
    "        alt.value([1, 0])     # solid otherwise\n",
    "    ),\n",
    "    strokeWidth=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value(8),\n",
    "        alt.value(2)\n",
    "    ),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant\"),\n",
    "        alt.Tooltip(\"gamma_center:Q\", title=\"Gamma\"),\n",
    "        alt.Tooltip(\"avg_coop_percent:Q\", title=\"Mean coop (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"std_coop_percent:Q\", title=\"Std (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"is_base:N\", title=\"Base?\")\n",
    "    ],\n",
    "    detail=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "# Optional: end-of-line labels (still no interactivity)\n",
    "endpoints = (\n",
    "    plot_df.sort_values([\"variant_id\", \"gamma_center\"])\n",
    "           .groupby(\"variant_id\", as_index=False)\n",
    "           .tail(1)\n",
    ")\n",
    "\n",
    "labels = alt.Chart(endpoints).mark_text(\n",
    "    dx=5, align=\"left\", baseline=\"middle\"\n",
    ").encode(\n",
    "    x=\"gamma_center:Q\",\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    text=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "chart = (line + labels).properties(\n",
    "    width=700, height=420,\n",
    "    title=f\"Performance of {chosen_norm} Variants (color = Emotion Leniency; dashed = base)\"\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pivot: rows = variant_id, cols = gamma_center\n",
    "pivot_df = plot_df.pivot_table(\n",
    "    index=\"variant_id\",\n",
    "    columns=\"gamma_center\",\n",
    "    values=\"avg_coop_percent\",\n",
    "    aggfunc=\"mean\"   # though already averaged\n",
    ").reset_index()\n",
    "\n",
    "# Optional: rename gamma columns for clarity (e.g., \"gamma 0.0\")\n",
    "pivot_df = pivot_df.rename(\n",
    "    columns={g: f\"gamma {g}\" for g in pivot_df.columns if isinstance(g, (int, float))}\n",
    ")\n",
    "\n",
    "# Check result\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca4dca",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02112145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "chosen_norm = \"SternJudging\"\n",
    "\n",
    "# Filter to chosen norm\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Ensure consistent gamma column name\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# ---- STEP 1: average cooperation per variant (across runs) ----\n",
    "variant_avg = (\n",
    "    norm_df\n",
    "    .groupby([\"norm\", \"variant_id\", \"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# ---- STEP 2: for each (Î³, DNF_literals), take the variant with the highest average ----\n",
    "variant_avg_sorted = variant_avg.sort_values(\"mean_coop\", ascending=False)\n",
    "agg = (\n",
    "    variant_avg_sorted\n",
    "    .groupby([\"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(\n",
    "        max_mean_coop=(\"mean_coop\", \"max\"),\n",
    "        best_variant=(\"variant_id\", \"first\"),\n",
    "        n=(\"variant_id\", \"nunique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "agg[\"DNF_literals\"] = agg[\"DNF_literals\"].astype(int)\n",
    "\n",
    "# Convert to percentage if needed\n",
    "if agg[\"max_mean_coop\"].max() <= 1:\n",
    "    agg[\"max_mean_coop\"] *= 100\n",
    "\n",
    "# ---- STEP 3: Visualization ----\n",
    "heat = alt.Chart(agg).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\",\n",
    "            sort=[f\"{x:.1f}\" for x in valid_gammas]),\n",
    "    y=alt.Y(\"DNF_literals:O\", title=\"DNF literals\", sort=\"descending\"),\n",
    "    color=alt.Color(\"max_mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"DNF_literals:O\", title=\"# literals\"),\n",
    "        alt.Tooltip(\"max_mean_coop:Q\", title=\"max mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"best_variant:N\", title=\"Best variant ID\"),\n",
    "        alt.Tooltip(\"n:Q\", title=\"# variants in bin\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=450, height=350,\n",
    "    title=f\"{chosen_norm} â€” Max *Mean* Cooperation by Î³ Ã— DNF Complexity\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb43276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "#chosen_base_norm = \"SternJudging\"    # 0) choose base social norm\n",
    "fixed_gamma = 1                   # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# For a runnable example, let's assume merged_df is loaded here (e.g., from a CSV)\n",
    "# For the purpose of adding the regression, we'll proceed assuming 'merged_df' exists.\n",
    "#df = merged_df[merged_df[\"norm\"] == chosen_base_norm].copy()\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# ensure average_cooperation is numeric\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "          runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) For every DNF complexity, choose the variant with maximal mean cooperation ===\n",
    "# use idxmax to get the variant row with the highest mean_coop\n",
    "idx = variant_avg.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()\n",
    "best_per_complexity = variant_avg.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# Optional: sort by complexity numeric ascending\n",
    "best_per_complexity[\"DNF_literals\"] = best_per_complexity[\"DNF_literals\"].astype(int)\n",
    "best_per_complexity = best_per_complexity.sort_values(\"DNF_literals\")\n",
    "\n",
    "# === ASSUMED best_per_complexity DATA STRUCTURE FOR REGRESSION ===\n",
    "# best_per_complexity = pd.DataFrame({\n",
    "#     'DNF_literals': [1, 2, 3, 4, 5],\n",
    "#     'mean_coop_pct': [50.0, 65.0, 75.0, 70.0, 80.0],\n",
    "#     'Emotion_Leniency': [0.1, 0.2, 0.3, 0.2, 0.4],\n",
    "#     'variant_id': ['v1', 'v2', 'v3', 'v4', 'v5'],\n",
    "#     'runs': [10, 10, 10, 10, 10]\n",
    "# })\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (max among variants per complexity) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Max mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(best_per_complexity).mark_circle(size=120).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    color=alt.Color(\"Emotion_Leniency:O\", title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\")),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"Best variant per complexity at Î³ = {fixed_gamma}\"\n",
    ")\n",
    "\n",
    "# === 5) Add Regression Line (Linear) - CORRECTED ===\n",
    "# We use transform_regression() to calculate the line\n",
    "# and then mark_line() to draw it.\n",
    "regression_line = alt.Chart(best_per_complexity).transform_regression(\n",
    "    'DNF_literals',        # The X variable\n",
    "    'mean_coop_pct',       # The Y variable\n",
    "    method='quad'        # Specify method (linear, poly, etc.)\n",
    ").mark_line(\n",
    "    color='red',           # Style the line\n",
    "    strokeDash=[5, 5]      # Make it dashed\n",
    ").encode(\n",
    "    x=alt.X('DNF_literals:Q'),  # Re-encode X for the line layer\n",
    "    y=alt.Y('mean_coop_pct:Q')  # Re-encode Y for the line layer\n",
    ")\n",
    "\n",
    "# Add text labels (optional) next to points showing variant short name\n",
    "labels = alt.Chart(best_per_complexity).mark_text(dx=7, dy=0, align=\"left\").encode(\n",
    "    x=x_encoding,  # Use the quantitative encoding\n",
    "    y=y_encoding,  # Use the quantitative encoding\n",
    "    text=alt.Text(\"variant_id:N\"),\n",
    ")\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line + Labels ===\n",
    "chart_with_regression = (chart + regression_line + labels).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b296a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "# chosen_base_norm = \"SternJudging\"    # 0) No longer filtering by a single norm\n",
    "fixed_gamma = 0.8                      # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# We use the full merged_df, as requested.\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# We add \"norm\" to the groupby so we can distinguish them in the plot\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"norm\", \"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "         runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if not variant_avg.empty and variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) Use all averaged variants (no 'best of' filter) ===\n",
    "# We are SKIPPING the step of choosing the maximal per complexity.\n",
    "# We will plot all variants from variant_avg.\n",
    "\n",
    "# Optional: ensure DNF_literals is int and sort\n",
    "if not variant_avg.empty:\n",
    "    variant_avg[\"DNF_literals\"] = variant_avg[\"DNF_literals\"].astype(int)\n",
    "    variant_avg = variant_avg.sort_values(\"DNF_literals\")\n",
    "else:\n",
    "    print(f\"Warning: No data found after filtering for gamma = {fixed_gamma}. Chart will be empty.\")\n",
    "\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (plotting ALL variants) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(variant_avg).mark_circle(size=80, opacity=0.7).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    # Color by norm to distinguish the data points\n",
    "    color=alt.Color(\"norm:N\", title=\"Social Norm\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"norm:N\", title=\"Norm\"),\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:Q\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"All Norms â€” All variants at Î³ = {fixed_gamma}\" # Updated title\n",
    ").interactive() # Add interactive zoom/pan\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line ===\n",
    "# The 'labels' chart was removed as it would be unreadable\n",
    "chart_with_regression = (chart ).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc67cc",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Emotion Leniency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0661296-2416-4720-9c4b-bb93a9fef8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_norm = \"SternJudging\"  # Example\n",
    "\n",
    "# === 1. Filter and unify gamma column name ===\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Ensure numeric gamma\n",
    "norm_df[\"gamma_center\"] = pd.to_numeric(norm_df[\"gamma_center\"], errors=\"coerce\")\n",
    "\n",
    "# === 2. Compute mean cooperation per variant first ===\n",
    "variant_means = (\n",
    "    norm_df.groupby([\"variant_id\", \"gamma_center\", \"Emotion_Leniency\"], as_index=False)\n",
    "           .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "                sd_coop=(\"average_cooperation\", \"std\"),\n",
    "                n_runs=(\"average_cooperation\", \"count\"))\n",
    ")\n",
    "\n",
    "# Convert to % if needed\n",
    "if variant_means[\"mean_coop\"].max() <= 1:\n",
    "    variant_means[\"mean_coop\"] *= 100\n",
    "\n",
    "# === 3. For each (Î³, Leniency), find the variant with highest mean ===\n",
    "idx = variant_means.groupby([\"gamma_center\", \"Emotion_Leniency\"])[\"mean_coop\"].idxmax()\n",
    "max_variants = variant_means.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# === 4. Plot heatmap ===\n",
    "heat = alt.Chart(max_variants).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:O\", title=\"Emotion Leniency\", sort=\"descending\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Top Variant\"),\n",
    "        alt.Tooltip(\"mean_coop:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"sd_coop:Q\", title=\"Std (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"n_runs:Q\", title=\"# runs\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=400, height=350,\n",
    "    title=f\"{chosen_norm} â€” Maximal Cooperation by Î³ Ã— Emotion Leniency\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab7b5a-03a9-446c-a457-5e1a67ca7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick your norm and gamma value\n",
    "chosen_norm = \"SternJudging\"\n",
    "gamma_value = 0.5  # ðŸ”‘ change this\n",
    "\n",
    "# filter results for chosen norm and gamma\n",
    "subset = merged_df[(merged_df[\"norm\"] == chosen_norm) &\n",
    "                   (merged_df[\"gamma_center\"] == gamma_value)].copy()\n",
    "\n",
    "# aggregate cooperation by (DNF_literals, Leniency)\n",
    "agg = (\n",
    "    subset.groupby([\"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "          .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "               std_coop=(\"average_cooperation\", \"std\"),\n",
    "               n=(\"variant_id\", \"nunique\"))\n",
    ")\n",
    "\n",
    "# --- Scatterplot ---\n",
    "chart = alt.Chart(agg).mark_circle(size=200).encode(\n",
    "    x=alt.X(\"DNF_literals:Q\", title=\"DNF complexity (# literals)\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0,100])),\n",
    "    size=alt.Size(\"n:Q\", title=\"# Variants\"),\n",
    "    tooltip=[\n",
    "        \"DNF_literals:Q\",\n",
    "        \"Emotion_Leniency:Q\",\n",
    "        alt.Tooltip(\"mean_coop:Q\", format=\".2f\", title=\"Mean coop\"),\n",
    "        alt.Tooltip(\"std_coop:Q\", format=\".2f\", title=\"Std\"),\n",
    "        \"n:Q\"\n",
    "    ]\n",
    ").properties(\n",
    "    title=f\"{chosen_norm} â€” Cooperation by Complexity Ã— Leniency (Î³={gamma_value})\",\n",
    "    width=500, height=400\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315cd82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
