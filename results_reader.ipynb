{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e41aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from itertools import chain\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "results_path = os.path.normpath(os.path.join(notebook_dir, \"outputs\", \"updated_model_results.csv\"))\n",
    "norms_path   = os.path.normpath(os.path.join(notebook_dir, \"data\", \"all_8bit_norms_with_dnf.csv\"))\n",
    "\n",
    "# Load CSVs\n",
    "results_df = pd.read_csv(results_path)\n",
    "norms_df   = pd.read_csv(norms_path, dtype={\"8bit_vector\": str})\n",
    "\n",
    "# --- Helpers to flatten ---\n",
    "def flatten_ebsn_to_str(ebsn):\n",
    "    flat_list = list(chain.from_iterable(chain.from_iterable(ebsn)))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "def flatten_base_sn_to_str(base_sn):\n",
    "    flat_list = list(chain.from_iterable(base_sn))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "\n",
    "def identify_base_norm(base_norm_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the base social norm (e.g. Image Scoring, Stern Judging, etc.)\n",
    "    from its 4-bit structure [[a,b], [c,d], ...] as stored in the dataframe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        norm = ast.literal_eval(base_norm_str)\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Flatten if nested\n",
    "    flat = [int(x) for pair in norm for x in pair]\n",
    "\n",
    "    mapping = {\n",
    "        (0, 0, 1, 1): \"Image Scoring\",\n",
    "        (1, 0, 0, 1): \"Stern Judging\",\n",
    "        (0, 0, 0, 1): \"Shunning\",\n",
    "        (1, 0, 1, 1): \"Simple Standing\",\n",
    "        (0, 0, 0, 0): \"All Bad\",\n",
    "        (1, 1, 1, 1): \"All Good\",\n",
    "    }\n",
    "\n",
    "    return mapping.get(tuple(flat), \"Unknown\")\n",
    "\n",
    "\n",
    "# Flatten columns in results\n",
    "results_df['8bit_vector'] = results_df['eb_social_norm'].apply(eval).apply(flatten_ebsn_to_str)\n",
    "results_df['4bit_orig']   = results_df['base_social_norm'].apply(eval).apply(flatten_base_sn_to_str)\n",
    "\n",
    "# Merge and include DNF columns\n",
    "merged_df = pd.merge(\n",
    "    results_df,\n",
    "    norms_df[[\"8bit_vector\", \n",
    "              \"Emotion_Leniency\", \"DNF\", \"DNF_literals\"]],\n",
    "    on=[\"8bit_vector\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure numeric\n",
    "merged_df[\"DNF_literals\"] = pd.to_numeric(merged_df[\"DNF_literals\"], errors=\"coerce\")\n",
    "merged_df[\"base_social_norm\"] = merged_df[\"base_social_norm\"].apply(identify_base_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e07cb15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11543</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11544</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11546</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11547</th>\n",
       "      <td>Stern Judging</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>11111111</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11548 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                ...                                   ...  ..   ...  ...   \n",
       "11543    Stern Judging  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "11544    Stern Judging  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "11545    Stern Judging  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "11546    Stern Judging  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "11547    Stern Judging  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0      0.01  0.01    0.0  5  1  ...        0.5333              0.1333   \n",
       "1      0.01  0.01    0.0  5  1  ...        0.1333              0.1333   \n",
       "2      0.01  0.01    0.0  5  1  ...        0.0000              0.0333   \n",
       "3      0.01  0.01    0.0  5  1  ...        0.2333              0.0000   \n",
       "4      0.01  0.01    0.0  5  1  ...        0.0333              0.0000   \n",
       "...     ...   ...    ... .. ..  ...           ...                 ...   \n",
       "11543  0.01  0.01    0.0  5  1  ...        0.0600              0.1200   \n",
       "11544  0.01  0.01    0.0  5  1  ...        0.0400              0.0000   \n",
       "11545  0.01  0.01    0.0  5  1  ...        0.0000              0.3600   \n",
       "11546  0.01  0.01    0.0  5  1  ...        0.1200              0.0200   \n",
       "11547  0.01  0.01    0.0  5  1  ...        0.0000              0.1800   \n",
       "\n",
       "       ALWAYS_DEFECT  Competitive  Cooperative  8bit_vector  4bit_orig  \\\n",
       "0             0.3333         0.87         0.13     00011111       0011   \n",
       "1             0.7333         0.73         0.27     00011111       0011   \n",
       "2             0.9333         0.07         0.93     00011111       0011   \n",
       "3             0.4000         0.60         0.40     00011111       0011   \n",
       "4             0.9333         0.93         0.07     00011111       0011   \n",
       "...              ...          ...          ...          ...        ...   \n",
       "11543         0.8200         0.06         0.94     11111111       1001   \n",
       "11544         0.9600         0.04         0.96     11111111       1001   \n",
       "11545         0.6400         0.36         0.64     11111111       1001   \n",
       "11546         0.8600         0.12         0.88     11111111       1001   \n",
       "11547         0.7800         0.78         0.22     11111111       1001   \n",
       "\n",
       "       Emotion_Leniency          DNF  DNF_literals  \n",
       "0                  0.75  A | (E & R)             3  \n",
       "1                  0.75  A | (E & R)             3  \n",
       "2                  0.75  A | (E & R)             3  \n",
       "3                  0.75  A | (E & R)             3  \n",
       "4                  0.75  A | (E & R)             3  \n",
       "...                 ...          ...           ...  \n",
       "11543              1.00         True             0  \n",
       "11544              1.00         True             0  \n",
       "11545              1.00         True             0  \n",
       "11546              1.00         True             0  \n",
       "11547              1.00         True             0  \n",
       "\n",
       "[11548 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e930e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Emergent Norms: DNF Complexity vs Cooperation  \n",
    "This section selects a **base social norm** (e.g., Image Scoring, Stern Judging) and visualizes how all **emergent 8-bit norms** derived from it perform.\n",
    "\n",
    "For each emergent norm:\n",
    "- All simulation runs are grouped.\n",
    "- The **mean cooperation ratio** is computed.\n",
    "- The **DNF complexity** (number of literals in simplified DNF) is retrieved.\n",
    "\n",
    "The scatterplot shows:\n",
    "- **x-axis:** DNF complexity  \n",
    "- **y-axis:** mean cooperation  \n",
    "- **each point:** one emergent 8-bit social norm  \n",
    "\n",
    "This helps reveal which evolved norms are both **simple** and **highly cooperative** under a chosen base norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b16cbe48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-dd8b4800c85345beb6625b72cb88e396.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-dd8b4800c85345beb6625b72cb88e396.vega-embed details,\n",
       "  #altair-viz-dd8b4800c85345beb6625b72cb88e396.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-dd8b4800c85345beb6625b72cb88e396\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dd8b4800c85345beb6625b72cb88e396\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dd8b4800c85345beb6625b72cb88e396\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 80}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"Emotion Leniency\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"line\", \"color\": \"black\", \"opacity\": 0.5, \"size\": 2}, \"encoding\": {\"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}, \"transform\": [{\"on\": \"DNF_literals\", \"regression\": \"mean_coop\", \"method\": \"poly\"}]}], \"data\": {\"name\": \"data-f21460453528c76ae4213c13511dc213\"}, \"height\": 300, \"title\": \"Social Norms (Top 10%) \\u2014 Poly Regression \\u2014 Base Norm: Stern Judging\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-f21460453528c76ae4213c13511dc213\": [{\"8bit_vector\": \"00000000\", \"DNF_literals\": 0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 5.55265}, {\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 86.6741}, {\"8bit_vector\": \"00000011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 82.329}, {\"8bit_vector\": \"00001010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 66.9212}, {\"8bit_vector\": \"11110011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 78.74969999999999}, {\"8bit_vector\": \"01010111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.68745}, {\"8bit_vector\": \"11010101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 91.94919999999999}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 85.6666}, {\"8bit_vector\": \"11111011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 79.6714}, {\"8bit_vector\": \"01000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 91.5376}, {\"8bit_vector\": \"10001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.4279}, {\"8bit_vector\": \"11000011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.4461}, {\"8bit_vector\": \"11001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.9881}, {\"8bit_vector\": \"11010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 89.736}, {\"8bit_vector\": \"11100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 93.5025}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 88.8103}, {\"8bit_vector\": \"11000001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.7906}, {\"8bit_vector\": \"11000010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 88.90610000000001}, {\"8bit_vector\": \"11101011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.9744}, {\"8bit_vector\": \"01000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.32965}, {\"8bit_vector\": \"10000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.9898}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 90.7678}, {\"8bit_vector\": \"11001011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.3524}, {\"8bit_vector\": \"11010011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 93.10810000000001}, {\"8bit_vector\": \"11100011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.1099}, {\"8bit_vector\": \"10100110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 76.9794}, {\"8bit_vector\": \"10101001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 78.6113}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.46090000000001}, {\"8bit_vector\": \"10000110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.364}, {\"8bit_vector\": \"11010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.4035}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 5.1353}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm (must match identify_base_norm output)\n",
    "chosen_base_norm = \"Stern Judging\"   # â† adjust as needed\n",
    "\n",
    "# Filter only runs that originate from this base norm\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == 0.8]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0.90)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"DNF_literals\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# Scatter plot with color by Emotion Leniency\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=80)\n",
    "    .encode(\n",
    "        x=alt.X(\"DNF_literals:Q\", title=\"DNF Complexity\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\", scale = alt.Scale(domain=[0,100])),\n",
    "        color=alt.Color(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\",\n",
    "                        scale=alt.Scale(scheme=\"viridis\")),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Polynomial regression (degree 2)\n",
    "poly_reg = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .transform_regression(\n",
    "        \"DNF_literals\",\n",
    "        \"mean_coop\",\n",
    "        method=\"poly\"\n",
    "    )\n",
    "    .mark_line(size=2, color=\"black\", opacity=0.5)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (scatter + poly_reg)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Social Norms (Top 10%) â€” Poly Regression â€” Base Norm: {chosen_base_norm}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3300f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.gamma_center.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b2cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f684835a78254c30831802c9b6f79ba4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f684835a78254c30831802c9b6f79ba4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f684835a78254c30831802c9b6f79ba4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d751713988987e9331980363e24189ce\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.8, \"size\": 80}, \"encoding\": {\"tooltip\": [{\"field\": \"8bit_vector\", \"title\": \"Norm vector\", \"type\": \"nominal\"}, {\"field\": \"Emotion_Leniency\", \"format\": \".3f\", \"title\": \"Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".3f\", \"title\": \"Mean Coop\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotion Leniency (0 = harsh, 1 = forgiving)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"Emotion Leniency vs Cooperation \\u2014 Stern Judging\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-d751713988987e9331980363e24189ce\": []}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Select a base social norm to examine ---\n",
    "# Filter to only runs that used this base norm\n",
    "sub = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "\n",
    "# Group by emergent norm and compute mean cooperation\n",
    "leniency_summary = (\n",
    "    sub.groupby([\"8bit_vector\", \"Emotion_Leniency\"], as_index=False)\n",
    "       .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "leniency_summary.head()\n",
    "\n",
    "# Scatter plot\n",
    "scatter_leniency = (\n",
    "    alt.Chart(leniency_summary)\n",
    "       .mark_circle(size=80, opacity=0.8)\n",
    "       .encode(\n",
    "           x=alt.X(\"Emotion_Leniency:Q\",\n",
    "                   title=\"Emotion Leniency (0 = harsh, 1 = forgiving)\"),\n",
    "           y=alt.Y(\"mean_coop:Q\",\n",
    "                   title=\"Mean Cooperation\"),\n",
    "           tooltip=[\n",
    "               alt.Tooltip(\"8bit_vector:N\", title=\"Norm vector\"),\n",
    "               alt.Tooltip(\"Emotion_Leniency:Q\", title=\"Leniency\", format=\".3f\"),\n",
    "               alt.Tooltip(\"mean_coop:Q\", title=\"Mean Coop\", format=\".3f\"),\n",
    "           ]\n",
    "       )\n",
    "       .properties(\n",
    "           width=500,\n",
    "           height=350,\n",
    "           title=f\"Emotion Leniency vs Cooperation â€” {chosen_base_norm}\"\n",
    "       )\n",
    ")\n",
    "\n",
    "scatter_leniency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ffe88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(1, 1), (0, 1)], [(1, 0), (1, 0)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11011010</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(A &amp; ~E) | (E &amp; ~A) | (~A &amp; ~R)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(1, 1), (0, 1)], [(1, 0), (1, 0)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11011010</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(A &amp; ~E) | (E &amp; ~A) | (~A &amp; ~R)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(1, 1), (0, 1)], [(1, 0), (1, 0)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11011010</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(A &amp; ~E) | (E &amp; ~A) | (~A &amp; ~R)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(1, 1), (0, 1)], [(1, 0), (1, 0)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11011010</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(A &amp; ~E) | (E &amp; ~A) | (~A &amp; ~R)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(1, 1), (0, 1)], [(1, 0), (1, 0)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11011010</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.25</td>\n",
       "      <td>(A &amp; ~E) | (E &amp; ~A) | (~A &amp; ~R)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3520 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0       Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1       Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2       Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3       Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4       Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...               ...                                   ...  ..   ...  ...   \n",
       "5143    Image Scoring  [[(1, 1), (0, 1)], [(1, 0), (1, 0)]]  50  1000  1.0   \n",
       "5144    Image Scoring  [[(1, 1), (0, 1)], [(1, 0), (1, 0)]]  50  1000  1.0   \n",
       "5145    Image Scoring  [[(1, 1), (0, 1)], [(1, 0), (1, 0)]]  50  1000  1.0   \n",
       "5146    Image Scoring  [[(1, 1), (0, 1)], [(1, 0), (1, 0)]]  50  1000  1.0   \n",
       "5147    Image Scoring  [[(1, 1), (0, 1)], [(1, 0), (1, 0)]]  50  1000  1.0   \n",
       "\n",
       "       chi   eps  alpha  b  c  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0     0.01  0.01    0.0  5  1  ...        0.5333              0.1333   \n",
       "1     0.01  0.01    0.0  5  1  ...        0.1333              0.1333   \n",
       "2     0.01  0.01    0.0  5  1  ...        0.0000              0.0333   \n",
       "3     0.01  0.01    0.0  5  1  ...        0.2333              0.0000   \n",
       "4     0.01  0.01    0.0  5  1  ...        0.0333              0.0000   \n",
       "...    ...   ...    ... .. ..  ...           ...                 ...   \n",
       "5143  0.01  0.01    0.0  5  1  ...        0.0400              0.0200   \n",
       "5144  0.01  0.01    0.0  5  1  ...        0.0200              0.0000   \n",
       "5145  0.01  0.01    0.0  5  1  ...        0.0000              0.0400   \n",
       "5146  0.01  0.01    0.0  5  1  ...        0.0000              0.0000   \n",
       "5147  0.01  0.01    0.0  5  1  ...        0.2000              0.0600   \n",
       "\n",
       "      ALWAYS_DEFECT  Competitive  Cooperative  8bit_vector  4bit_orig  \\\n",
       "0            0.3333         0.87         0.13     00011111       0011   \n",
       "1            0.7333         0.73         0.27     00011111       0011   \n",
       "2            0.9333         0.07         0.93     00011111       0011   \n",
       "3            0.4000         0.60         0.40     00011111       0011   \n",
       "4            0.9333         0.93         0.07     00011111       0011   \n",
       "...             ...          ...          ...          ...        ...   \n",
       "5143         0.9200         0.92         0.08     11011010       0011   \n",
       "5144         0.9800         0.98         0.02     11011010       0011   \n",
       "5145         0.9600         0.96         0.04     11011010       0011   \n",
       "5146         1.0000         1.00         0.00     11011010       0011   \n",
       "5147         0.7400         0.74         0.26     11011010       0011   \n",
       "\n",
       "      Emotion_Leniency                              DNF  DNF_literals  \n",
       "0                 0.75                      A | (E & R)             3  \n",
       "1                 0.75                      A | (E & R)             3  \n",
       "2                 0.75                      A | (E & R)             3  \n",
       "3                 0.75                      A | (E & R)             3  \n",
       "4                 0.75                      A | (E & R)             3  \n",
       "...                ...                              ...           ...  \n",
       "5143              0.25  (A & ~E) | (E & ~A) | (~A & ~R)             6  \n",
       "5144              0.25  (A & ~E) | (E & ~A) | (~A & ~R)             6  \n",
       "5145              0.25  (A & ~E) | (E & ~A) | (~A & ~R)             6  \n",
       "5146              0.25  (A & ~E) | (E & ~A) | (~A & ~R)             6  \n",
       "5147              0.25  (A & ~E) | (E & ~A) | (~A & ~R)             6  \n",
       "\n",
       "[3520 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf733f9",
   "metadata": {},
   "source": [
    "## Multiple Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6c403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28aa2cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-eec9ab8b5ae94653b22b413d2f296769\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-eec9ab8b5ae94653b22b413d2f296769\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-eec9ab8b5ae94653b22b413d2f296769\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-18e7d998407c2409085123ab53681ab7\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"scale\": {\"scheme\": \"bluepurple\"}, \"title\": \"Emotion Leniency\", \"type\": \"ordinal\"}, \"detail\": {\"field\": \"variant_id\", \"type\": \"nominal\"}, \"strokeDash\": {\"condition\": {\"value\": [5, 5], \"test\": \"datum.is_base\"}, \"value\": [1, 0]}, \"strokeWidth\": {\"condition\": {\"value\": 8, \"test\": \"datum.is_base\"}, \"value\": 2}, \"tooltip\": [{\"field\": \"variant_id\", \"title\": \"Variant\", \"type\": \"nominal\"}, {\"field\": \"gamma_center\", \"title\": \"Gamma\", \"type\": \"quantitative\"}, {\"field\": \"avg_coop_percent\", \"format\": \".1f\", \"title\": \"Mean coop (%)\", \"type\": \"quantitative\"}, {\"field\": \"std_coop_percent\", \"format\": \".1f\", \"title\": \"Std (%)\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"title\": \"Leniency\", \"type\": \"ordinal\"}, {\"field\": \"is_base\", \"title\": \"Base?\", \"type\": \"nominal\"}], \"x\": {\"field\": \"gamma_center\", \"title\": \"Gamma value\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"avg_coop_percent\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Average Cooperation (%)\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-ceb3261634142d67a582295fbae5ab87\"}, \"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 5}, \"encoding\": {\"text\": {\"field\": \"variant_id\", \"type\": \"nominal\"}, \"x\": {\"field\": \"gamma_center\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"avg_coop_percent\", \"scale\": {\"domain\": [0, 100]}, \"type\": \"quantitative\"}}}], \"height\": 420, \"title\": \"Performance of SternJudging Variants (color = Emotion Leniency; dashed = base)\", \"width\": 700, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-18e7d998407c2409085123ab53681ab7\": [{\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.0, \"is_base\": true, \"avg_coop\": 93.28864, \"std_coop\": 1.0400989505517133, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.28864, \"std_coop_percent\": 1.0400989505517133}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.1, \"is_base\": true, \"avg_coop\": 93.26889999999999, \"std_coop\": 1.0359131286956855, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.26889999999999, \"std_coop_percent\": 1.0359131286956855}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.2, \"is_base\": true, \"avg_coop\": 93.47752, \"std_coop\": 0.18695653101669366, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.47752, \"std_coop_percent\": 0.18695653101669366}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.3, \"is_base\": true, \"avg_coop\": 92.8325, \"std_coop\": 3.1317599358696646, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 92.8325, \"std_coop_percent\": 3.1317599358696646}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.4, \"is_base\": true, \"avg_coop\": 92.90152, \"std_coop\": 2.779827393261413, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 92.90152, \"std_coop_percent\": 2.779827393261413}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.5, \"is_base\": true, \"avg_coop\": 93.1975, \"std_coop\": 1.436465222946485, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.1975, \"std_coop_percent\": 1.436465222946485}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.6, \"is_base\": true, \"avg_coop\": 93.09698, \"std_coop\": 1.6272718309602547, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.09698, \"std_coop_percent\": 1.6272718309602547}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.7, \"is_base\": true, \"avg_coop\": 93.25764, \"std_coop\": 0.9691021462136612, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.25764, \"std_coop_percent\": 0.9691021462136612}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.8, \"is_base\": true, \"avg_coop\": 93.08008, \"std_coop\": 1.3641344544420533, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.08008, \"std_coop_percent\": 1.3641344544420533}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 0.9, \"is_base\": true, \"avg_coop\": 93.04866, \"std_coop\": 1.7628617111540736, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.04866, \"std_coop_percent\": 1.7628617111540736}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 1.0, \"is_base\": true, \"avg_coop\": 93.34371999999999, \"std_coop\": 0.89741247177081, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.34371999999999, \"std_coop_percent\": 0.89741247177081}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.33162, \"std_coop\": 0.7515730955530449, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 93.33162, \"std_coop_percent\": 0.7515730955530449}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.14812, \"std_coop\": 2.7528059201995556, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.14812, \"std_coop_percent\": 2.7528059201995556}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 90.55076, \"std_coop\": 5.689944336587959, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 90.55076, \"std_coop_percent\": 5.689944336587959}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 88.2009, \"std_coop\": 8.278607911296413, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 88.2009, \"std_coop_percent\": 8.278607911296413}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 83.78479999999999, \"std_coop\": 10.024947926985734, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 83.78479999999999, \"std_coop_percent\": 10.024947926985734}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 79.97648, \"std_coop\": 12.969264138551203, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 79.97648, \"std_coop_percent\": 12.969264138551203}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 80.3377, \"std_coop\": 11.572526468638857, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 80.3377, \"std_coop_percent\": 11.572526468638857}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 73.2056, \"std_coop\": 16.16698352210708, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 73.2056, \"std_coop_percent\": 16.16698352210708}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 62.971540000000005, \"std_coop\": 17.350311664800557, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 62.971540000000005, \"std_coop_percent\": 17.350311664800557}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 27.80382, \"std_coop\": 9.96353317115234, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 27.80382, \"std_coop_percent\": 9.96353317115234}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 21.301260000000003, \"std_coop\": 6.315114010992733, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 21.301260000000003, \"std_coop_percent\": 6.315114010992733}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.35224, \"std_coop\": 0.8234064277780001, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 93.35224, \"std_coop_percent\": 0.8234064277780001}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.55862, \"std_coop\": 4.254751878374416, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.55862, \"std_coop_percent\": 4.254751878374416}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 92.17433999999999, \"std_coop\": 3.1304000240563883, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.17433999999999, \"std_coop_percent\": 3.1304000240563883}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 90.76350000000001, \"std_coop\": 6.868298135310538, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 90.76350000000001, \"std_coop_percent\": 6.868298135310538}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 92.16544, \"std_coop\": 3.751567820068224, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.16544, \"std_coop_percent\": 3.751567820068224}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 92.27366, \"std_coop\": 4.501405651707529, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.27366, \"std_coop_percent\": 4.501405651707529}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 92.02842000000001, \"std_coop\": 4.788982048922082, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.02842000000001, \"std_coop_percent\": 4.788982048922082}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 92.09494000000001, \"std_coop\": 4.733529732770292, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 92.09494000000001, \"std_coop_percent\": 4.733529732770292}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 91.7682, \"std_coop\": 3.7544495778546643, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 91.7682, \"std_coop_percent\": 3.7544495778546643}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 90.48394, \"std_coop\": 7.442806269115959, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 90.48394, \"std_coop_percent\": 7.442806269115959}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 90.72412, \"std_coop\": 7.179876468836712, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 90.72412, \"std_coop_percent\": 7.179876468836712}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.14702, \"std_coop\": 2.0388122541703275, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 93.14702, \"std_coop_percent\": 2.0388122541703275}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 91.59006, \"std_coop\": 3.7590477159807936, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 91.59006, \"std_coop_percent\": 3.7590477159807936}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 90.2436, \"std_coop\": 6.324249962789005, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 90.2436, \"std_coop_percent\": 6.324249962789005}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 89.42605999999999, \"std_coop\": 7.02256978201465, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 89.42605999999999, \"std_coop_percent\": 7.02256978201465}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 85.2059, \"std_coop\": 10.560749658861482, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 85.2059, \"std_coop_percent\": 10.560749658861482}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 84.27042, \"std_coop\": 11.708433740545093, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 84.27042, \"std_coop_percent\": 11.708433740545093}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 86.59692, \"std_coop\": 8.074863511426258, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 86.59692, \"std_coop_percent\": 8.074863511426258}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 81.48238, \"std_coop\": 13.046498824870485, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 81.48238, \"std_coop_percent\": 13.046498824870485}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 73.9078, \"std_coop\": 13.596651996363079, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 73.9078, \"std_coop_percent\": 13.596651996363079}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 47.14592, \"std_coop\": 12.767310687750612, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 47.14592, \"std_coop_percent\": 12.767310687750612}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 36.66792, \"std_coop\": 12.834894914367517, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 36.66792, \"std_coop_percent\": 12.834894914367517}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.2878, \"std_coop\": 1.1929905656776685, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 93.2878, \"std_coop_percent\": 1.1929905656776685}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.97808, \"std_coop\": 1.839201033723336, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.97808, \"std_coop_percent\": 1.839201033723336}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 93.00762, \"std_coop\": 1.152332840416363, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 93.00762, \"std_coop_percent\": 1.152332840416363}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 92.03415999999999, \"std_coop\": 2.9708565889044123, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.03415999999999, \"std_coop_percent\": 2.9708565889044123}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 90.85938, \"std_coop\": 5.405254891722477, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 90.85938, \"std_coop_percent\": 5.405254891722477}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 85.9983, \"std_coop\": 15.297163249426077, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 85.9983, \"std_coop_percent\": 15.297163249426077}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 71.79606, \"std_coop\": 25.382321662848863, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 71.79606, \"std_coop_percent\": 25.382321662848863}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 23.9979, \"std_coop\": 17.21967980603731, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 23.9979, \"std_coop_percent\": 17.21967980603731}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 6.45368, \"std_coop\": 2.960821531333519, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 6.45368, \"std_coop_percent\": 2.960821531333519}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 5.61582, \"std_coop\": 0.38780090042101106, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.61582, \"std_coop_percent\": 0.38780090042101106}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.41884, \"std_coop\": 0.2804854654461271, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.41884, \"std_coop_percent\": 0.2804854654461271}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.87316000000001, \"std_coop\": 1.6580212617725383, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.87316000000001, \"std_coop_percent\": 1.6580212617725383}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 91.79338, \"std_coop\": 3.3403137692652267, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 91.79338, \"std_coop_percent\": 3.3403137692652267}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 89.94936, \"std_coop\": 6.266303078843087, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 89.94936, \"std_coop_percent\": 6.266303078843087}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 88.82904, \"std_coop\": 10.690281829316014, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 88.82904, \"std_coop_percent\": 10.690281829316014}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 85.59362000000002, \"std_coop\": 13.91352416204303, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 85.59362000000002, \"std_coop_percent\": 13.91352416204303}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 72.08164, \"std_coop\": 27.43076631750769, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 72.08164, \"std_coop_percent\": 27.43076631750769}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 57.18136, \"std_coop\": 27.67328066945826, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 57.18136, \"std_coop_percent\": 27.67328066945826}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 24.641460000000002, \"std_coop\": 30.47451963908638, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 24.641460000000002, \"std_coop_percent\": 30.47451963908638}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 6.17852, \"std_coop\": 2.4053682669378995, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 6.17852, \"std_coop_percent\": 2.4053682669378995}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 5.808719999999999, \"std_coop\": 1.8524266934736928, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.808719999999999, \"std_coop_percent\": 1.8524266934736928}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.46212, \"std_coop\": 0.32577259127263897, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.46212, \"std_coop_percent\": 0.32577259127263897}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.7692, \"std_coop\": 2.5065781456000926, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 92.7692, \"std_coop_percent\": 2.5065781456000926}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.70026, \"std_coop\": 2.0400322307377836, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 92.70026, \"std_coop_percent\": 2.0400322307377836}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 90.7391, \"std_coop\": 4.8996208401825365, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 90.7391, \"std_coop_percent\": 4.8996208401825365}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 87.63084, \"std_coop\": 9.334331788246079, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 87.63084, \"std_coop_percent\": 9.334331788246079}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 81.96889999999999, \"std_coop\": 18.27557821553794, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 81.96889999999999, \"std_coop_percent\": 18.27557821553794}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 77.00726, \"std_coop\": 21.426812993384466, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 77.00726, \"std_coop_percent\": 21.426812993384466}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 53.06528, \"std_coop\": 33.01388676462914, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 53.06528, \"std_coop_percent\": 33.01388676462914}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 26.19612, \"std_coop\": 30.00803569293684, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 26.19612, \"std_coop_percent\": 30.00803569293684}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 7.03662, \"std_coop\": 6.750920299742057, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 7.03662, \"std_coop_percent\": 6.750920299742057}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 5.64558, \"std_coop\": 1.295415071610293, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 5.64558, \"std_coop_percent\": 1.295415071610293}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.388780000000001, \"std_coop\": 0.28310402573569154, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 5.388780000000001, \"std_coop_percent\": 0.28310402573569154}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.11822000000001, \"std_coop\": 1.9041862506443186, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 93.11822000000001, \"std_coop_percent\": 1.9041862506443186}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 91.25736, \"std_coop\": 3.7916452180540112, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 91.25736, \"std_coop_percent\": 3.7916452180540112}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 90.86474, \"std_coop\": 5.039298136301382, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 90.86474, \"std_coop_percent\": 5.039298136301382}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 80.59694, \"std_coop\": 20.59671645954019, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 80.59694, \"std_coop_percent\": 20.59671645954019}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 72.66954, \"std_coop\": 31.969935092916682, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 72.66954, \"std_coop_percent\": 31.969935092916682}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 51.163999999999994, \"std_coop\": 40.417048136666686, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 51.163999999999994, \"std_coop_percent\": 40.417048136666686}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 26.503899999999998, \"std_coop\": 34.50511935708872, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 26.503899999999998, \"std_coop_percent\": 34.50511935708872}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 10.143279999999999, \"std_coop\": 16.9567722634194, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 10.143279999999999, \"std_coop_percent\": 16.9567722634194}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 6.17164, \"std_coop\": 3.281814099872576, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 6.17164, \"std_coop_percent\": 3.281814099872576}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 5.489339999999999, \"std_coop\": 0.25294732935647185, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 5.489339999999999, \"std_coop_percent\": 0.25294732935647185}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.38526, \"std_coop\": 0.26446247448014853, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 5.38526, \"std_coop_percent\": 0.26446247448014853}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.03453999999999, \"std_coop\": 2.645954842581331, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 93.03453999999999, \"std_coop_percent\": 2.645954842581331}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.67144, \"std_coop\": 1.9372702671964137, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.67144, \"std_coop_percent\": 1.9372702671964137}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 92.13582000000001, \"std_coop\": 3.344058530698093, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.13582000000001, \"std_coop_percent\": 3.344058530698093}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 91.8932, \"std_coop\": 4.831046445140232, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 91.8932, \"std_coop_percent\": 4.831046445140232}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 91.25692000000001, \"std_coop\": 4.963165665383418, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 91.25692000000001, \"std_coop_percent\": 4.963165665383418}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 90.9268, \"std_coop\": 6.586169785921069, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.9268, \"std_coop_percent\": 6.586169785921069}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 89.79384, \"std_coop\": 6.856119031781695, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 89.79384, \"std_coop_percent\": 6.856119031781695}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 91.10637999999999, \"std_coop\": 4.78475172789049, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 91.10637999999999, \"std_coop_percent\": 4.78475172789049}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 90.40572, \"std_coop\": 6.705218473483383, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.40572, \"std_coop_percent\": 6.705218473483383}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 90.30824000000001, \"std_coop\": 7.681607948595032, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.30824000000001, \"std_coop_percent\": 7.681607948595032}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 90.58912000000001, \"std_coop\": 4.424054838018617, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.58912000000001, \"std_coop_percent\": 4.424054838018617}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.39326000000001, \"std_coop\": 0.8501818487349477, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 93.39326000000001, \"std_coop_percent\": 0.8501818487349477}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.60914000000001, \"std_coop\": 2.0295030256248467, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 92.60914000000001, \"std_coop_percent\": 2.0295030256248467}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 91.73056000000001, \"std_coop\": 3.6801883501044994, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.73056000000001, \"std_coop_percent\": 3.6801883501044994}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 91.41912, \"std_coop\": 4.450281553303507, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.41912, \"std_coop_percent\": 4.450281553303507}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 91.90673999999999, \"std_coop\": 3.7970693576139234, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.90673999999999, \"std_coop_percent\": 3.7970693576139234}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 91.4167, \"std_coop\": 5.694214551379568, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.4167, \"std_coop_percent\": 5.694214551379568}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 91.6209, \"std_coop\": 3.5899987109883407, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.6209, \"std_coop_percent\": 3.5899987109883407}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 90.92022000000001, \"std_coop\": 5.936609168540574, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 90.92022000000001, \"std_coop_percent\": 5.936609168540574}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 86.69257999999999, \"std_coop\": 12.759270641764598, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 86.69257999999999, \"std_coop_percent\": 12.759270641764598}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 90.4426, \"std_coop\": 5.905524017254299, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 90.4426, \"std_coop_percent\": 5.905524017254299}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 91.12549999999999, \"std_coop\": 5.151091278277147, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.12549999999999, \"std_coop_percent\": 5.151091278277147}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.27825999999999, \"std_coop\": 0.5795226681132855, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 93.27825999999999, \"std_coop_percent\": 0.5795226681132855}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 91.93066, \"std_coop\": 3.1029517652633634, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.93066, \"std_coop_percent\": 3.1029517652633634}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 91.90690000000001, \"std_coop\": 3.6949509634701476, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.90690000000001, \"std_coop_percent\": 3.6949509634701476}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 91.57438, \"std_coop\": 5.572762891098829, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.57438, \"std_coop_percent\": 5.572762891098829}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 87.34582, \"std_coop\": 13.696130238047202, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 87.34582, \"std_coop_percent\": 13.696130238047202}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 87.51540000000001, \"std_coop\": 15.873166508936016, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 87.51540000000001, \"std_coop_percent\": 15.873166508936016}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 83.89002, \"std_coop\": 22.68646073753044, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 83.89002, \"std_coop_percent\": 22.68646073753044}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 81.73788, \"std_coop\": 27.421981666464557, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 81.73788, \"std_coop_percent\": 27.421981666464557}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 85.78712, \"std_coop\": 21.247317399596206, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 85.78712, \"std_coop_percent\": 21.247317399596206}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 85.74058, \"std_coop\": 20.49583914975557, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 85.74058, \"std_coop_percent\": 20.49583914975557}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 79.1816, \"std_coop\": 29.167665660481514, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 79.1816, \"std_coop_percent\": 29.167665660481514}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.92218000000001, \"std_coop\": 3.156671701689125, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 92.92218000000001, \"std_coop_percent\": 3.156671701689125}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 93.17255999999999, \"std_coop\": 1.3099260792354743, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 93.17255999999999, \"std_coop_percent\": 1.3099260792354743}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 93.02959999999999, \"std_coop\": 1.9064888552262904, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 93.02959999999999, \"std_coop_percent\": 1.9064888552262904}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 93.08588, \"std_coop\": 1.4799631081998814, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 93.08588, \"std_coop_percent\": 1.4799631081998814}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 92.27668, \"std_coop\": 3.3084512218479136, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 92.27668, \"std_coop_percent\": 3.3084512218479136}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 91.64882, \"std_coop\": 5.109246866062292, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 91.64882, \"std_coop_percent\": 5.109246866062292}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 92.16077999999999, \"std_coop\": 3.5367685544512404, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 92.16077999999999, \"std_coop_percent\": 3.5367685544512404}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 91.14142, \"std_coop\": 5.705731290088402, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 91.14142, \"std_coop_percent\": 5.705731290088402}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 91.51386000000001, \"std_coop\": 7.304537493942251, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 91.51386000000001, \"std_coop_percent\": 7.304537493942251}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 92.10706, \"std_coop\": 4.62795874432602, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 92.10706, \"std_coop_percent\": 4.62795874432602}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 89.33404, \"std_coop\": 7.765522779516111, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 89.33404, \"std_coop_percent\": 7.765522779516111}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 93.27758, \"std_coop\": 1.1570299255297711, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 93.27758, \"std_coop_percent\": 1.1570299255297711}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.7543, \"std_coop\": 1.7378251391569048, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.7543, \"std_coop_percent\": 1.7378251391569048}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 92.24432, \"std_coop\": 4.247288611405096, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.24432, \"std_coop_percent\": 4.247288611405096}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 92.41026, \"std_coop\": 3.2496061978683635, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.41026, \"std_coop_percent\": 3.2496061978683635}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 92.67386, \"std_coop\": 2.2709546496608737, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.67386, \"std_coop_percent\": 2.2709546496608737}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 92.10361999999999, \"std_coop\": 3.263267030108925, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.10361999999999, \"std_coop_percent\": 3.263267030108925}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 92.77177999999999, \"std_coop\": 3.378810558073201, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 92.77177999999999, \"std_coop_percent\": 3.378810558073201}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 91.32214, \"std_coop\": 6.346744838200483, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 91.32214, \"std_coop_percent\": 6.346744838200483}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 91.72015999999999, \"std_coop\": 4.546811223308942, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 91.72015999999999, \"std_coop_percent\": 4.546811223308942}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 90.18094, \"std_coop\": 7.926951294984799, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.18094, \"std_coop_percent\": 7.926951294984799}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 88.95024, \"std_coop\": 11.117476449009716, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 88.95024, \"std_coop_percent\": 11.117476449009716}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.94562, \"std_coop\": 1.8831192305126447, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 92.94562, \"std_coop_percent\": 1.8831192305126447}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.78265999999999, \"std_coop\": 1.3858575273535338, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 92.78265999999999, \"std_coop_percent\": 1.3858575273535338}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 91.37845999999999, \"std_coop\": 4.177646824249659, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 91.37845999999999, \"std_coop_percent\": 4.177646824249659}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 86.40892, \"std_coop\": 9.013163010999918, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 86.40892, \"std_coop_percent\": 9.013163010999918}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 85.92110000000001, \"std_coop\": 9.367475277332126, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 85.92110000000001, \"std_coop_percent\": 9.367475277332126}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 84.13086, \"std_coop\": 10.347217589146513, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 84.13086, \"std_coop_percent\": 10.347217589146513}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 78.41594, \"std_coop\": 13.074593222548154, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 78.41594, \"std_coop_percent\": 13.074593222548154}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 74.96332000000001, \"std_coop\": 13.066293302655518, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 74.96332000000001, \"std_coop_percent\": 13.066293302655518}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 64.35798, \"std_coop\": 15.218458978933096, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 64.35798, \"std_coop_percent\": 15.218458978933096}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 30.81354, \"std_coop\": 8.27814000899788, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 30.81354, \"std_coop_percent\": 8.27814000899788}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 21.60942, \"std_coop\": 7.628190038861094, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 21.60942, \"std_coop_percent\": 7.628190038861094}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.63486, \"std_coop\": 2.5414555367556844, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 92.63486, \"std_coop_percent\": 2.5414555367556844}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.42178, \"std_coop\": 2.4165395759310035, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 92.42178, \"std_coop_percent\": 2.4165395759310035}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 91.41596, \"std_coop\": 5.128617106680782, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.41596, \"std_coop_percent\": 5.128617106680782}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 88.34062, \"std_coop\": 9.486175414544583, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 88.34062, \"std_coop_percent\": 9.486175414544583}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 87.44434, \"std_coop\": 9.122442969905796, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 87.44434, \"std_coop_percent\": 9.122442969905796}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 84.35611999999999, \"std_coop\": 10.894049981788882, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 84.35611999999999, \"std_coop_percent\": 10.894049981788882}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 83.53792, \"std_coop\": 11.908531025157673, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 83.53792, \"std_coop_percent\": 11.908531025157673}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 76.46188000000001, \"std_coop\": 14.077202955364772, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 76.46188000000001, \"std_coop_percent\": 14.077202955364772}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 68.721, \"std_coop\": 13.914101538822157, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 68.721, \"std_coop_percent\": 13.914101538822157}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 46.475739999999995, \"std_coop\": 13.501462287863943, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 46.475739999999995, \"std_coop_percent\": 13.501462287863943}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 37.38422, \"std_coop\": 12.130863687625673, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 37.38422, \"std_coop_percent\": 12.130863687625673}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.0, \"is_base\": false, \"avg_coop\": 92.95046, \"std_coop\": 2.4367493838291696, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.95046, \"std_coop_percent\": 2.4367493838291696}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.1, \"is_base\": false, \"avg_coop\": 92.99202, \"std_coop\": 1.3025976165386752, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.99202, \"std_coop_percent\": 1.3025976165386752}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.2, \"is_base\": false, \"avg_coop\": 93.26469999999999, \"std_coop\": 1.031782037772216, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 93.26469999999999, \"std_coop_percent\": 1.031782037772216}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.3, \"is_base\": false, \"avg_coop\": 92.65343999999999, \"std_coop\": 2.890497225498106, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.65343999999999, \"std_coop_percent\": 2.890497225498106}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.4, \"is_base\": false, \"avg_coop\": 92.61858000000001, \"std_coop\": 1.809397172022347, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.61858000000001, \"std_coop_percent\": 1.809397172022347}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.5, \"is_base\": false, \"avg_coop\": 92.06914, \"std_coop\": 2.797082729617867, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 92.06914, \"std_coop_percent\": 2.797082729617867}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.6, \"is_base\": false, \"avg_coop\": 90.94066000000001, \"std_coop\": 5.969414946241231, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 90.94066000000001, \"std_coop_percent\": 5.969414946241231}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.7, \"is_base\": false, \"avg_coop\": 91.5649, \"std_coop\": 4.339526435415907, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 91.5649, \"std_coop_percent\": 4.339526435415907}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.8, \"is_base\": false, \"avg_coop\": 91.96763999999999, \"std_coop\": 4.861737619831168, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 91.96763999999999, \"std_coop_percent\": 4.861737619831168}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 0.9, \"is_base\": false, \"avg_coop\": 91.161, \"std_coop\": 6.2390210214522, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 91.161, \"std_coop_percent\": 6.2390210214522}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 88.11525999999999, \"std_coop\": 15.803100278122901, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 88.11525999999999, \"std_coop_percent\": 15.803100278122901}], \"data-ceb3261634142d67a582295fbae5ab87\": [{\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"gamma_center\": 1.0, \"is_base\": true, \"avg_coop\": 93.34371999999999, \"std_coop\": 0.89741247177081, \"DNF\": \"(A & R) | (~A & ~R)\", \"avg_coop_percent\": 93.34371999999999, \"std_coop_percent\": 0.89741247177081}, {\"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 21.301260000000003, \"std_coop\": 6.315114010992733, \"DNF\": \"(A & E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 21.301260000000003, \"std_coop_percent\": 6.315114010992733}, {\"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 90.72412, \"std_coop\": 7.179876468836712, \"DNF\": \"(A & R) | (~E & ~R)\", \"avg_coop_percent\": 90.72412, \"std_coop_percent\": 7.179876468836712}, {\"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 36.66792, \"std_coop\": 12.834894914367517, \"DNF\": \"(A & E & R) | (~E & ~R)\", \"avg_coop_percent\": 36.66792, \"std_coop_percent\": 12.834894914367517}, {\"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.41884, \"std_coop\": 0.2804854654461271, \"DNF\": \"(A & R) | (E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.41884, \"std_coop_percent\": 0.2804854654461271}, {\"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.46212, \"std_coop\": 0.32577259127263897, \"DNF\": \"(E & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 5.46212, \"std_coop_percent\": 0.32577259127263897}, {\"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.388780000000001, \"std_coop\": 0.28310402573569154, \"DNF\": \"(E & R) | (A & ~E) | (~E & ~R)\", \"avg_coop_percent\": 5.388780000000001, \"std_coop_percent\": 0.28310402573569154}, {\"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 5.38526, \"std_coop\": 0.26446247448014853, \"DNF\": \"(E & R) | (~E & ~R)\", \"avg_coop_percent\": 5.38526, \"std_coop_percent\": 0.26446247448014853}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 90.58912000000001, \"std_coop\": 4.424054838018617, \"DNF\": \"(A & E & R) | (~A & ~R)\", \"avg_coop_percent\": 90.58912000000001, \"std_coop_percent\": 4.424054838018617}, {\"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 91.12549999999999, \"std_coop\": 5.151091278277147, \"DNF\": \"(A & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 91.12549999999999, \"std_coop_percent\": 5.151091278277147}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 79.1816, \"std_coop\": 29.167665660481514, \"DNF\": \"(A & E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 79.1816, \"std_coop_percent\": 29.167665660481514}, {\"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 89.33404, \"std_coop\": 7.765522779516111, \"DNF\": \"(A & R) | (E & ~A) | (~A & ~R)\", \"avg_coop_percent\": 89.33404, \"std_coop_percent\": 7.765522779516111}, {\"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 88.95024, \"std_coop\": 11.117476449009716, \"DNF\": \"(E & R) | (~A & ~R)\", \"avg_coop_percent\": 88.95024, \"std_coop_percent\": 11.117476449009716}, {\"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 21.60942, \"std_coop\": 7.628190038861094, \"DNF\": \"(E & R) | (A & ~E) | (~A & ~R)\", \"avg_coop_percent\": 21.60942, \"std_coop_percent\": 7.628190038861094}, {\"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 37.38422, \"std_coop\": 12.130863687625673, \"DNF\": \"(E & R) | (~A & ~R) | (~E & ~R)\", \"avg_coop_percent\": 37.38422, \"std_coop_percent\": 12.130863687625673}, {\"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"gamma_center\": 1.0, \"is_base\": false, \"avg_coop\": 88.11525999999999, \"std_coop\": 15.803100278122901, \"DNF\": \"(A & R) | (~A & ~E & ~R)\", \"avg_coop_percent\": 88.11525999999999, \"std_coop_percent\": 15.803100278122901}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick norm\n",
    "chosen_norm = \"SternJudging\"\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "norm_df[\"is_base\"] = norm_df[\"variant_id\"].str.endswith(\"_v1\")\n",
    "\n",
    "# If your results use a different name (e.g., \"gamma_gaussian_n\"),\n",
    "# rename it once so plots are consistent:\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Aggregate per variant & gamma, carry DNF info (constant per variant)\n",
    "agg_df = (\n",
    "    norm_df\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\", \"gamma_center\", \"is_base\"], as_index=False)\n",
    "    .agg(\n",
    "        avg_coop=(\"average_cooperation\", \"mean\"),\n",
    "        std_coop=(\"average_cooperation\", \"std\"),\n",
    "        DNF=(\"DNF\", \"first\")\n",
    "    )\n",
    "    .sort_values([\"variant_id\", \"gamma_center\"])\n",
    ")\n",
    "\n",
    "# Make a percent-friendly copy\n",
    "plot_df = agg_df.copy()\n",
    "\n",
    "# If avg_coop is in [0,1], convert to %; if already 0â€“100, keep as-is\n",
    "def to_percent(col):\n",
    "    arr = col.to_numpy(dtype=float)\n",
    "    # heuristic: if most values â‰¤ 1, treat as proportions\n",
    "    needs_scale = (np.nanmean(arr <= 1.0) > 0.5)\n",
    "    return arr * 100.0 if needs_scale else arr\n",
    "\n",
    "plot_df[\"avg_coop_percent\"] = to_percent(plot_df[\"avg_coop\"])\n",
    "plot_df[\"std_coop_percent\"] = to_percent(plot_df[\"std_coop\"])\n",
    "\n",
    "# Base lines (no selections; color by DNF_literals; dashed if base)\n",
    "line = alt.Chart(plot_df).mark_line().encode(\n",
    "    x=alt.X(\"gamma_center:Q\", title=\"Gamma value\"),\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            title=\"Average Cooperation (%)\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    color=alt.Color(\"Emotion_Leniency:O\",\n",
    "                    title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"bluepurple\")),\n",
    "    strokeDash=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value([5, 5]),    # dashed for base\n",
    "        alt.value([1, 0])     # solid otherwise\n",
    "    ),\n",
    "    strokeWidth=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value(8),\n",
    "        alt.value(2)\n",
    "    ),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant\"),\n",
    "        alt.Tooltip(\"gamma_center:Q\", title=\"Gamma\"),\n",
    "        alt.Tooltip(\"avg_coop_percent:Q\", title=\"Mean coop (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"std_coop_percent:Q\", title=\"Std (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"is_base:N\", title=\"Base?\")\n",
    "    ],\n",
    "    detail=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "# Optional: end-of-line labels (still no interactivity)\n",
    "endpoints = (\n",
    "    plot_df.sort_values([\"variant_id\", \"gamma_center\"])\n",
    "           .groupby(\"variant_id\", as_index=False)\n",
    "           .tail(1)\n",
    ")\n",
    "\n",
    "labels = alt.Chart(endpoints).mark_text(\n",
    "    dx=5, align=\"left\", baseline=\"middle\"\n",
    ").encode(\n",
    "    x=\"gamma_center:Q\",\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    text=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "chart = (line + labels).properties(\n",
    "    width=700, height=420,\n",
    "    title=f\"Performance of {chosen_norm} Variants (color = Emotion Leniency; dashed = base)\"\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b541490f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gamma_center</th>\n",
       "      <th>variant_id</th>\n",
       "      <th>gamma 0.0</th>\n",
       "      <th>gamma 0.1</th>\n",
       "      <th>gamma 0.2</th>\n",
       "      <th>gamma 0.3</th>\n",
       "      <th>gamma 0.4</th>\n",
       "      <th>gamma 0.5</th>\n",
       "      <th>gamma 0.6</th>\n",
       "      <th>gamma 0.7</th>\n",
       "      <th>gamma 0.8</th>\n",
       "      <th>gamma 0.9</th>\n",
       "      <th>gamma 1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stern_Judging_v1</td>\n",
       "      <td>93.28864</td>\n",
       "      <td>93.26890</td>\n",
       "      <td>93.47752</td>\n",
       "      <td>92.83250</td>\n",
       "      <td>92.90152</td>\n",
       "      <td>93.19750</td>\n",
       "      <td>93.09698</td>\n",
       "      <td>93.25764</td>\n",
       "      <td>93.08008</td>\n",
       "      <td>93.04866</td>\n",
       "      <td>93.34372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stern_Judging_v10</td>\n",
       "      <td>93.33162</td>\n",
       "      <td>92.14812</td>\n",
       "      <td>90.55076</td>\n",
       "      <td>88.20090</td>\n",
       "      <td>83.78480</td>\n",
       "      <td>79.97648</td>\n",
       "      <td>80.33770</td>\n",
       "      <td>73.20560</td>\n",
       "      <td>62.97154</td>\n",
       "      <td>27.80382</td>\n",
       "      <td>21.30126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stern_Judging_v11</td>\n",
       "      <td>93.35224</td>\n",
       "      <td>92.55862</td>\n",
       "      <td>92.17434</td>\n",
       "      <td>90.76350</td>\n",
       "      <td>92.16544</td>\n",
       "      <td>92.27366</td>\n",
       "      <td>92.02842</td>\n",
       "      <td>92.09494</td>\n",
       "      <td>91.76820</td>\n",
       "      <td>90.48394</td>\n",
       "      <td>90.72412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stern_Judging_v12</td>\n",
       "      <td>93.14702</td>\n",
       "      <td>91.59006</td>\n",
       "      <td>90.24360</td>\n",
       "      <td>89.42606</td>\n",
       "      <td>85.20590</td>\n",
       "      <td>84.27042</td>\n",
       "      <td>86.59692</td>\n",
       "      <td>81.48238</td>\n",
       "      <td>73.90780</td>\n",
       "      <td>47.14592</td>\n",
       "      <td>36.66792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stern_Judging_v13</td>\n",
       "      <td>93.28780</td>\n",
       "      <td>92.97808</td>\n",
       "      <td>93.00762</td>\n",
       "      <td>92.03416</td>\n",
       "      <td>90.85938</td>\n",
       "      <td>85.99830</td>\n",
       "      <td>71.79606</td>\n",
       "      <td>23.99790</td>\n",
       "      <td>6.45368</td>\n",
       "      <td>5.61582</td>\n",
       "      <td>5.41884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stern_Judging_v14</td>\n",
       "      <td>92.87316</td>\n",
       "      <td>91.79338</td>\n",
       "      <td>89.94936</td>\n",
       "      <td>88.82904</td>\n",
       "      <td>85.59362</td>\n",
       "      <td>72.08164</td>\n",
       "      <td>57.18136</td>\n",
       "      <td>24.64146</td>\n",
       "      <td>6.17852</td>\n",
       "      <td>5.80872</td>\n",
       "      <td>5.46212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stern_Judging_v15</td>\n",
       "      <td>92.76920</td>\n",
       "      <td>92.70026</td>\n",
       "      <td>90.73910</td>\n",
       "      <td>87.63084</td>\n",
       "      <td>81.96890</td>\n",
       "      <td>77.00726</td>\n",
       "      <td>53.06528</td>\n",
       "      <td>26.19612</td>\n",
       "      <td>7.03662</td>\n",
       "      <td>5.64558</td>\n",
       "      <td>5.38878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stern_Judging_v16</td>\n",
       "      <td>93.11822</td>\n",
       "      <td>91.25736</td>\n",
       "      <td>90.86474</td>\n",
       "      <td>80.59694</td>\n",
       "      <td>72.66954</td>\n",
       "      <td>51.16400</td>\n",
       "      <td>26.50390</td>\n",
       "      <td>10.14328</td>\n",
       "      <td>6.17164</td>\n",
       "      <td>5.48934</td>\n",
       "      <td>5.38526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stern_Judging_v2</td>\n",
       "      <td>93.03454</td>\n",
       "      <td>92.67144</td>\n",
       "      <td>92.13582</td>\n",
       "      <td>91.89320</td>\n",
       "      <td>91.25692</td>\n",
       "      <td>90.92680</td>\n",
       "      <td>89.79384</td>\n",
       "      <td>91.10638</td>\n",
       "      <td>90.40572</td>\n",
       "      <td>90.30824</td>\n",
       "      <td>90.58912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stern_Judging_v3</td>\n",
       "      <td>93.39326</td>\n",
       "      <td>92.60914</td>\n",
       "      <td>91.73056</td>\n",
       "      <td>91.41912</td>\n",
       "      <td>91.90674</td>\n",
       "      <td>91.41670</td>\n",
       "      <td>91.62090</td>\n",
       "      <td>90.92022</td>\n",
       "      <td>86.69258</td>\n",
       "      <td>90.44260</td>\n",
       "      <td>91.12550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stern_Judging_v4</td>\n",
       "      <td>93.27826</td>\n",
       "      <td>91.93066</td>\n",
       "      <td>91.90690</td>\n",
       "      <td>91.57438</td>\n",
       "      <td>87.34582</td>\n",
       "      <td>87.51540</td>\n",
       "      <td>83.89002</td>\n",
       "      <td>81.73788</td>\n",
       "      <td>85.78712</td>\n",
       "      <td>85.74058</td>\n",
       "      <td>79.18160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Stern_Judging_v5</td>\n",
       "      <td>92.92218</td>\n",
       "      <td>93.17256</td>\n",
       "      <td>93.02960</td>\n",
       "      <td>93.08588</td>\n",
       "      <td>92.27668</td>\n",
       "      <td>91.64882</td>\n",
       "      <td>92.16078</td>\n",
       "      <td>91.14142</td>\n",
       "      <td>91.51386</td>\n",
       "      <td>92.10706</td>\n",
       "      <td>89.33404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stern_Judging_v6</td>\n",
       "      <td>93.27758</td>\n",
       "      <td>92.75430</td>\n",
       "      <td>92.24432</td>\n",
       "      <td>92.41026</td>\n",
       "      <td>92.67386</td>\n",
       "      <td>92.10362</td>\n",
       "      <td>92.77178</td>\n",
       "      <td>91.32214</td>\n",
       "      <td>91.72016</td>\n",
       "      <td>90.18094</td>\n",
       "      <td>88.95024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stern_Judging_v7</td>\n",
       "      <td>92.94562</td>\n",
       "      <td>92.78266</td>\n",
       "      <td>91.37846</td>\n",
       "      <td>86.40892</td>\n",
       "      <td>85.92110</td>\n",
       "      <td>84.13086</td>\n",
       "      <td>78.41594</td>\n",
       "      <td>74.96332</td>\n",
       "      <td>64.35798</td>\n",
       "      <td>30.81354</td>\n",
       "      <td>21.60942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stern_Judging_v8</td>\n",
       "      <td>92.63486</td>\n",
       "      <td>92.42178</td>\n",
       "      <td>91.41596</td>\n",
       "      <td>88.34062</td>\n",
       "      <td>87.44434</td>\n",
       "      <td>84.35612</td>\n",
       "      <td>83.53792</td>\n",
       "      <td>76.46188</td>\n",
       "      <td>68.72100</td>\n",
       "      <td>46.47574</td>\n",
       "      <td>37.38422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stern_Judging_v9</td>\n",
       "      <td>92.95046</td>\n",
       "      <td>92.99202</td>\n",
       "      <td>93.26470</td>\n",
       "      <td>92.65344</td>\n",
       "      <td>92.61858</td>\n",
       "      <td>92.06914</td>\n",
       "      <td>90.94066</td>\n",
       "      <td>91.56490</td>\n",
       "      <td>91.96764</td>\n",
       "      <td>91.16100</td>\n",
       "      <td>88.11526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gamma_center         variant_id  gamma 0.0  gamma 0.1  gamma 0.2  gamma 0.3  \\\n",
       "0              Stern_Judging_v1   93.28864   93.26890   93.47752   92.83250   \n",
       "1             Stern_Judging_v10   93.33162   92.14812   90.55076   88.20090   \n",
       "2             Stern_Judging_v11   93.35224   92.55862   92.17434   90.76350   \n",
       "3             Stern_Judging_v12   93.14702   91.59006   90.24360   89.42606   \n",
       "4             Stern_Judging_v13   93.28780   92.97808   93.00762   92.03416   \n",
       "5             Stern_Judging_v14   92.87316   91.79338   89.94936   88.82904   \n",
       "6             Stern_Judging_v15   92.76920   92.70026   90.73910   87.63084   \n",
       "7             Stern_Judging_v16   93.11822   91.25736   90.86474   80.59694   \n",
       "8              Stern_Judging_v2   93.03454   92.67144   92.13582   91.89320   \n",
       "9              Stern_Judging_v3   93.39326   92.60914   91.73056   91.41912   \n",
       "10             Stern_Judging_v4   93.27826   91.93066   91.90690   91.57438   \n",
       "11             Stern_Judging_v5   92.92218   93.17256   93.02960   93.08588   \n",
       "12             Stern_Judging_v6   93.27758   92.75430   92.24432   92.41026   \n",
       "13             Stern_Judging_v7   92.94562   92.78266   91.37846   86.40892   \n",
       "14             Stern_Judging_v8   92.63486   92.42178   91.41596   88.34062   \n",
       "15             Stern_Judging_v9   92.95046   92.99202   93.26470   92.65344   \n",
       "\n",
       "gamma_center  gamma 0.4  gamma 0.5  gamma 0.6  gamma 0.7  gamma 0.8  \\\n",
       "0              92.90152   93.19750   93.09698   93.25764   93.08008   \n",
       "1              83.78480   79.97648   80.33770   73.20560   62.97154   \n",
       "2              92.16544   92.27366   92.02842   92.09494   91.76820   \n",
       "3              85.20590   84.27042   86.59692   81.48238   73.90780   \n",
       "4              90.85938   85.99830   71.79606   23.99790    6.45368   \n",
       "5              85.59362   72.08164   57.18136   24.64146    6.17852   \n",
       "6              81.96890   77.00726   53.06528   26.19612    7.03662   \n",
       "7              72.66954   51.16400   26.50390   10.14328    6.17164   \n",
       "8              91.25692   90.92680   89.79384   91.10638   90.40572   \n",
       "9              91.90674   91.41670   91.62090   90.92022   86.69258   \n",
       "10             87.34582   87.51540   83.89002   81.73788   85.78712   \n",
       "11             92.27668   91.64882   92.16078   91.14142   91.51386   \n",
       "12             92.67386   92.10362   92.77178   91.32214   91.72016   \n",
       "13             85.92110   84.13086   78.41594   74.96332   64.35798   \n",
       "14             87.44434   84.35612   83.53792   76.46188   68.72100   \n",
       "15             92.61858   92.06914   90.94066   91.56490   91.96764   \n",
       "\n",
       "gamma_center  gamma 0.9  gamma 1.0  \n",
       "0              93.04866   93.34372  \n",
       "1              27.80382   21.30126  \n",
       "2              90.48394   90.72412  \n",
       "3              47.14592   36.66792  \n",
       "4               5.61582    5.41884  \n",
       "5               5.80872    5.46212  \n",
       "6               5.64558    5.38878  \n",
       "7               5.48934    5.38526  \n",
       "8              90.30824   90.58912  \n",
       "9              90.44260   91.12550  \n",
       "10             85.74058   79.18160  \n",
       "11             92.10706   89.33404  \n",
       "12             90.18094   88.95024  \n",
       "13             30.81354   21.60942  \n",
       "14             46.47574   37.38422  \n",
       "15             91.16100   88.11526  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pivot: rows = variant_id, cols = gamma_center\n",
    "pivot_df = plot_df.pivot_table(\n",
    "    index=\"variant_id\",\n",
    "    columns=\"gamma_center\",\n",
    "    values=\"avg_coop_percent\",\n",
    "    aggfunc=\"mean\"   # though already averaged\n",
    ").reset_index()\n",
    "\n",
    "# Optional: rename gamma columns for clarity (e.g., \"gamma 0.0\")\n",
    "pivot_df = pivot_df.rename(\n",
    "    columns={g: f\"gamma {g}\" for g in pivot_df.columns if isinstance(g, (int, float))}\n",
    ")\n",
    "\n",
    "# Check result\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca4dca",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02112145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f2b75b1a6f474c2ca17affe273b592cc\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f2b75b1a6f474c2ca17affe273b592cc\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f2b75b1a6f474c2ca17affe273b592cc\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d751713988987e9331980363e24189ce\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"max_mean_coop\", \"scale\": {\"domain\": [0, 100], \"scheme\": \"viridis\"}, \"title\": \"Max mean cooperation (%)\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"gamma_center\", \"title\": \"\\u03b3\", \"type\": \"ordinal\"}, {\"field\": \"DNF_literals\", \"title\": \"# literals\", \"type\": \"ordinal\"}, {\"field\": \"max_mean_coop\", \"format\": \".2f\", \"title\": \"max mean coop (%)\", \"type\": \"quantitative\"}, {\"field\": \"best_variant\", \"title\": \"Best variant ID\", \"type\": \"nominal\"}, {\"field\": \"n\", \"title\": \"# variants in bin\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"gamma_center\", \"sort\": [\"0.0\", \"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\", \"0.7\", \"0.8\", \"0.9\", \"1.0\"], \"title\": \"\\u03b3\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"DNF_literals\", \"sort\": \"descending\", \"title\": \"DNF literals\", \"type\": \"ordinal\"}}, \"height\": 350, \"title\": \"SternJudging \\u2014 Max *Mean* Cooperation by \\u03b3 \\u00d7 DNF Complexity\", \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-d751713988987e9331980363e24189ce\": []}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "chosen_norm = \"SternJudging\"\n",
    "\n",
    "# Filter to chosen norm\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Ensure consistent gamma column name\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# ---- STEP 1: average cooperation per variant (across runs) ----\n",
    "variant_avg = (\n",
    "    norm_df\n",
    "    .groupby([\"norm\", \"variant_id\", \"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# ---- STEP 2: for each (Î³, DNF_literals), take the variant with the highest average ----\n",
    "variant_avg_sorted = variant_avg.sort_values(\"mean_coop\", ascending=False)\n",
    "agg = (\n",
    "    variant_avg_sorted\n",
    "    .groupby([\"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(\n",
    "        max_mean_coop=(\"mean_coop\", \"max\"),\n",
    "        best_variant=(\"variant_id\", \"first\"),\n",
    "        n=(\"variant_id\", \"nunique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "agg[\"DNF_literals\"] = agg[\"DNF_literals\"].astype(int)\n",
    "\n",
    "# Convert to percentage if needed\n",
    "if agg[\"max_mean_coop\"].max() <= 1:\n",
    "    agg[\"max_mean_coop\"] *= 100\n",
    "\n",
    "# ---- STEP 3: Visualization ----\n",
    "heat = alt.Chart(agg).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\",\n",
    "            sort=[f\"{x:.1f}\" for x in valid_gammas]),\n",
    "    y=alt.Y(\"DNF_literals:O\", title=\"DNF literals\", sort=\"descending\"),\n",
    "    color=alt.Color(\"max_mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"DNF_literals:O\", title=\"# literals\"),\n",
    "        alt.Tooltip(\"max_mean_coop:Q\", title=\"max mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"best_variant:N\", title=\"Best variant ID\"),\n",
    "        alt.Tooltip(\"n:Q\", title=\"# variants in bin\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=450, height=350,\n",
    "    title=f\"{chosen_norm} â€” Max *Mean* Cooperation by Î³ Ã— DNF Complexity\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbb43276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f2836a917b0f4fcba2ef514ccd250713\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f2836a917b0f4fcba2ef514ccd250713\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f2836a917b0f4fcba2ef514ccd250713\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 14}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 120}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"Emotion Leniency\", \"type\": \"ordinal\"}, \"tooltip\": [{\"field\": \"DNF_literals\", \"title\": \"DNF literals\", \"type\": \"quantitative\"}, {\"field\": \"variant_id\", \"title\": \"Variant ID\", \"type\": \"nominal\"}, {\"field\": \"mean_coop_pct\", \"format\": \".2f\", \"title\": \"Mean coop (%)\", \"type\": \"quantitative\"}, {\"field\": \"runs\", \"title\": \"# runs\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"title\": \"Leniency\", \"type\": \"ordinal\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF complexity (number of literals)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop_pct\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Max mean cooperation (%)\", \"type\": \"quantitative\"}}, \"height\": 350, \"title\": \"Best variant per complexity at \\u03b3 = 1\", \"width\": 600}, {\"mark\": {\"type\": \"line\", \"color\": \"red\", \"strokeDash\": [5, 5]}, \"encoding\": {\"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop_pct\", \"type\": \"quantitative\"}}, \"transform\": [{\"on\": \"DNF_literals\", \"regression\": \"mean_coop_pct\", \"method\": \"quad\"}]}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"dx\": 7, \"dy\": 0}, \"encoding\": {\"text\": {\"field\": \"variant_id\", \"type\": \"nominal\"}, \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF complexity (number of literals)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop_pct\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Max mean cooperation (%)\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-e23de45eca73aa4130d35c7a5340fc5b\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-e23de45eca73aa4130d35c7a5340fc5b\": [{\"variant_id\": \"Image_Scoring_v16\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 68.24152, \"runs\": 50, \"mean_coop_pct\": 68.24152}, {\"variant_id\": \"Simple_Standing_v1\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 55.91876, \"runs\": 50, \"mean_coop_pct\": 55.91876}, {\"variant_id\": \"Simple_Standing_v8\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 84.57525454545454, \"runs\": 55, \"mean_coop_pct\": 84.57525454545454}, {\"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.34371999999999, \"runs\": 50, \"mean_coop_pct\": 93.34371999999999}, {\"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 90.58912000000001, \"runs\": 50, \"mean_coop_pct\": 90.58912000000001}, {\"variant_id\": \"Simple_Standing_v3\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.40402, \"runs\": 50, \"mean_coop_pct\": 91.40402}, {\"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 79.1816, \"runs\": 50, \"mean_coop_pct\": 79.1816}, {\"variant_id\": \"Shunning_v12\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 61.99206, \"runs\": 50, \"mean_coop_pct\": 61.99206}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "#chosen_base_norm = \"SternJudging\"    # 0) choose base social norm\n",
    "fixed_gamma = 1                   # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# For a runnable example, let's assume merged_df is loaded here (e.g., from a CSV)\n",
    "# For the purpose of adding the regression, we'll proceed assuming 'merged_df' exists.\n",
    "#df = merged_df[merged_df[\"norm\"] == chosen_base_norm].copy()\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# ensure average_cooperation is numeric\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "          runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) For every DNF complexity, choose the variant with maximal mean cooperation ===\n",
    "# use idxmax to get the variant row with the highest mean_coop\n",
    "idx = variant_avg.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()\n",
    "best_per_complexity = variant_avg.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# Optional: sort by complexity numeric ascending\n",
    "best_per_complexity[\"DNF_literals\"] = best_per_complexity[\"DNF_literals\"].astype(int)\n",
    "best_per_complexity = best_per_complexity.sort_values(\"DNF_literals\")\n",
    "\n",
    "# === ASSUMED best_per_complexity DATA STRUCTURE FOR REGRESSION ===\n",
    "# best_per_complexity = pd.DataFrame({\n",
    "#     'DNF_literals': [1, 2, 3, 4, 5],\n",
    "#     'mean_coop_pct': [50.0, 65.0, 75.0, 70.0, 80.0],\n",
    "#     'Emotion_Leniency': [0.1, 0.2, 0.3, 0.2, 0.4],\n",
    "#     'variant_id': ['v1', 'v2', 'v3', 'v4', 'v5'],\n",
    "#     'runs': [10, 10, 10, 10, 10]\n",
    "# })\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (max among variants per complexity) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Max mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(best_per_complexity).mark_circle(size=120).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    color=alt.Color(\"Emotion_Leniency:O\", title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\")),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"Best variant per complexity at Î³ = {fixed_gamma}\"\n",
    ")\n",
    "\n",
    "# === 5) Add Regression Line (Linear) - CORRECTED ===\n",
    "# We use transform_regression() to calculate the line\n",
    "# and then mark_line() to draw it.\n",
    "regression_line = alt.Chart(best_per_complexity).transform_regression(\n",
    "    'DNF_literals',        # The X variable\n",
    "    'mean_coop_pct',       # The Y variable\n",
    "    method='quad'        # Specify method (linear, poly, etc.)\n",
    ").mark_line(\n",
    "    color='red',           # Style the line\n",
    "    strokeDash=[5, 5]      # Make it dashed\n",
    ").encode(\n",
    "    x=alt.X('DNF_literals:Q'),  # Re-encode X for the line layer\n",
    "    y=alt.Y('mean_coop_pct:Q')  # Re-encode Y for the line layer\n",
    ")\n",
    "\n",
    "# Add text labels (optional) next to points showing variant short name\n",
    "labels = alt.Chart(best_per_complexity).mark_text(dx=7, dy=0, align=\"left\").encode(\n",
    "    x=x_encoding,  # Use the quantitative encoding\n",
    "    y=y_encoding,  # Use the quantitative encoding\n",
    "    text=alt.Text(\"variant_id:N\"),\n",
    ")\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line + Labels ===\n",
    "chart_with_regression = (chart + regression_line + labels).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b296a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-98a38d52a294417fad7e7525309a64e1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-98a38d52a294417fad7e7525309a64e1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-98a38d52a294417fad7e7525309a64e1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"title\": {\"fontSize\": 14}}, \"data\": {\"name\": \"data-8e83da60279f749ea28dfc66f2a019f5\"}, \"mark\": {\"type\": \"circle\", \"opacity\": 0.7, \"size\": 80}, \"encoding\": {\"color\": {\"field\": \"norm\", \"title\": \"Social Norm\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"norm\", \"title\": \"Norm\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"title\": \"DNF literals\", \"type\": \"quantitative\"}, {\"field\": \"variant_id\", \"title\": \"Variant ID\", \"type\": \"nominal\"}, {\"field\": \"mean_coop_pct\", \"format\": \".2f\", \"title\": \"Mean coop (%)\", \"type\": \"quantitative\"}, {\"field\": \"runs\", \"title\": \"# runs\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"title\": \"Leniency\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF complexity (number of literals)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop_pct\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean cooperation (%)\", \"type\": \"quantitative\"}}, \"height\": 350, \"selection\": {\"selector003\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"All Norms \\u2014 All variants at \\u03b3 = 0.8\", \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-8e83da60279f749ea28dfc66f2a019f5\": [{\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v1\", \"DNF_literals\": 1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 31.20498, \"runs\": 50, \"mean_coop_pct\": 31.20498}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v16\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 72.11314, \"runs\": 50, \"mean_coop_pct\": 72.11314}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v6\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 56.40424, \"runs\": 50, \"mean_coop_pct\": 56.40424}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v1\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 56.29818, \"runs\": 50, \"mean_coop_pct\": 56.29818}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v13\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 43.99124, \"runs\": 50, \"mean_coop_pct\": 43.99124}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v6\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.45038, \"runs\": 50, \"mean_coop_pct\": 4.45038}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v4\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.75754, \"runs\": 50, \"mean_coop_pct\": 25.75754}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v1\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 4.39128, \"runs\": 50, \"mean_coop_pct\": 4.39128}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v5\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 27.98618, \"runs\": 50, \"mean_coop_pct\": 27.98618}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v8\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.39127272727272, \"runs\": 55, \"mean_coop_pct\": 75.39127272727272}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v9\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 37.36498, \"runs\": 50, \"mean_coop_pct\": 37.36498}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v2\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.4217, \"runs\": 50, \"mean_coop_pct\": 4.4217}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v9\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 23.73218, \"runs\": 50, \"mean_coop_pct\": 23.73218}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v2\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 57.30862, \"runs\": 50, \"mean_coop_pct\": 57.30862}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v5\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 7.87862, \"runs\": 50, \"mean_coop_pct\": 7.87862}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v14\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 62.095, \"runs\": 50, \"mean_coop_pct\": 62.095}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v15\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 55.580439999999996, \"runs\": 50, \"mean_coop_pct\": 55.580439999999996}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v8\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 10.700740000000001, \"runs\": 50, \"mean_coop_pct\": 10.700740000000001}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v6\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 91.72015999999999, \"runs\": 50, \"mean_coop_pct\": 91.72015999999999}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v11\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.40594545454546, \"runs\": 55, \"mean_coop_pct\": 73.40594545454546}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v10\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.10504, \"runs\": 50, \"mean_coop_pct\": 6.10504}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v12\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 69.53678, \"runs\": 50, \"mean_coop_pct\": 69.53678}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v7\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.838653061224489, \"runs\": 49, \"mean_coop_pct\": 7.838653061224489}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v5\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.410872340425532, \"runs\": 47, \"mean_coop_pct\": 4.410872340425532}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v2\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 19.40556, \"runs\": 50, \"mean_coop_pct\": 19.40556}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v3\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 44.261854166666666, \"runs\": 48, \"mean_coop_pct\": 44.261854166666666}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v3\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 35.28786, \"runs\": 50, \"mean_coop_pct\": 35.28786}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v1\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.08008, \"runs\": 50, \"mean_coop_pct\": 93.08008}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v11\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 91.7682, \"runs\": 50, \"mean_coop_pct\": 91.7682}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v14\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 74.8976, \"runs\": 50, \"mean_coop_pct\": 74.8976}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v13\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 55.03148, \"runs\": 50, \"mean_coop_pct\": 55.03148}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v4\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.6672, \"runs\": 50, \"mean_coop_pct\": 82.6672}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v16\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 6.17164, \"runs\": 50, \"mean_coop_pct\": 6.17164}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v6\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.68786, \"runs\": 50, \"mean_coop_pct\": 7.68786}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v7\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.64792, \"runs\": 50, \"mean_coop_pct\": 73.64792}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v12\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 73.9078, \"runs\": 50, \"mean_coop_pct\": 73.9078}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v2\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 90.40572, \"runs\": 50, \"mean_coop_pct\": 90.40572}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v14\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 6.17852, \"runs\": 50, \"mean_coop_pct\": 6.17852}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v9\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 88.03936734693877, \"runs\": 49, \"mean_coop_pct\": 88.03936734693877}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v9\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.96763999999999, \"runs\": 50, \"mean_coop_pct\": 91.96763999999999}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v13\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 5.59348, \"runs\": 50, \"mean_coop_pct\": 5.59348}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v12\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.458326530612243, \"runs\": 49, \"mean_coop_pct\": 8.458326530612243}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v8\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 7.46044, \"runs\": 50, \"mean_coop_pct\": 7.46044}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v15\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 7.03662, \"runs\": 50, \"mean_coop_pct\": 7.03662}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v3\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 86.69257999999999, \"runs\": 50, \"mean_coop_pct\": 86.69257999999999}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v5\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.51386000000001, \"runs\": 50, \"mean_coop_pct\": 91.51386000000001}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v15\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 48.21604, \"runs\": 50, \"mean_coop_pct\": 48.21604}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v10\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 62.971540000000005, \"runs\": 50, \"mean_coop_pct\": 62.971540000000005}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v4\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 23.90464, \"runs\": 50, \"mean_coop_pct\": 23.90464}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v10\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 80.50202, \"runs\": 50, \"mean_coop_pct\": 80.50202}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v8\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 68.721, \"runs\": 50, \"mean_coop_pct\": 68.721}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v7\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 64.35798, \"runs\": 50, \"mean_coop_pct\": 64.35798}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v3\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 78.7709, \"runs\": 50, \"mean_coop_pct\": 78.7709}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v14\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.365, \"runs\": 50, \"mean_coop_pct\": 5.365}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v10\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 72.37048, \"runs\": 50, \"mean_coop_pct\": 72.37048}, {\"norm\": \"ImageScoring\", \"variant_id\": \"Image_Scoring_v7\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 8.8934, \"runs\": 50, \"mean_coop_pct\": 8.8934}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v4\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 85.78712, \"runs\": 50, \"mean_coop_pct\": 85.78712}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v16\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 5.7991399999999995, \"runs\": 50, \"mean_coop_pct\": 5.7991399999999995}, {\"norm\": \"SternJudging\", \"variant_id\": \"Stern_Judging_v13\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.45368, \"runs\": 50, \"mean_coop_pct\": 6.45368}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v16\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 66.61574, \"runs\": 50, \"mean_coop_pct\": 66.61574}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v11\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 46.966319999999996, \"runs\": 50, \"mean_coop_pct\": 46.966319999999996}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v11\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 38.911120000000004, \"runs\": 50, \"mean_coop_pct\": 38.911120000000004}, {\"norm\": \"SimpleStanding\", \"variant_id\": \"Simple_Standing_v15\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 5.6045799999999995, \"runs\": 50, \"mean_coop_pct\": 5.6045799999999995}, {\"norm\": \"Shunning\", \"variant_id\": \"Shunning_v12\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 77.72358333333334, \"runs\": 24, \"mean_coop_pct\": 77.72358333333334}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "# chosen_base_norm = \"SternJudging\"    # 0) No longer filtering by a single norm\n",
    "fixed_gamma = 0.8                      # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# We use the full merged_df, as requested.\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# We add \"norm\" to the groupby so we can distinguish them in the plot\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"norm\", \"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "         runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if not variant_avg.empty and variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) Use all averaged variants (no 'best of' filter) ===\n",
    "# We are SKIPPING the step of choosing the maximal per complexity.\n",
    "# We will plot all variants from variant_avg.\n",
    "\n",
    "# Optional: ensure DNF_literals is int and sort\n",
    "if not variant_avg.empty:\n",
    "    variant_avg[\"DNF_literals\"] = variant_avg[\"DNF_literals\"].astype(int)\n",
    "    variant_avg = variant_avg.sort_values(\"DNF_literals\")\n",
    "else:\n",
    "    print(f\"Warning: No data found after filtering for gamma = {fixed_gamma}. Chart will be empty.\")\n",
    "\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (plotting ALL variants) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(variant_avg).mark_circle(size=80, opacity=0.7).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    # Color by norm to distinguish the data points\n",
    "    color=alt.Color(\"norm:N\", title=\"Social Norm\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"norm:N\", title=\"Norm\"),\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:Q\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"All Norms â€” All variants at Î³ = {fixed_gamma}\" # Updated title\n",
    ").interactive() # Add interactive zoom/pan\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line ===\n",
    "# The 'labels' chart was removed as it would be unreadable\n",
    "chart_with_regression = (chart ).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc67cc",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Emotion Leniency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0661296-2416-4720-9c4b-bb93a9fef8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-449c1da73c8b470788e803aca0e51ee5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-449c1da73c8b470788e803aca0e51ee5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-449c1da73c8b470788e803aca0e51ee5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-692e02c9cd8eb87b4887ce3402c4086a\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100], \"scheme\": \"viridis\"}, \"title\": \"Max mean cooperation (%)\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"gamma_center\", \"title\": \"\\u03b3\", \"type\": \"ordinal\"}, {\"field\": \"Emotion_Leniency\", \"title\": \"Leniency\", \"type\": \"ordinal\"}, {\"field\": \"variant_id\", \"title\": \"Top Variant\", \"type\": \"nominal\"}, {\"field\": \"mean_coop\", \"format\": \".2f\", \"title\": \"Mean coop (%)\", \"type\": \"quantitative\"}, {\"field\": \"sd_coop\", \"format\": \".2f\", \"title\": \"Std (%)\", \"type\": \"quantitative\"}, {\"field\": \"n_runs\", \"title\": \"# runs\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"gamma_center\", \"title\": \"\\u03b3\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Emotion_Leniency\", \"sort\": \"descending\", \"title\": \"Emotion Leniency\", \"type\": \"ordinal\"}}, \"height\": 350, \"title\": \"SternJudging \\u2014 Maximal Cooperation by \\u03b3 \\u00d7 Emotion Leniency\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-692e02c9cd8eb87b4887ce3402c4086a\": [{\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 0.0, \"mean_coop\": 93.11822000000001, \"sd_coop\": 1.9041862506443186, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 0.25, \"mean_coop\": 93.14702, \"sd_coop\": 2.0388122541703275, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 0.5, \"mean_coop\": 93.35224, \"sd_coop\": 0.8234064277780001, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v3\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 0.75, \"mean_coop\": 93.39326000000001, \"sd_coop\": 0.8501818487349477, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.28864, \"sd_coop\": 1.0400989505517133, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 91.25736, \"sd_coop\": 3.7916452180540112, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v15\", \"gamma_center\": 0.1, \"Emotion_Leniency\": 0.25, \"mean_coop\": 92.70026, \"sd_coop\": 2.0400322307377836, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v13\", \"gamma_center\": 0.1, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.97808, \"sd_coop\": 1.839201033723336, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v5\", \"gamma_center\": 0.1, \"Emotion_Leniency\": 0.75, \"mean_coop\": 93.17255999999999, \"sd_coop\": 1.3099260792354743, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.26889999999999, \"sd_coop\": 1.0359131286956855, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.2, \"Emotion_Leniency\": 0.0, \"mean_coop\": 90.86474, \"sd_coop\": 5.039298136301382, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v8\", \"gamma_center\": 0.2, \"Emotion_Leniency\": 0.25, \"mean_coop\": 91.41596, \"sd_coop\": 5.128617106680782, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v13\", \"gamma_center\": 0.2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 93.00762, \"sd_coop\": 1.152332840416363, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v9\", \"gamma_center\": 0.2, \"Emotion_Leniency\": 0.75, \"mean_coop\": 93.26469999999999, \"sd_coop\": 1.031782037772216, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.47752, \"sd_coop\": 0.18695653101669366, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.3, \"Emotion_Leniency\": 0.0, \"mean_coop\": 80.59694, \"sd_coop\": 20.59671645954019, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 89.42605999999999, \"sd_coop\": 7.02256978201465, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v6\", \"gamma_center\": 0.3, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.41026, \"sd_coop\": 3.2496061978683635, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v5\", \"gamma_center\": 0.3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 93.08588, \"sd_coop\": 1.4799631081998814, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.3, \"Emotion_Leniency\": 1.0, \"mean_coop\": 92.8325, \"sd_coop\": 3.1317599358696646, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 72.66954, \"sd_coop\": 31.969935092916682, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v8\", \"gamma_center\": 0.4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 87.44434, \"sd_coop\": 9.122442969905796, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v6\", \"gamma_center\": 0.4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.67386, \"sd_coop\": 2.2709546496608737, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v9\", \"gamma_center\": 0.4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.61858000000001, \"sd_coop\": 1.809397172022347, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 92.90152, \"sd_coop\": 2.779827393261413, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.0, \"mean_coop\": 51.163999999999994, \"sd_coop\": 40.417048136666686, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v8\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 84.35611999999999, \"sd_coop\": 10.894049981788882, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.27366, \"sd_coop\": 4.501405651707529, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v9\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.06914, \"sd_coop\": 2.797082729617867, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.5, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.1975, \"sd_coop\": 1.436465222946485, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.6, \"Emotion_Leniency\": 0.0, \"mean_coop\": 26.503899999999998, \"sd_coop\": 34.50511935708872, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 86.59692, \"sd_coop\": 8.074863511426258, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v6\", \"gamma_center\": 0.6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.77177999999999, \"sd_coop\": 3.378810558073201, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v5\", \"gamma_center\": 0.6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.16077999999999, \"sd_coop\": 3.5367685544512404, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.6, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.09698, \"sd_coop\": 1.6272718309602547, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 10.143279999999999, \"sd_coop\": 16.9567722634194, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.7, \"Emotion_Leniency\": 0.25, \"mean_coop\": 81.48238, \"sd_coop\": 13.046498824870485, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 0.7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.09494000000001, \"sd_coop\": 4.733529732770292, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v9\", \"gamma_center\": 0.7, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.5649, \"sd_coop\": 4.339526435415907, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.7, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.25764, \"sd_coop\": 0.9691021462136612, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.8, \"Emotion_Leniency\": 0.0, \"mean_coop\": 6.17164, \"sd_coop\": 3.281814099872576, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.8, \"Emotion_Leniency\": 0.25, \"mean_coop\": 73.9078, \"sd_coop\": 13.596651996363079, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 0.8, \"Emotion_Leniency\": 0.5, \"mean_coop\": 91.7682, \"sd_coop\": 3.7544495778546643, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v9\", \"gamma_center\": 0.8, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.96763999999999, \"sd_coop\": 4.861737619831168, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.8, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.08008, \"sd_coop\": 1.3641344544420533, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 0.9, \"Emotion_Leniency\": 0.0, \"mean_coop\": 5.489339999999999, \"sd_coop\": 0.25294732935647185, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v12\", \"gamma_center\": 0.9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 47.14592, \"sd_coop\": 12.767310687750612, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 0.9, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.48394, \"sd_coop\": 7.442806269115959, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v5\", \"gamma_center\": 0.9, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.10706, \"sd_coop\": 4.62795874432602, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 0.9, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.04866, \"sd_coop\": 1.7628617111540736, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v16\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.0, \"mean_coop\": 5.38526, \"sd_coop\": 0.26446247448014853, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v8\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.25, \"mean_coop\": 37.38422, \"sd_coop\": 12.130863687625673, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v11\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.72412, \"sd_coop\": 7.179876468836712, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v3\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.12549999999999, \"sd_coop\": 5.151091278277147, \"n_runs\": 50}, {\"variant_id\": \"Stern_Judging_v1\", \"gamma_center\": 1.0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.34371999999999, \"sd_coop\": 0.89741247177081, \"n_runs\": 50}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_norm = \"SternJudging\"  # Example\n",
    "\n",
    "# === 1. Filter and unify gamma column name ===\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Ensure numeric gamma\n",
    "norm_df[\"gamma_center\"] = pd.to_numeric(norm_df[\"gamma_center\"], errors=\"coerce\")\n",
    "\n",
    "# === 2. Compute mean cooperation per variant first ===\n",
    "variant_means = (\n",
    "    norm_df.groupby([\"variant_id\", \"gamma_center\", \"Emotion_Leniency\"], as_index=False)\n",
    "           .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "                sd_coop=(\"average_cooperation\", \"std\"),\n",
    "                n_runs=(\"average_cooperation\", \"count\"))\n",
    ")\n",
    "\n",
    "# Convert to % if needed\n",
    "if variant_means[\"mean_coop\"].max() <= 1:\n",
    "    variant_means[\"mean_coop\"] *= 100\n",
    "\n",
    "# === 3. For each (Î³, Leniency), find the variant with highest mean ===\n",
    "idx = variant_means.groupby([\"gamma_center\", \"Emotion_Leniency\"])[\"mean_coop\"].idxmax()\n",
    "max_variants = variant_means.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# === 4. Plot heatmap ===\n",
    "heat = alt.Chart(max_variants).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:O\", title=\"Emotion Leniency\", sort=\"descending\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Top Variant\"),\n",
    "        alt.Tooltip(\"mean_coop:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"sd_coop:Q\", title=\"Std (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"n_runs:Q\", title=\"# runs\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=400, height=350,\n",
    "    title=f\"{chosen_norm} â€” Maximal Cooperation by Î³ Ã— Emotion Leniency\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29ab7b5a-03a9-446c-a457-5e1a67ca7a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-d60e595c5c39426ab908af3596bc620c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d60e595c5c39426ab908af3596bc620c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d60e595c5c39426ab908af3596bc620c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a53b2182601e01adcbae8a864b314859\"}, \"mark\": {\"type\": \"circle\", \"size\": 200}, \"encoding\": {\"color\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100], \"scheme\": \"viridis\"}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}, \"size\": {\"field\": \"n\", \"title\": \"# Variants\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".2f\", \"title\": \"Mean coop\", \"type\": \"quantitative\"}, {\"field\": \"std_coop\", \"format\": \".2f\", \"title\": \"Std\", \"type\": \"quantitative\"}, {\"field\": \"n\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF complexity (# literals)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotion Leniency\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"SternJudging \\u2014 Cooperation by Complexity \\u00d7 Leniency (\\u03b3=0.5)\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-a53b2182601e01adcbae8a864b314859\": [{\"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.0, \"mean_coop\": 51.163999999999994, \"std_coop\": 40.417048136666686, \"n\": 1}, {\"DNF_literals\": 4.0, \"Emotion_Leniency\": 0.5, \"mean_coop\": 92.18863999999999, \"std_coop\": 3.912411619087609, \"n\": 2}, {\"DNF_literals\": 4.0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 93.1975, \"std_coop\": 1.436465222946485, \"n\": 1}, {\"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.25, \"mean_coop\": 78.17603, \"std_coop\": 21.85843864434942, \"n\": 2}, {\"DNF_literals\": 5.0, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.49797000000001, \"std_coop\": 5.0667139400805, \"n\": 2}, {\"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.25, \"mean_coop\": 80.68169, \"std_coop\": 17.30936190474375, \"n\": 2}, {\"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.5, \"mean_coop\": 82.05367, \"std_coop\": 11.857547275682716, \"n\": 2}, {\"DNF_literals\": 6.0, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.53276, \"std_coop\": 5.3835164189149864, \"n\": 2}, {\"DNF_literals\": 7.0, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.75685, \"std_coop\": 15.527626119161438, \"n\": 2}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick your norm and gamma value\n",
    "chosen_norm = \"SternJudging\"\n",
    "gamma_value = 0.5  # ðŸ”‘ change this\n",
    "\n",
    "# filter results for chosen norm and gamma\n",
    "subset = merged_df[(merged_df[\"norm\"] == chosen_norm) &\n",
    "                   (merged_df[\"gamma_center\"] == gamma_value)].copy()\n",
    "\n",
    "# aggregate cooperation by (DNF_literals, Leniency)\n",
    "agg = (\n",
    "    subset.groupby([\"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "          .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "               std_coop=(\"average_cooperation\", \"std\"),\n",
    "               n=(\"variant_id\", \"nunique\"))\n",
    ")\n",
    "\n",
    "# --- Scatterplot ---\n",
    "chart = alt.Chart(agg).mark_circle(size=200).encode(\n",
    "    x=alt.X(\"DNF_literals:Q\", title=\"DNF complexity (# literals)\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0,100])),\n",
    "    size=alt.Size(\"n:Q\", title=\"# Variants\"),\n",
    "    tooltip=[\n",
    "        \"DNF_literals:Q\",\n",
    "        \"Emotion_Leniency:Q\",\n",
    "        alt.Tooltip(\"mean_coop:Q\", format=\".2f\", title=\"Mean coop\"),\n",
    "        alt.Tooltip(\"std_coop:Q\", format=\".2f\", title=\"Std\"),\n",
    "        \"n:Q\"\n",
    "    ]\n",
    ").properties(\n",
    "    title=f\"{chosen_norm} â€” Cooperation by Complexity Ã— Leniency (Î³={gamma_value})\",\n",
    "    width=500, height=400\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315cd82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
