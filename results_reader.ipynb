{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e41aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from itertools import chain\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "results_path = os.path.normpath(os.path.join(notebook_dir, \"outputs\", \"updated_model_results.csv\"))\n",
    "norms_path   = os.path.normpath(os.path.join(notebook_dir, \"data\", \"all_8bit_norms_with_dnf.csv\"))\n",
    "\n",
    "# Load CSVs\n",
    "results_df = pd.read_csv(results_path)\n",
    "norms_df   = pd.read_csv(norms_path, dtype={\"8bit_vector\": str})\n",
    "\n",
    "# --- Helpers to flatten ---\n",
    "def flatten_ebsn_to_str(ebsn):\n",
    "    # If it's a string, convert it\n",
    "    if isinstance(ebsn, str):\n",
    "        ebsn = ast.literal_eval(ebsn)\n",
    "\n",
    "    flat_list = list(chain.from_iterable(chain.from_iterable(ebsn)))\n",
    "    return ''.join(str(int(b)) for b in flat_list)\n",
    "\n",
    "def flatten_base_sn_to_str(base_sn):\n",
    "    if isinstance(base_sn, str):\n",
    "        base_sn = ast.literal_eval(base_sn)\n",
    "\n",
    "    return ''.join(str(int(b)) for b in chain.from_iterable(base_sn))\n",
    "\n",
    "def identify_base_norm(base_norm_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the base social norm (e.g. Image Scoring, Stern Judging, etc.)\n",
    "    from its 4-bit structure [[a,b], [c,d], ...] as stored in the dataframe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        norm = ast.literal_eval(base_norm_str)\n",
    "    except Exception:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Flatten if nested\n",
    "    flat = [int(x) for pair in norm for x in pair]\n",
    "\n",
    "    mapping = {\n",
    "        (0, 0, 1, 1): \"Image Scoring\",\n",
    "        (1, 0, 0, 1): \"Stern Judging\",\n",
    "        (0, 0, 0, 1): \"Shunning\",\n",
    "        (1, 0, 1, 1): \"Simple Standing\",\n",
    "        (0, 0, 0, 0): \"All Bad\",\n",
    "        (1, 1, 1, 1): \"All Good\",\n",
    "    }\n",
    "\n",
    "    return mapping.get(tuple(flat), \"Unknown\")\n",
    "\n",
    "\n",
    "# Flatten columns in results\n",
    "results_df['8bit_vector'] = results_df['eb_social_norm'].apply(flatten_ebsn_to_str)\n",
    "results_df['4bit_orig']   = results_df['base_social_norm'].apply(eval).apply(flatten_base_sn_to_str)\n",
    "\n",
    "# Merge and include DNF columns\n",
    "merged_df = pd.merge(\n",
    "    results_df,\n",
    "    norms_df[[\"8bit_vector\", \n",
    "              \"Emotion_Leniency\", \"DNF\", \"DNF_literals\"]],\n",
    "    on=[\"8bit_vector\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure numeric\n",
    "merged_df[\"DNF_literals\"] = pd.to_numeric(merged_df[\"DNF_literals\"], errors=\"coerce\")\n",
    "merged_df[\"base_social_norm\"] = merged_df[\"base_social_norm\"].apply(identify_base_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e07cb15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_center</th>\n",
       "      <th>average_cooperation</th>\n",
       "      <th>ALWAYS_COOPERATE</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.745</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.206</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.674</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, 0], [1, 1]]</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.837</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55466</th>\n",
       "      <td>[[0, 0], [0, 1]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>85.723</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55467</th>\n",
       "      <td>[[0, 0], [0, 1]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>85.440</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55468</th>\n",
       "      <td>[[0, 0], [0, 1]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>85.146</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55469</th>\n",
       "      <td>[[0, 0], [0, 1]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.634</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55470</th>\n",
       "      <td>[[0, 0], [0, 1]]</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>86.078</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55471 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4      [[0, 0], [1, 1]]  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                 ...                                   ...  ..   ...  ...   \n",
       "55466  [[0, 0], [0, 1]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55467  [[0, 0], [0, 1]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55468  [[0, 0], [0, 1]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55469  [[0, 0], [0, 1]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55470  [[0, 0], [0, 1]]  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  gamma_center  average_cooperation  \\\n",
       "0      0.01  0.01    0.0  5  1  ...           0.0               37.745   \n",
       "1      0.01  0.01    0.0  5  1  ...           0.0               36.042   \n",
       "2      0.01  0.01    0.0  5  1  ...           0.0               17.206   \n",
       "3      0.01  0.01    0.0  5  1  ...           0.0               34.674   \n",
       "4      0.01  0.01    0.0  5  1  ...           0.0               18.837   \n",
       "...     ...   ...    ... .. ..  ...           ...                  ...   \n",
       "55466  0.01  0.01    0.0  5  1  ...           0.2               85.723   \n",
       "55467  0.01  0.01    0.0  5  1  ...           0.2               85.440   \n",
       "55468  0.01  0.01    0.0  5  1  ...           0.2               85.146   \n",
       "55469  0.01  0.01    0.0  5  1  ...           0.2               13.634   \n",
       "55470  0.01  0.01    0.0  5  1  ...           0.2               86.078   \n",
       "\n",
       "       ALWAYS_COOPERATE  DISCRIMINATE  PARADOXICALLY_DISC  ALWAYS_DEFECT  \\\n",
       "0                0.0000        0.5333              0.1333         0.3333   \n",
       "1                0.0000        0.1333              0.1333         0.7333   \n",
       "2                0.0333        0.0000              0.0333         0.9333   \n",
       "3                0.3667        0.2333              0.0000         0.4000   \n",
       "4                0.0333        0.0333              0.0000         0.9333   \n",
       "...                 ...           ...                 ...            ...   \n",
       "55466            0.0600        0.9400              0.0000         0.0000   \n",
       "55467            0.0200        0.9800              0.0000         0.0000   \n",
       "55468            0.3200        0.6400              0.0000         0.0400   \n",
       "55469            0.0200        0.0200              0.0000         0.9600   \n",
       "55470            0.4600        0.4800              0.0000         0.0600   \n",
       "\n",
       "       Competitive  Cooperative  8bit_vector  4bit_orig  \n",
       "0             0.87         0.13     00011111       0011  \n",
       "1             0.73         0.27     00011111       0011  \n",
       "2             0.07         0.93     00011111       0011  \n",
       "3             0.60         0.40     00011111       0011  \n",
       "4             0.93         0.07     00011111       0011  \n",
       "...            ...          ...          ...        ...  \n",
       "55466         0.06         0.94     11111111       0001  \n",
       "55467         0.98         0.02     11111111       0001  \n",
       "55468         0.36         0.64     11111111       0001  \n",
       "55469         0.04         0.96     11111111       0001  \n",
       "55470         0.52         0.48     11111111       0001  \n",
       "\n",
       "[55471 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98672db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_social_norm</th>\n",
       "      <th>eb_social_norm</th>\n",
       "      <th>Z</th>\n",
       "      <th>gens</th>\n",
       "      <th>mu</th>\n",
       "      <th>chi</th>\n",
       "      <th>eps</th>\n",
       "      <th>alpha</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>...</th>\n",
       "      <th>DISCRIMINATE</th>\n",
       "      <th>PARADOXICALLY_DISC</th>\n",
       "      <th>ALWAYS_DEFECT</th>\n",
       "      <th>Competitive</th>\n",
       "      <th>Cooperative</th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>4bit_orig</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>DNF</th>\n",
       "      <th>DNF_literals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.93</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Scoring</td>\n",
       "      <td>[[(0, 0), (0, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>00011111</td>\n",
       "      <td>0011</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A | (E &amp; R)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55466</th>\n",
       "      <td>Shunning</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55467</th>\n",
       "      <td>Shunning</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55468</th>\n",
       "      <td>Shunning</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.64</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55469</th>\n",
       "      <td>Shunning</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55470</th>\n",
       "      <td>Shunning</td>\n",
       "      <td>[[(1, 1), (1, 1)], [(1, 1), (1, 1)]]</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>11111111</td>\n",
       "      <td>0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55471 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      base_social_norm                        eb_social_norm   Z  gens   mu  \\\n",
       "0        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "1        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "2        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "3        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "4        Image Scoring  [[(0, 0), (0, 1)], [(1, 1), (1, 1)]]  30   250  1.0   \n",
       "...                ...                                   ...  ..   ...  ...   \n",
       "55466         Shunning  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55467         Shunning  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55468         Shunning  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55469         Shunning  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "55470         Shunning  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]  50  1000  1.0   \n",
       "\n",
       "        chi   eps  alpha  b  c  ...  DISCRIMINATE  PARADOXICALLY_DISC  \\\n",
       "0      0.01  0.01    0.0  5  1  ...        0.5333              0.1333   \n",
       "1      0.01  0.01    0.0  5  1  ...        0.1333              0.1333   \n",
       "2      0.01  0.01    0.0  5  1  ...        0.0000              0.0333   \n",
       "3      0.01  0.01    0.0  5  1  ...        0.2333              0.0000   \n",
       "4      0.01  0.01    0.0  5  1  ...        0.0333              0.0000   \n",
       "...     ...   ...    ... .. ..  ...           ...                 ...   \n",
       "55466  0.01  0.01    0.0  5  1  ...        0.9400              0.0000   \n",
       "55467  0.01  0.01    0.0  5  1  ...        0.9800              0.0000   \n",
       "55468  0.01  0.01    0.0  5  1  ...        0.6400              0.0000   \n",
       "55469  0.01  0.01    0.0  5  1  ...        0.0200              0.0000   \n",
       "55470  0.01  0.01    0.0  5  1  ...        0.4800              0.0000   \n",
       "\n",
       "       ALWAYS_DEFECT  Competitive  Cooperative  8bit_vector  4bit_orig  \\\n",
       "0             0.3333         0.87         0.13     00011111       0011   \n",
       "1             0.7333         0.73         0.27     00011111       0011   \n",
       "2             0.9333         0.07         0.93     00011111       0011   \n",
       "3             0.4000         0.60         0.40     00011111       0011   \n",
       "4             0.9333         0.93         0.07     00011111       0011   \n",
       "...              ...          ...          ...          ...        ...   \n",
       "55466         0.0000         0.06         0.94     11111111       0001   \n",
       "55467         0.0000         0.98         0.02     11111111       0001   \n",
       "55468         0.0400         0.36         0.64     11111111       0001   \n",
       "55469         0.9600         0.04         0.96     11111111       0001   \n",
       "55470         0.0600         0.52         0.48     11111111       0001   \n",
       "\n",
       "       Emotion_Leniency          DNF  DNF_literals  \n",
       "0                  0.75  A | (E & R)             3  \n",
       "1                  0.75  A | (E & R)             3  \n",
       "2                  0.75  A | (E & R)             3  \n",
       "3                  0.75  A | (E & R)             3  \n",
       "4                  0.75  A | (E & R)             3  \n",
       "...                 ...          ...           ...  \n",
       "55466              1.00         True             0  \n",
       "55467              1.00         True             0  \n",
       "55468              1.00         True             0  \n",
       "55469              1.00         True             0  \n",
       "55470              1.00         True             0  \n",
       "\n",
       "[55471 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78830fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_social_norm  eb_social_norm                      \n",
      "[[0, 0], [0, 1]]  [[(0, 0), (0, 0)], [(0, 0), (0, 0)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (0, 1)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (1, 0)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 0), (1, 1)]]    30\n",
      "                  [[(0, 0), (0, 0)], [(0, 1), (0, 0)]]    30\n",
      "                                                          ..\n",
      "[[1, 0], [1, 1]]  [[(1, 1), (1, 1)], [(1, 0), (1, 1)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (0, 0)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (0, 1)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (1, 0)]]    26\n",
      "                  [[(1, 1), (1, 1)], [(1, 1), (1, 1)]]    26\n",
      "Length: 987, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter only runs that originate from this base norm\n",
    "filtered = results_df[results_df.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == 0.8]\n",
    "\n",
    "# Average all runs per emergent norm\n",
    "grouped = filtered.groupby([\"base_social_norm\", \"eb_social_norm\"])\n",
    "\n",
    "print(grouped.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e930e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Emergent Norms: DNF Complexity vs Cooperation  \n",
    "This section selects a **base social norm** (e.g., Image Scoring, Stern Judging) and visualizes how all **emergent 8-bit norms** derived from it perform.\n",
    "\n",
    "For each emergent norm:\n",
    "- All simulation runs are grouped.\n",
    "- The **mean cooperation ratio** is computed.\n",
    "- The **DNF complexity** (number of literals in simplified DNF) is retrieved.\n",
    "\n",
    "The scatterplot shows:\n",
    "- **x-axis:** DNF complexity  \n",
    "- **y-axis:** mean cooperation  \n",
    "- **each point:** one emergent 8-bit social norm  \n",
    "\n",
    "This helps reveal which evolved norms are both **simple** and **highly cooperative** under a chosen base norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b16cbe48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-53a286b4e6dd4c9685a154a396c90983.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-53a286b4e6dd4c9685a154a396c90983.vega-embed details,\n",
       "  #altair-viz-53a286b4e6dd4c9685a154a396c90983.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-53a286b4e6dd4c9685a154a396c90983\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-53a286b4e6dd4c9685a154a396c90983\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-53a286b4e6dd4c9685a154a396c90983\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"color\": \"orange\", \"opacity\": 0.5, \"size\": 2}, \"encoding\": {\"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}, \"transform\": [{\"on\": \"DNF_literals\", \"regression\": \"mean_coop\", \"method\": \"poly\"}]}, {\"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"Emotion Leniency\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-2c1f2091f15831422f9fa0db673d5968\"}, \"height\": 300, \"title\": \"Base Norm: Stern Judging; Gamma: 0.8, Social Norms (Top 10%) \\u2014 Poly Regression + Max-Per-DNF Line\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-2c1f2091f15831422f9fa0db673d5968\": [{\"8bit_vector\": \"00000000\", \"DNF_literals\": 0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 5.539949999999999}, {\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 85.65469999999999}, {\"8bit_vector\": \"00000011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 82.77855}, {\"8bit_vector\": \"11000000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 65.16346}, {\"8bit_vector\": \"11110011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 81.74346}, {\"8bit_vector\": \"01010111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.10373333333334}, {\"8bit_vector\": \"10101011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.91558}, {\"8bit_vector\": \"11010101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 88.64234}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 87.70062}, {\"8bit_vector\": \"01000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.88816666666666}, {\"8bit_vector\": \"11000011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 92.85692}, {\"8bit_vector\": \"11000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.86758}, {\"8bit_vector\": \"11001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 89.47286}, {\"8bit_vector\": \"11010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.92048000000001}, {\"8bit_vector\": \"11100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.73273999999999}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.18442}, {\"8bit_vector\": \"11000010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.90484000000001}, {\"8bit_vector\": \"11010111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.08923999999999}, {\"8bit_vector\": \"11101011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 91.28856}, {\"8bit_vector\": \"01000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.37431666666666}, {\"8bit_vector\": \"10000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 90.62523999999999}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 89.24176}, {\"8bit_vector\": \"11001011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 91.65361999999999}, {\"8bit_vector\": \"11010011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.79214}, {\"8bit_vector\": \"11100011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 92.15190000000001}, {\"8bit_vector\": \"01011001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 76.66536666666666}, {\"8bit_vector\": \"10101001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 76.21652}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 86.27853999999999}, {\"8bit_vector\": \"10000110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 72.78546}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 77.78613999999999}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 5.13608}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"Stern Judging\"\n",
    "chosen_gamma = 0.8\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0.9)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"DNF_literals\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"DNF_literals:Q\", title=\"DNF Complexity\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\",\n",
    "                        scale=alt.Scale(scheme=\"viridis\")),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Polynomial regression (degree 2)\n",
    "poly_reg = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .transform_regression(\n",
    "        \"DNF_literals\",\n",
    "        \"mean_coop\",\n",
    "        method=\"poly\"\n",
    "    )\n",
    "    .mark_line(size=2, color=\"orange\", opacity=0.5)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\",\n",
    "        tooltip=[\"DNF_literals\", \"mean_coop\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (poly_reg + scatter)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Social Norms (Top 10%) â€” Poly Regression + Max-Per-DNF Line\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccd12ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-8aea6bfcea804cddbc0a30352241c177.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-8aea6bfcea804cddbc0a30352241c177.vega-embed details,\n",
       "  #altair-viz-8aea6bfcea804cddbc0a30352241c177.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-8aea6bfcea804cddbc0a30352241c177\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-8aea6bfcea804cddbc0a30352241c177\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-8aea6bfcea804cddbc0a30352241c177\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-ab44cf1e0c78bed354d9e8eb90d1c94d\"}, \"mark\": {\"type\": \"line\", \"color\": \"gray\", \"opacity\": 0.8, \"point\": true, \"size\": 2}, \"encoding\": {\"tooltip\": [{\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-09d4510ef0dd1163a89fca065c48e47c\"}, \"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"Emotion_Leniency\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"Emotion Leniency\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"DNF_literals\", \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}], \"height\": 300, \"title\": \"Base Norm: Shunning; Gamma: 0.2, Emotion Based Social Norms (All)\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-ab44cf1e0c78bed354d9e8eb90d1c94d\": [{\"8bit_vector\": \"11111111\", \"DNF_literals\": 0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 80.9823}, {\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 64.8802}, {\"8bit_vector\": \"11110011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 84.65705}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 82.7252}, {\"8bit_vector\": \"11000011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 83.2129}, {\"8bit_vector\": \"11010111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.51035}, {\"8bit_vector\": \"11100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.31295}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 80.79185}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 80.922}, {\"8bit_vector\": \"01101001\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 70.86179999999999}], \"data-09d4510ef0dd1163a89fca065c48e47c\": [{\"8bit_vector\": \"00000000\", \"DNF_literals\": 0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 4.182433333333333}, {\"8bit_vector\": \"00000001\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1752}, {\"8bit_vector\": \"00000010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.213333333333334}, {\"8bit_vector\": \"00000011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 4.221933333333333}, {\"8bit_vector\": \"00000100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 5.9028}, {\"8bit_vector\": \"00000101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 9.2937}, {\"8bit_vector\": \"00000110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.43455}, {\"8bit_vector\": \"00000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 15.204249999999998}, {\"8bit_vector\": \"00001000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.9846}, {\"8bit_vector\": \"00001001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.930400000000001}, {\"8bit_vector\": \"00001010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 8.77195}, {\"8bit_vector\": \"00001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 12.618350000000001}, {\"8bit_vector\": \"00001100\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 8.949200000000001}, {\"8bit_vector\": \"00001101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 14.631}, {\"8bit_vector\": \"00001110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 13.34575}, {\"8bit_vector\": \"00001111\", \"DNF_literals\": 1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 27.03605}, {\"8bit_vector\": \"00010000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.2067}, {\"8bit_vector\": \"00010001\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.1232500000000005}, {\"8bit_vector\": \"00010010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.20115}, {\"8bit_vector\": \"00010011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.19325}, {\"8bit_vector\": \"00010100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.21815}, {\"8bit_vector\": \"00010101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.098099999999999}, {\"8bit_vector\": \"00010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.09375}, {\"8bit_vector\": \"00010111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 11.731649999999998}, {\"8bit_vector\": \"00011000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.8062}, {\"8bit_vector\": \"00011001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.573699999999999}, {\"8bit_vector\": \"00011010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.68055}, {\"8bit_vector\": \"00011011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 12.61535}, {\"8bit_vector\": \"00011100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 8.9988}, {\"8bit_vector\": \"00011101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 14.661000000000001}, {\"8bit_vector\": \"00011110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 14.10305}, {\"8bit_vector\": \"00011111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 25.2244}, {\"8bit_vector\": \"00100000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.16995}, {\"8bit_vector\": \"00100001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.1884999999999994}, {\"8bit_vector\": \"00100010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 4.209300000000001}, {\"8bit_vector\": \"00100011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.12855}, {\"8bit_vector\": \"00100100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.1524}, {\"8bit_vector\": \"00100101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 8.5495}, {\"8bit_vector\": \"00100110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 7.09705}, {\"8bit_vector\": \"00100111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 10.8846}, {\"8bit_vector\": \"00101000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 6.0915}, {\"8bit_vector\": \"00101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 7.3309}, {\"8bit_vector\": \"00101010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 9.2163}, {\"8bit_vector\": \"00101011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 11.99145}, {\"8bit_vector\": \"00101100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 9.23315}, {\"8bit_vector\": \"00101101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 14.662450000000002}, {\"8bit_vector\": \"00101110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 16.59665}, {\"8bit_vector\": \"00101111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 25.2648}, {\"8bit_vector\": \"00110000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 4.07585}, {\"8bit_vector\": \"00110001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.1831499999999995}, {\"8bit_vector\": \"00110010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 4.18435}, {\"8bit_vector\": \"00110011\", \"DNF_literals\": 1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 4.16365}, {\"8bit_vector\": \"00110100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.681399999999999}, {\"8bit_vector\": \"00110101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 8.0856}, {\"8bit_vector\": \"00110110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.930400000000001}, {\"8bit_vector\": \"00110111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 10.705200000000001}, {\"8bit_vector\": \"00111000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 6.3541}, {\"8bit_vector\": \"00111001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 7.220150000000001}, {\"8bit_vector\": \"00111010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 8.79285}, {\"8bit_vector\": \"00111011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 11.43585}, {\"8bit_vector\": \"00111100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 9.44175}, {\"8bit_vector\": \"00111101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 13.05165}, {\"8bit_vector\": \"00111110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 16.08015}, {\"8bit_vector\": \"00111111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 26.0315}, {\"8bit_vector\": \"01000000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 39.675650000000005}, {\"8bit_vector\": \"01000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 74.4251}, {\"8bit_vector\": \"01000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 36.97225}, {\"8bit_vector\": \"01000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 71.486}, {\"8bit_vector\": \"01000100\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 30.202800000000003}, {\"8bit_vector\": \"01000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 67.57730000000001}, {\"8bit_vector\": \"01000110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 34.7407}, {\"8bit_vector\": \"01000111\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 74.71705}, {\"8bit_vector\": \"01001000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 37.08925}, {\"8bit_vector\": \"01001001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 73.6714}, {\"8bit_vector\": \"01001010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 35.933749999999996}, {\"8bit_vector\": \"01001011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 59.7196}, {\"8bit_vector\": \"01001100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 29.6312}, {\"8bit_vector\": \"01001101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 61.03175}, {\"8bit_vector\": \"01001110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 41.2464}, {\"8bit_vector\": \"01001111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 64.908}, {\"8bit_vector\": \"01010000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.446949999999998}, {\"8bit_vector\": \"01010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 56.599149999999995}, {\"8bit_vector\": \"01010010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 30.2403}, {\"8bit_vector\": \"01010011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 71.54260000000001}, {\"8bit_vector\": \"01010100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 30.0431}, {\"8bit_vector\": \"01010101\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 56.930150000000005}, {\"8bit_vector\": \"01010110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 30.542849999999998}, {\"8bit_vector\": \"01010111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 66.7022}, {\"8bit_vector\": \"01011000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 26.557949999999998}, {\"8bit_vector\": \"01011001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 69.7431}, {\"8bit_vector\": \"01011010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 29.0465}, {\"8bit_vector\": \"01011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 51.08985}, {\"8bit_vector\": \"01011100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 30.5944}, {\"8bit_vector\": \"01011101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 68.2084}, {\"8bit_vector\": \"01011110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 21.16745}, {\"8bit_vector\": \"01011111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 61.750099999999996}, {\"8bit_vector\": \"01100000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 39.661500000000004}, {\"8bit_vector\": \"01100001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 64.77745}, {\"8bit_vector\": \"01100010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 41.53705}, {\"8bit_vector\": \"01100011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 74.3607}, {\"8bit_vector\": \"01100100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 38.00125}, {\"8bit_vector\": \"01100101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 66.51775}, {\"8bit_vector\": \"01100110\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 31.23195}, {\"8bit_vector\": \"01100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 71.8541}, {\"8bit_vector\": \"01101000\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 40.57665}, {\"8bit_vector\": \"01101001\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 70.86179999999999}, {\"8bit_vector\": \"01101010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 38.1471}, {\"8bit_vector\": \"01101011\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 73.48255}, {\"8bit_vector\": \"01101100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 32.4222}, {\"8bit_vector\": \"01101101\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 62.858349999999994}, {\"8bit_vector\": \"01101110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 31.3531}, {\"8bit_vector\": \"01101111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 64.35135}, {\"8bit_vector\": \"01110000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 23.4546}, {\"8bit_vector\": \"01110001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 71.9085}, {\"8bit_vector\": \"01110010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 34.4388}, {\"8bit_vector\": \"01110011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 72.72985}, {\"8bit_vector\": \"01110100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 32.0822}, {\"8bit_vector\": \"01110101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 64.2632}, {\"8bit_vector\": \"01110110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 23.14635}, {\"8bit_vector\": \"01110111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.01955000000001}, {\"8bit_vector\": \"01111000\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 34.4863}, {\"8bit_vector\": \"01111001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 60.3344}, {\"8bit_vector\": \"01111010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 37.5546}, {\"8bit_vector\": \"01111011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 51.009249999999994}, {\"8bit_vector\": \"01111100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 37.816}, {\"8bit_vector\": \"01111101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 70.779}, {\"8bit_vector\": \"01111110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 25.2201}, {\"8bit_vector\": \"01111111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 50.11515}, {\"8bit_vector\": \"10000000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 45.423700000000004}, {\"8bit_vector\": \"10000001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.0031}, {\"8bit_vector\": \"10000010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 74.58964999999999}, {\"8bit_vector\": \"10000011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 75.55805000000001}, {\"8bit_vector\": \"10000100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 35.0111}, {\"8bit_vector\": \"10000101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 35.22555}, {\"8bit_vector\": \"10000110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 58.720600000000005}, {\"8bit_vector\": \"10000111\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 61.391099999999994}, {\"8bit_vector\": \"10001000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 31.670350000000003}, {\"8bit_vector\": \"10001001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 34.2801}, {\"8bit_vector\": \"10001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 58.165200000000006}, {\"8bit_vector\": \"10001011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 63.763200000000005}, {\"8bit_vector\": \"10001100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 30.48295}, {\"8bit_vector\": \"10001101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 43.46105}, {\"8bit_vector\": \"10001110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 74.8992}, {\"8bit_vector\": \"10001111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 61.30825}, {\"8bit_vector\": \"10010000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 33.55745}, {\"8bit_vector\": \"10010001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 45.41325}, {\"8bit_vector\": \"10010010\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 66.99125000000001}, {\"8bit_vector\": \"10010011\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.03595}, {\"8bit_vector\": \"10010100\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 42.58005}, {\"8bit_vector\": \"10010101\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 41.7954}, {\"8bit_vector\": \"10010110\", \"DNF_literals\": 12, \"Emotion_Leniency\": 0.0, \"mean_coop\": 63.31955000000001}, {\"8bit_vector\": \"10010111\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 70.86635}, {\"8bit_vector\": \"10011000\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 33.8351}, {\"8bit_vector\": \"10011001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 34.40805}, {\"8bit_vector\": \"10011010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 58.732499999999995}, {\"8bit_vector\": \"10011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.63550000000001}, {\"8bit_vector\": \"10011100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 33.09395}, {\"8bit_vector\": \"10011101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 23.37585}, {\"8bit_vector\": \"10011110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 66.46475000000001}, {\"8bit_vector\": \"10011111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.89005}, {\"8bit_vector\": \"10100000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 30.14405}, {\"8bit_vector\": \"10100001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 30.5894}, {\"8bit_vector\": \"10100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 64.9082}, {\"8bit_vector\": \"10100011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 48.38245}, {\"8bit_vector\": \"10100100\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.25, \"mean_coop\": 29.539749999999998}, {\"8bit_vector\": \"10100101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.0, \"mean_coop\": 28.72075}, {\"8bit_vector\": \"10100110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 68.03254999999999}, {\"8bit_vector\": \"10100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 50.925850000000004}, {\"8bit_vector\": \"10101000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.25, \"mean_coop\": 27.9735}, {\"8bit_vector\": \"10101001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.0, \"mean_coop\": 32.5895}, {\"8bit_vector\": \"10101010\", \"DNF_literals\": 1, \"Emotion_Leniency\": 0.0, \"mean_coop\": 64.8802}, {\"8bit_vector\": \"10101011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 72.8915}, {\"8bit_vector\": \"10101100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 19.9286}, {\"8bit_vector\": \"10101101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 31.6558}, {\"8bit_vector\": \"10101110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 69.17235000000001}, {\"8bit_vector\": \"10101111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 63.86315}, {\"8bit_vector\": \"10110000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 33.8766}, {\"8bit_vector\": \"10110001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 33.371300000000005}, {\"8bit_vector\": \"10110010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 64.8573}, {\"8bit_vector\": \"10110011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 50.98995}, {\"8bit_vector\": \"10110100\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 36.60935}, {\"8bit_vector\": \"10110101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 35.74255}, {\"8bit_vector\": \"10110110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.9919}, {\"8bit_vector\": \"10110111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 54.480650000000004}, {\"8bit_vector\": \"10111000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 33.16395}, {\"8bit_vector\": \"10111001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 24.1321}, {\"8bit_vector\": \"10111010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 60.36514999999999}, {\"8bit_vector\": \"10111011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 72.99925}, {\"8bit_vector\": \"10111100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 34.90365}, {\"8bit_vector\": \"10111101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 22.6719}, {\"8bit_vector\": \"10111110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 60.969899999999996}, {\"8bit_vector\": \"10111111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 47.4901}, {\"8bit_vector\": \"11000000\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 45.357150000000004}, {\"8bit_vector\": \"11000001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 72.61845000000001}, {\"8bit_vector\": \"11000010\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.75, \"mean_coop\": 78.37545}, {\"8bit_vector\": \"11000011\", \"DNF_literals\": 4, \"Emotion_Leniency\": 1.0, \"mean_coop\": 83.2129}, {\"8bit_vector\": \"11000100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 44.531600000000005}, {\"8bit_vector\": \"11000101\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.4564}, {\"8bit_vector\": \"11000110\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 80.79185}, {\"8bit_vector\": \"11000111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 83.11865}, {\"8bit_vector\": \"11001000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 46.1519}, {\"8bit_vector\": \"11001001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.2962}, {\"8bit_vector\": \"11001010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 79.72325}, {\"8bit_vector\": \"11001011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 83.93379999999999}, {\"8bit_vector\": \"11001100\", \"DNF_literals\": 1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 46.8663}, {\"8bit_vector\": \"11001101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 79.4423}, {\"8bit_vector\": \"11001110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 75.29339999999999}, {\"8bit_vector\": \"11001111\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 82.93365}, {\"8bit_vector\": \"11010000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 40.52685}, {\"8bit_vector\": \"11010001\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.70215}, {\"8bit_vector\": \"11010010\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 80.024}, {\"8bit_vector\": \"11010011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 83.41}, {\"8bit_vector\": \"11010100\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 42.20755}, {\"8bit_vector\": \"11010101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 77.96205}, {\"8bit_vector\": \"11010110\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 74.85035}, {\"8bit_vector\": \"11010111\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.51035}, {\"8bit_vector\": \"11011000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 45.2764}, {\"8bit_vector\": \"11011001\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 75.5177}, {\"8bit_vector\": \"11011010\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 79.1868}, {\"8bit_vector\": \"11011011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.22999999999999}, {\"8bit_vector\": \"11011100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 43.250800000000005}, {\"8bit_vector\": \"11011101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 70.89605}, {\"8bit_vector\": \"11011110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 79.44715}, {\"8bit_vector\": \"11011111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 81.43955}, {\"8bit_vector\": \"11100000\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.75, \"mean_coop\": 43.09505}, {\"8bit_vector\": \"11100001\", \"DNF_literals\": 7, \"Emotion_Leniency\": 0.5, \"mean_coop\": 75.06365}, {\"8bit_vector\": \"11100010\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.38305}, {\"8bit_vector\": \"11100011\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.75, \"mean_coop\": 82.0364}, {\"8bit_vector\": \"11100100\", \"DNF_literals\": 4, \"Emotion_Leniency\": 0.5, \"mean_coop\": 44.4728}, {\"8bit_vector\": \"11100101\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 80.73285}, {\"8bit_vector\": \"11100110\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.25, \"mean_coop\": 68.96520000000001}, {\"8bit_vector\": \"11100111\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.31295}, {\"8bit_vector\": \"11101000\", \"DNF_literals\": 6, \"Emotion_Leniency\": 0.5, \"mean_coop\": 45.7817}, {\"8bit_vector\": \"11101001\", \"DNF_literals\": 9, \"Emotion_Leniency\": 0.25, \"mean_coop\": 80.922}, {\"8bit_vector\": \"11101010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.25, \"mean_coop\": 82.7252}, {\"8bit_vector\": \"11101011\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 84.38735}, {\"8bit_vector\": \"11101100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 41.6856}, {\"8bit_vector\": \"11101101\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 76.10510000000001}, {\"8bit_vector\": \"11101110\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 73.76865000000001}, {\"8bit_vector\": \"11101111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 79.68695}, {\"8bit_vector\": \"11110000\", \"DNF_literals\": 1, \"Emotion_Leniency\": 1.0, \"mean_coop\": 36.10085}, {\"8bit_vector\": \"11110001\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 80.84270000000001}, {\"8bit_vector\": \"11110010\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 72.25975}, {\"8bit_vector\": \"11110011\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 84.65705}, {\"8bit_vector\": \"11110100\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 42.8906}, {\"8bit_vector\": \"11110101\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 77.50305}, {\"8bit_vector\": \"11110110\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 67.9811}, {\"8bit_vector\": \"11110111\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 80.8403}, {\"8bit_vector\": \"11111000\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 40.3303}, {\"8bit_vector\": \"11111001\", \"DNF_literals\": 5, \"Emotion_Leniency\": 0.5, \"mean_coop\": 71.6231}, {\"8bit_vector\": \"11111010\", \"DNF_literals\": 2, \"Emotion_Leniency\": 0.5, \"mean_coop\": 78.33865}, {\"8bit_vector\": \"11111011\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 80.462}, {\"8bit_vector\": \"11111100\", \"DNF_literals\": 2, \"Emotion_Leniency\": 1.0, \"mean_coop\": 41.5991}, {\"8bit_vector\": \"11111101\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 64.01263157894736}, {\"8bit_vector\": \"11111110\", \"DNF_literals\": 3, \"Emotion_Leniency\": 0.75, \"mean_coop\": 68.03295}, {\"8bit_vector\": \"11111111\", \"DNF_literals\": 0, \"Emotion_Leniency\": 1.0, \"mean_coop\": 80.9823}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"Shunning\"\n",
    "chosen_gamma = 0.2\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "#filtered = filtered[filtered.Emotion_Leniency != 1]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"DNF_literals\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"DNF_literals:Q\", title=\"DNF Complexity\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\",\n",
    "                        scale=alt.Scale(scheme=\"viridis\")),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"DNF_literals:Q\",\n",
    "        y=\"mean_coop:Q\",\n",
    "        tooltip=[\"DNF_literals\", \"mean_coop\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (topline + scatter)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Emotion Based Social Norms (All)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3300f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choose base norm (must match identify_base_norm output)\n",
    "chosen_base_norm = \"Image Scoring\"   # â† adjust as needed\n",
    "chosen_gamma = 0.8\n",
    "\n",
    "# Filter only runs that originate from this base norm\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "elites = grouped[grouped.mean_coop >= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4bf182b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8bit_vector</th>\n",
       "      <th>DNF_literals</th>\n",
       "      <th>Emotion_Leniency</th>\n",
       "      <th>mean_coop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>01000011</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>82.6409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>11000011</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>83.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>11000111</td>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>84.1315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    8bit_vector  DNF_literals  Emotion_Leniency  mean_coop\n",
       "67     01000011             5              0.75    82.6409\n",
       "195    11000011             4              1.00    83.0274\n",
       "199    11000111             6              0.75    84.1315"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76dceab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_Good</th>\n",
       "      <th>freq_Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_Good  freq_Bad\n",
       "0   0.666667  0.333333\n",
       "1   1.000000  0.000000\n",
       "2   0.000000  1.000000\n",
       "3   0.000000  1.000000\n",
       "4   0.000000  1.000000\n",
       "5   0.333333  0.666667\n",
       "6   1.000000  0.000000\n",
       "7   1.000000  0.000000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the bitstrings into columns\n",
    "bits = elites[\"8bit_vector\"].apply(lambda s: pd.Series(list(s))).astype(int)\n",
    "#bits.columns = [\"DBm\", \"DBn\", \"DGm\", \"DGn\", \"CBm\", \"CBn\", \"CGm\", \"CGn\"]\n",
    "\n",
    "# Frequency of 1s and 0s at each position\n",
    "bit_summary = pd.DataFrame({\n",
    "    \"freq_Good\": bits.mean(),\n",
    "    \"freq_Bad\": 1 - bits.mean()\n",
    "})\n",
    "\n",
    "# Optional: merge back if you want combined dataframe\n",
    "df_bits = pd.concat([elites, bits], axis=1)\n",
    "\n",
    "bit_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7196a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed details,\n",
       "  #altair-viz-cda72954b14e44f1ac8cca1f0431c0ed.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cda72954b14e44f1ac8cca1f0431c0ed\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f20cc1b8c19293d054dbb83ccc577b72\"}, \"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"freq_1\", \"scale\": {\"scheme\": \"reds\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"bit\", \"type\": \"nominal\"}, {\"field\": \"freq_1\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"bit\", \"title\": \"Bit Position\", \"type\": \"nominal\"}, \"y\": {\"field\": \"freq_1\", \"scale\": {\"domain\": [0, 1]}, \"title\": \"Frequency of 1\", \"type\": \"quantitative\"}}, \"title\": \"Bit Frequency of High-performing norms on base Image Scoring; \\u03b3=0.8\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-f20cc1b8c19293d054dbb83ccc577b72\": [{\"bit\": \"bit_0\", \"freq_1\": 0.6666666666666666}, {\"bit\": \"bit_1\", \"freq_1\": 1.0}, {\"bit\": \"bit_2\", \"freq_1\": 0.0}, {\"bit\": \"bit_3\", \"freq_1\": 0.0}, {\"bit\": \"bit_4\", \"freq_1\": 0.0}, {\"bit\": \"bit_5\", \"freq_1\": 0.3333333333333333}, {\"bit\": \"bit_6\", \"freq_1\": 1.0}, {\"bit\": \"bit_7\", \"freq_1\": 1.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split bitstrings\n",
    "bits = elites[\"8bit_vector\"].apply(lambda s: pd.Series(list(s))).astype(int)\n",
    "bits.columns = [f\"bit_{i}\" for i in range(8)]\n",
    "freq = bits.mean().reset_index()\n",
    "freq.columns = [\"bit\", \"freq_1\"]\n",
    "\n",
    "heat_freq = (\n",
    "    alt.Chart(freq)\n",
    "    .mark_rect()\n",
    "    .encode(\n",
    "        x=alt.X(\"bit:N\", title=\"Bit Position\"),\n",
    "        y=alt.Y(\"freq_1:Q\", scale=alt.Scale(domain=[0,1]), title=\"Frequency of 1\"),\n",
    "        color=alt.Color(\"freq_1:Q\", scale=alt.Scale(scheme=\"reds\")),\n",
    "        tooltip=[\"bit\", \"freq_1\"]\n",
    "    )\n",
    "    .properties(title=f\"Bit Frequency of High-performing norms on base {chosen_base_norm}; Î³={chosen_gamma}\")\n",
    ")\n",
    "\n",
    "heat_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dc92529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed details,\n",
       "  #altair-viz-916d14c762ef44ebbcc67fe075cec528.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-916d14c762ef44ebbcc67fe075cec528\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-916d14c762ef44ebbcc67fe075cec528\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-916d14c762ef44ebbcc67fe075cec528\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e9bded0633f9946d70a054b064ec1de6\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"corr_with_coop\", \"scale\": {\"scheme\": \"blueorange\"}, \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"bit\", \"type\": \"nominal\"}, {\"field\": \"corr_with_coop\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"bit\", \"title\": \"Bit Position\", \"type\": \"nominal\"}, \"y\": {\"field\": \"corr_with_coop\", \"title\": \"Correlation\", \"type\": \"quantitative\"}}, \"title\": \"Base norm: Stern Judging; Gamma: 0.8; Bit\\u2013Cooperation Correlation\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-e9bded0633f9946d70a054b064ec1de6\": [{\"bit\": \"bit_0\", \"corr_with_coop\": 0.31608142051631294}, {\"bit\": \"bit_1\", \"corr_with_coop\": 0.3118265701814451}, {\"bit\": \"bit_2\", \"corr_with_coop\": -0.3040889787619574}, {\"bit\": \"bit_3\", \"corr_with_coop\": -0.30832920766746386}, {\"bit\": \"bit_4\", \"corr_with_coop\": -0.15075530001873966}, {\"bit\": \"bit_5\", \"corr_with_coop\": -0.15305577257339434}, {\"bit\": \"bit_6\", \"corr_with_coop\": 0.15510988629537784}, {\"bit\": \"bit_7\", \"corr_with_coop\": 0.14869775421647233}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = bits.apply(lambda col: col.corr(elites[\"mean_coop\"])).reset_index()\n",
    "corr.columns = [\"bit\", \"corr_with_coop\"]\n",
    "\n",
    "heat_corr = (\n",
    "    alt.Chart(corr)\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"bit:N\", title=\"Bit Position\"),\n",
    "        y=alt.Y(\"corr_with_coop:Q\", title=\"Correlation\"),\n",
    "        tooltip=[\"bit\",\"corr_with_coop\"],\n",
    "        color=alt.Color(\"corr_with_coop:Q\", scale=alt.Scale(scheme=\"blueorange\"))\n",
    "    )\n",
    "    .properties(title=f\"Base norm: {chosen_base_norm}; Gamma: {chosen_gamma}; Bitâ€“Cooperation Correlation\")\n",
    ")\n",
    "\n",
    "heat_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80b2cd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed details,\n",
       "  #altair-viz-d4ade63099e14ae6a16545fbc21c14a6.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d4ade63099e14ae6a16545fbc21c14a6\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-4276d876a4661acb91e1af80f69dbf77\"}, \"mark\": {\"type\": \"circle\", \"size\": 100}, \"encoding\": {\"color\": {\"field\": \"DNF_literals\", \"scale\": {\"scheme\": \"viridis\"}, \"title\": \"DNF Complexity\", \"type\": \"quantitative\"}, \"tooltip\": [{\"field\": \"8bit_vector\", \"type\": \"nominal\"}, {\"field\": \"DNF_literals\", \"type\": \"quantitative\"}, {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, {\"field\": \"mean_coop\", \"format\": \".4f\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Emotion_Leniency\", \"title\": \"Emotional Leniency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"scale\": {\"domain\": [0, 100]}, \"title\": \"Mean Cooperation\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-7d53f7e111883533d95293259bd3bbd8\"}, \"mark\": {\"type\": \"line\", \"color\": \"gray\", \"opacity\": 0.8, \"point\": true, \"size\": 2}, \"encoding\": {\"x\": {\"field\": \"Emotion_Leniency\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_coop\", \"type\": \"quantitative\"}}}], \"height\": 300, \"title\": \"Base Norm: Shunning; Gamma: 0.8, Social Norms (Top 10%) \\u2014 Poly Regression + Max-Per-Leniency Line\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-4276d876a4661acb91e1af80f69dbf77\": [{\"8bit_vector\": \"01010101\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 74.25256666666668}, {\"8bit_vector\": \"10101010\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 68.48956666666666}, {\"8bit_vector\": \"01000101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 72.85103333333333}, {\"8bit_vector\": \"01001001\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 9, \"mean_coop\": 71.765}, {\"8bit_vector\": \"01010001\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 70.01486666666666}, {\"8bit_vector\": \"10001010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 71.3493}, {\"8bit_vector\": \"10100010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 4, \"mean_coop\": 75.31400000000001}, {\"8bit_vector\": \"11010101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.33036666666666}, {\"8bit_vector\": \"11101010\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.137}, {\"8bit_vector\": \"01000001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 6, \"mean_coop\": 88.0087}, {\"8bit_vector\": \"01000111\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 77.18900000000001}, {\"8bit_vector\": \"10000010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 6, \"mean_coop\": 87.31146666666667}, {\"8bit_vector\": \"11000101\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 84.9773}, {\"8bit_vector\": \"11001001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 7, \"mean_coop\": 76.1965}, {\"8bit_vector\": \"11001010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 82.98060000000001}, {\"8bit_vector\": \"11010001\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 89.2706}, {\"8bit_vector\": \"11010111\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 5, \"mean_coop\": 79.96673333333334}, {\"8bit_vector\": \"11100010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 90.38993333333333}, {\"8bit_vector\": \"11101011\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 5, \"mean_coop\": 85.71173333333333}, {\"8bit_vector\": \"01000011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 84.90473333333333}, {\"8bit_vector\": \"10000011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 87.79356666666666}, {\"8bit_vector\": \"11000010\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 5, \"mean_coop\": 91.69476666666667}, {\"8bit_vector\": \"11000111\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 87.41186666666665}, {\"8bit_vector\": \"11001011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 90.80446666666667}, {\"8bit_vector\": \"11010011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 92.1654}, {\"8bit_vector\": \"11100011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 85.38473333333333}, {\"8bit_vector\": \"11000011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 4, \"mean_coop\": 92.6014}, {\"8bit_vector\": \"11110011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 2, \"mean_coop\": 82.64323333333333}], \"data-7d53f7e111883533d95293259bd3bbd8\": [{\"8bit_vector\": \"01010101\", \"Emotion_Leniency\": 0.0, \"DNF_literals\": 1, \"mean_coop\": 74.25256666666668}, {\"8bit_vector\": \"11010101\", \"Emotion_Leniency\": 0.25, \"DNF_literals\": 3, \"mean_coop\": 90.33036666666666}, {\"8bit_vector\": \"11100010\", \"Emotion_Leniency\": 0.5, \"DNF_literals\": 4, \"mean_coop\": 90.38993333333333}, {\"8bit_vector\": \"11010011\", \"Emotion_Leniency\": 0.75, \"DNF_literals\": 6, \"mean_coop\": 92.1654}, {\"8bit_vector\": \"11000011\", \"Emotion_Leniency\": 1.0, \"DNF_literals\": 4, \"mean_coop\": 92.6014}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================\n",
    "#   Scatterplot by Base Norm\n",
    "# =============================\n",
    "\n",
    "# 1. Choose base norm\n",
    "chosen_base_norm = \"Shunning\"\n",
    "chosen_gamma = 0.8\n",
    "\n",
    "# Filter relevant runs\n",
    "filtered = merged_df[merged_df[\"base_social_norm\"] == chosen_base_norm].copy()\n",
    "filtered = filtered[filtered.Z == 50]\n",
    "filtered = filtered[filtered.gens == 1000]\n",
    "filtered = filtered[filtered.gamma_center == chosen_gamma]\n",
    "\n",
    "# 2. Average all runs per emergent norm\n",
    "grouped = (\n",
    "    filtered.groupby([\"8bit_vector\", \"Emotion_Leniency\", \"DNF_literals\"], as_index=False)\n",
    "            .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# 3. Keep only the top 10% for each DNF complexity\n",
    "def top_10_percent(df):\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    cutoff = np.quantile(df[\"mean_coop\"], 0.9)\n",
    "    return df[df[\"mean_coop\"] >= cutoff]\n",
    "\n",
    "grouped_top = (\n",
    "    grouped.groupby(\"Emotion_Leniency\", group_keys=False)\n",
    "           .apply(top_10_percent)\n",
    ")\n",
    "\n",
    "# NEW: Highest value per DNF (one per group)\n",
    "top_per_dnf = (\n",
    "    grouped_top.loc[grouped_top.groupby(\"Emotion_Leniency\")[\"mean_coop\"].idxmax()]\n",
    ")\n",
    "\n",
    "# Scatter plot\n",
    "scatter = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .mark_circle(size=100)\n",
    "    .encode(\n",
    "        x=alt.X(\"Emotion_Leniency:Q\", title=\"Emotional Leniency\"),\n",
    "        y=alt.Y(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                scale=alt.Scale(domain=[0, 100])),\n",
    "        color=alt.Color(\"DNF_literals:Q\", title=\"DNF Complexity\",\n",
    "                        scale=alt.Scale(scheme=\"viridis\")),\n",
    "        tooltip=[\n",
    "            \"8bit_vector\",\n",
    "            \"DNF_literals\",\n",
    "            \"Emotion_Leniency\",\n",
    "            alt.Tooltip(\"mean_coop:Q\", format=\".4f\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Polynomial regression (degree 2)\n",
    "poly_reg = (\n",
    "    alt.Chart(grouped_top)\n",
    "    .transform_regression(\n",
    "        \"Emotion_Leniency\",\n",
    "        \"mean_coop\",\n",
    "        method=\"poly\"\n",
    "    )\n",
    "    .mark_line(size=2, color=\"orange\", opacity=0.5)\n",
    "    .encode(\n",
    "        x=\"Emotion_Leniency:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# NEW: Line connecting the top points\n",
    "topline = (\n",
    "    alt.Chart(top_per_dnf)\n",
    "    .mark_line(point=True, size=2, color=\"gray\", opacity=0.8)\n",
    "    .encode(\n",
    "        x=\"Emotion_Leniency:Q\",\n",
    "        y=\"mean_coop:Q\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine\n",
    "plot = (\n",
    "    (scatter + topline)\n",
    "    .properties(\n",
    "        width=500,\n",
    "        height=300,\n",
    "        title=f\"Base Norm: {chosen_base_norm}; Gamma: {chosen_gamma}, Social Norms (Top 10%) â€” Poly Regression + Max-Per-Leniency Line\"\n",
    "    )\n",
    ")\n",
    "\n",
    "plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffe88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf733f9",
   "metadata": {},
   "source": [
    "## Multiple Line Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6c403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick norm\n",
    "chosen_norm = \"SternJudging\"\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "norm_df[\"is_base\"] = norm_df[\"variant_id\"].str.endswith(\"_v1\")\n",
    "\n",
    "# If your results use a different name (e.g., \"gamma_gaussian_n\"),\n",
    "# rename it once so plots are consistent:\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Aggregate per variant & gamma, carry DNF info (constant per variant)\n",
    "agg_df = (\n",
    "    norm_df\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\", \"gamma_center\", \"is_base\"], as_index=False)\n",
    "    .agg(\n",
    "        avg_coop=(\"average_cooperation\", \"mean\"),\n",
    "        std_coop=(\"average_cooperation\", \"std\"),\n",
    "        DNF=(\"DNF\", \"first\")\n",
    "    )\n",
    "    .sort_values([\"variant_id\", \"gamma_center\"])\n",
    ")\n",
    "\n",
    "# Make a percent-friendly copy\n",
    "plot_df = agg_df.copy()\n",
    "\n",
    "# If avg_coop is in [0,1], convert to %; if already 0â€“100, keep as-is\n",
    "def to_percent(col):\n",
    "    arr = col.to_numpy(dtype=float)\n",
    "    # heuristic: if most values â‰¤ 1, treat as proportions\n",
    "    needs_scale = (np.nanmean(arr <= 1.0) > 0.5)\n",
    "    return arr * 100.0 if needs_scale else arr\n",
    "\n",
    "plot_df[\"avg_coop_percent\"] = to_percent(plot_df[\"avg_coop\"])\n",
    "plot_df[\"std_coop_percent\"] = to_percent(plot_df[\"std_coop\"])\n",
    "\n",
    "# Base lines (no selections; color by DNF_literals; dashed if base)\n",
    "line = alt.Chart(plot_df).mark_line().encode(\n",
    "    x=alt.X(\"gamma_center:Q\", title=\"Gamma value\"),\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            title=\"Average Cooperation (%)\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    color=alt.Color(\"Emotion_Leniency:O\",\n",
    "                    title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"bluepurple\")),\n",
    "    strokeDash=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value([5, 5]),    # dashed for base\n",
    "        alt.value([1, 0])     # solid otherwise\n",
    "    ),\n",
    "    strokeWidth=alt.condition(\n",
    "        alt.datum.is_base,\n",
    "        alt.value(8),\n",
    "        alt.value(2)\n",
    "    ),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant\"),\n",
    "        alt.Tooltip(\"gamma_center:Q\", title=\"Gamma\"),\n",
    "        alt.Tooltip(\"avg_coop_percent:Q\", title=\"Mean coop (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"std_coop_percent:Q\", title=\"Std (%)\", format=\".1f\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"is_base:N\", title=\"Base?\")\n",
    "    ],\n",
    "    detail=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "# Optional: end-of-line labels (still no interactivity)\n",
    "endpoints = (\n",
    "    plot_df.sort_values([\"variant_id\", \"gamma_center\"])\n",
    "           .groupby(\"variant_id\", as_index=False)\n",
    "           .tail(1)\n",
    ")\n",
    "\n",
    "labels = alt.Chart(endpoints).mark_text(\n",
    "    dx=5, align=\"left\", baseline=\"middle\"\n",
    ").encode(\n",
    "    x=\"gamma_center:Q\",\n",
    "    y=alt.Y(\"avg_coop_percent:Q\",\n",
    "            scale=alt.Scale(domain=[0, 100])),\n",
    "    text=\"variant_id:N\"\n",
    ")\n",
    "\n",
    "chart = (line + labels).properties(\n",
    "    width=700, height=420,\n",
    "    title=f\"Performance of {chosen_norm} Variants (color = Emotion Leniency; dashed = base)\"\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pivot: rows = variant_id, cols = gamma_center\n",
    "pivot_df = plot_df.pivot_table(\n",
    "    index=\"variant_id\",\n",
    "    columns=\"gamma_center\",\n",
    "    values=\"avg_coop_percent\",\n",
    "    aggfunc=\"mean\"   # though already averaged\n",
    ").reset_index()\n",
    "\n",
    "# Optional: rename gamma columns for clarity (e.g., \"gamma 0.0\")\n",
    "pivot_df = pivot_df.rename(\n",
    "    columns={g: f\"gamma {g}\" for g in pivot_df.columns if isinstance(g, (int, float))}\n",
    ")\n",
    "\n",
    "# Check result\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca4dca",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02112145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "chosen_norm = \"SternJudging\"\n",
    "\n",
    "# Filter to chosen norm\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Ensure consistent gamma column name\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# ---- STEP 1: average cooperation per variant (across runs) ----\n",
    "variant_avg = (\n",
    "    norm_df\n",
    "    .groupby([\"norm\", \"variant_id\", \"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"))\n",
    ")\n",
    "\n",
    "# ---- STEP 2: for each (Î³, DNF_literals), take the variant with the highest average ----\n",
    "variant_avg_sorted = variant_avg.sort_values(\"mean_coop\", ascending=False)\n",
    "agg = (\n",
    "    variant_avg_sorted\n",
    "    .groupby([\"gamma_center\", \"DNF_literals\"], as_index=False)\n",
    "    .agg(\n",
    "        max_mean_coop=(\"mean_coop\", \"max\"),\n",
    "        best_variant=(\"variant_id\", \"first\"),\n",
    "        n=(\"variant_id\", \"nunique\")\n",
    "    )\n",
    ")\n",
    "\n",
    "agg[\"DNF_literals\"] = agg[\"DNF_literals\"].astype(int)\n",
    "\n",
    "# Convert to percentage if needed\n",
    "if agg[\"max_mean_coop\"].max() <= 1:\n",
    "    agg[\"max_mean_coop\"] *= 100\n",
    "\n",
    "# ---- STEP 3: Visualization ----\n",
    "heat = alt.Chart(agg).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\",\n",
    "            sort=[f\"{x:.1f}\" for x in valid_gammas]),\n",
    "    y=alt.Y(\"DNF_literals:O\", title=\"DNF literals\", sort=\"descending\"),\n",
    "    color=alt.Color(\"max_mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"DNF_literals:O\", title=\"# literals\"),\n",
    "        alt.Tooltip(\"max_mean_coop:Q\", title=\"max mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"best_variant:N\", title=\"Best variant ID\"),\n",
    "        alt.Tooltip(\"n:Q\", title=\"# variants in bin\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=450, height=350,\n",
    "    title=f\"{chosen_norm} â€” Max *Mean* Cooperation by Î³ Ã— DNF Complexity\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb43276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "#chosen_base_norm = \"SternJudging\"    # 0) choose base social norm\n",
    "fixed_gamma = 1                   # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# For a runnable example, let's assume merged_df is loaded here (e.g., from a CSV)\n",
    "# For the purpose of adding the regression, we'll proceed assuming 'merged_df' exists.\n",
    "#df = merged_df[merged_df[\"norm\"] == chosen_base_norm].copy()\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# ensure average_cooperation is numeric\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "          runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) For every DNF complexity, choose the variant with maximal mean cooperation ===\n",
    "# use idxmax to get the variant row with the highest mean_coop\n",
    "idx = variant_avg.groupby(\"DNF_literals\")[\"mean_coop\"].idxmax()\n",
    "best_per_complexity = variant_avg.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# Optional: sort by complexity numeric ascending\n",
    "best_per_complexity[\"DNF_literals\"] = best_per_complexity[\"DNF_literals\"].astype(int)\n",
    "best_per_complexity = best_per_complexity.sort_values(\"DNF_literals\")\n",
    "\n",
    "# === ASSUMED best_per_complexity DATA STRUCTURE FOR REGRESSION ===\n",
    "# best_per_complexity = pd.DataFrame({\n",
    "#     'DNF_literals': [1, 2, 3, 4, 5],\n",
    "#     'mean_coop_pct': [50.0, 65.0, 75.0, 70.0, 80.0],\n",
    "#     'Emotion_Leniency': [0.1, 0.2, 0.3, 0.2, 0.4],\n",
    "#     'variant_id': ['v1', 'v2', 'v3', 'v4', 'v5'],\n",
    "#     'runs': [10, 10, 10, 10, 10]\n",
    "# })\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (max among variants per complexity) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Max mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(best_per_complexity).mark_circle(size=120).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    color=alt.Color(\"Emotion_Leniency:O\", title=\"Emotion Leniency\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\")),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"Best variant per complexity at Î³ = {fixed_gamma}\"\n",
    ")\n",
    "\n",
    "# === 5) Add Regression Line (Linear) - CORRECTED ===\n",
    "# We use transform_regression() to calculate the line\n",
    "# and then mark_line() to draw it.\n",
    "regression_line = alt.Chart(best_per_complexity).transform_regression(\n",
    "    'DNF_literals',        # The X variable\n",
    "    'mean_coop_pct',       # The Y variable\n",
    "    method='quad'        # Specify method (linear, poly, etc.)\n",
    ").mark_line(\n",
    "    color='red',           # Style the line\n",
    "    strokeDash=[5, 5]      # Make it dashed\n",
    ").encode(\n",
    "    x=alt.X('DNF_literals:Q'),  # Re-encode X for the line layer\n",
    "    y=alt.Y('mean_coop_pct:Q')  # Re-encode Y for the line layer\n",
    ")\n",
    "\n",
    "# Add text labels (optional) next to points showing variant short name\n",
    "labels = alt.Chart(best_per_complexity).mark_text(dx=7, dy=0, align=\"left\").encode(\n",
    "    x=x_encoding,  # Use the quantitative encoding\n",
    "    y=y_encoding,  # Use the quantitative encoding\n",
    "    text=alt.Text(\"variant_id:N\"),\n",
    ")\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line + Labels ===\n",
    "chart_with_regression = (chart + regression_line + labels).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b296a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Import statsmodels for potential more advanced regression or to ensure required dependencies are available\n",
    "# (though Altair's mark_regression handles the basic fit)\n",
    "# import statsmodels.formula.api as smf # Not strictly needed for Altair's basic regression\n",
    "\n",
    "# === Parameters ===\n",
    "# chosen_base_norm = \"SternJudging\"    # 0) No longer filtering by a single norm\n",
    "fixed_gamma = 0.8                      # 1) fix gamma value\n",
    "\n",
    "# === 0) Filter to chosen base norm ===\n",
    "# NOTE: merged_df is assumed to be defined and loaded before this code block runs\n",
    "# We use the full merged_df, as requested.\n",
    "df = merged_df.copy()\n",
    "\n",
    "# === ensure gamma column consistency & rounding ===\n",
    "if \"gamma_center\" not in df.columns and \"gamma_gaussian_n\" in df.columns:\n",
    "    df = df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "if \"gamma_center\" not in df.columns:\n",
    "    raise KeyError(\"No gamma column found ('gamma_center' or 'gamma_gaussian_n').\")\n",
    "\n",
    "# round to 1 decimal to avoid float noise and keep only exact bin values\n",
    "df[\"gamma_center\"] = pd.to_numeric(df[\"gamma_center\"], errors=\"coerce\").round(1)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "\n",
    "# filter rows to valid gammas first (drops messy intermediate values)\n",
    "df = df[df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "# === 1) Filter to the fixed gamma value ===\n",
    "df_gamma = df[np.isclose(df[\"gamma_center\"], fixed_gamma)].copy()\n",
    "if df_gamma.empty:\n",
    "    raise ValueError(f\"No rows found for gamma = {fixed_gamma}. Check rounding or available gamma values.\")\n",
    "\n",
    "# === 2) Compute mean cooperation per variant (averaging across runs) ===\n",
    "# We add \"norm\" to the groupby so we can distinguish them in the plot\n",
    "df_gamma[\"average_cooperation\"] = pd.to_numeric(df_gamma[\"average_cooperation\"], errors=\"coerce\")\n",
    "variant_avg = (\n",
    "    df_gamma\n",
    "    .groupby([\"norm\", \"variant_id\", \"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "    .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "         runs=(\"average_cooperation\", \"count\"))    # how many runs contributed\n",
    ")\n",
    "\n",
    "# convert to percent if values are proportions in [0,1]\n",
    "if not variant_avg.empty and variant_avg[\"mean_coop\"].max() <= 1.0:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"] * 100.0\n",
    "else:\n",
    "    variant_avg[\"mean_coop_pct\"] = variant_avg[\"mean_coop\"]\n",
    "\n",
    "# === 3) Use all averaged variants (no 'best of' filter) ===\n",
    "# We are SKIPPING the step of choosing the maximal per complexity.\n",
    "# We will plot all variants from variant_avg.\n",
    "\n",
    "# Optional: ensure DNF_literals is int and sort\n",
    "if not variant_avg.empty:\n",
    "    variant_avg[\"DNF_literals\"] = variant_avg[\"DNF_literals\"].astype(int)\n",
    "    variant_avg = variant_avg.sort_values(\"DNF_literals\")\n",
    "else:\n",
    "    print(f\"Warning: No data found after filtering for gamma = {fixed_gamma}. Chart will be empty.\")\n",
    "\n",
    "\n",
    "# === 4) Scatter plot: x = complexity, y = avg cooperation (plotting ALL variants) ===\n",
    "# We must use :Q (Quantitative) for the x-axis for the regression to work.\n",
    "x_encoding = alt.X(\"DNF_literals:Q\", title=\"DNF complexity (number of literals)\")\n",
    "y_encoding = alt.Y(\"mean_coop_pct:Q\", title=\"Mean cooperation (%)\",\n",
    "                   scale=alt.Scale(domain=[0, 100]))\n",
    "\n",
    "chart = alt.Chart(variant_avg).mark_circle(size=80, opacity=0.7).encode(\n",
    "    x=x_encoding,\n",
    "    y=y_encoding,\n",
    "    # Color by norm to distinguish the data points\n",
    "    color=alt.Color(\"norm:N\", title=\"Social Norm\"),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"norm:N\", title=\"Norm\"),\n",
    "        alt.Tooltip(\"DNF_literals:Q\", title=\"DNF literals\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Variant ID\"),\n",
    "        alt.Tooltip(\"mean_coop_pct:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"runs:Q\", title=\"# runs\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:Q\", title=\"Leniency\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=600, height=350,\n",
    "    title=f\"All Norms â€” All variants at Î³ = {fixed_gamma}\" # Updated title\n",
    ").interactive() # Add interactive zoom/pan\n",
    "\n",
    "# === 6) Combine the charts: Scatter + Regression Line ===\n",
    "# The 'labels' chart was removed as it would be unreadable\n",
    "chart_with_regression = (chart ).configure_title(fontSize=14)\n",
    "\n",
    "chart_with_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc67cc",
   "metadata": {},
   "source": [
    "# HEATMAPS\n",
    "## Emotion Leniency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0661296-2416-4720-9c4b-bb93a9fef8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_norm = \"SternJudging\"  # Example\n",
    "\n",
    "# === 1. Filter and unify gamma column name ===\n",
    "norm_df = merged_df[merged_df.norm == chosen_norm].copy()\n",
    "\n",
    "# Round Î³ and keep only clean bins (0.0, 0.1, ..., 1.0)\n",
    "valid_gammas = np.round(np.arange(0, 1.01, 0.1), 1)\n",
    "norm_df = norm_df[norm_df[\"gamma_center\"].isin(valid_gammas)]\n",
    "\n",
    "if \"gamma_center\" not in norm_df.columns and \"gamma_gaussian_n\" in norm_df.columns:\n",
    "    norm_df = norm_df.rename(columns={\"gamma_gaussian_n\": \"gamma_center\"})\n",
    "\n",
    "# Ensure numeric gamma\n",
    "norm_df[\"gamma_center\"] = pd.to_numeric(norm_df[\"gamma_center\"], errors=\"coerce\")\n",
    "\n",
    "# === 2. Compute mean cooperation per variant first ===\n",
    "variant_means = (\n",
    "    norm_df.groupby([\"variant_id\", \"gamma_center\", \"Emotion_Leniency\"], as_index=False)\n",
    "           .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "                sd_coop=(\"average_cooperation\", \"std\"),\n",
    "                n_runs=(\"average_cooperation\", \"count\"))\n",
    ")\n",
    "\n",
    "# Convert to % if needed\n",
    "if variant_means[\"mean_coop\"].max() <= 1:\n",
    "    variant_means[\"mean_coop\"] *= 100\n",
    "\n",
    "# === 3. For each (Î³, Leniency), find the variant with highest mean ===\n",
    "idx = variant_means.groupby([\"gamma_center\", \"Emotion_Leniency\"])[\"mean_coop\"].idxmax()\n",
    "max_variants = variant_means.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# === 4. Plot heatmap ===\n",
    "heat = alt.Chart(max_variants).mark_rect().encode(\n",
    "    x=alt.X(\"gamma_center:O\", title=\"Î³\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:O\", title=\"Emotion Leniency\", sort=\"descending\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Max mean cooperation (%)\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0, 100])),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"gamma_center:O\", title=\"Î³\"),\n",
    "        alt.Tooltip(\"Emotion_Leniency:O\", title=\"Leniency\"),\n",
    "        alt.Tooltip(\"variant_id:N\", title=\"Top Variant\"),\n",
    "        alt.Tooltip(\"mean_coop:Q\", title=\"Mean coop (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"sd_coop:Q\", title=\"Std (%)\", format=\".2f\"),\n",
    "        alt.Tooltip(\"n_runs:Q\", title=\"# runs\")\n",
    "    ]\n",
    ").properties(\n",
    "    width=400, height=350,\n",
    "    title=f\"{chosen_norm} â€” Maximal Cooperation by Î³ Ã— Emotion Leniency\"\n",
    ")\n",
    "\n",
    "heat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab7b5a-03a9-446c-a457-5e1a67ca7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick your norm and gamma value\n",
    "chosen_norm = \"SternJudging\"\n",
    "gamma_value = 0.5  # ðŸ”‘ change this\n",
    "\n",
    "# filter results for chosen norm and gamma\n",
    "subset = merged_df[(merged_df[\"norm\"] == chosen_norm) &\n",
    "                   (merged_df[\"gamma_center\"] == gamma_value)].copy()\n",
    "\n",
    "# aggregate cooperation by (DNF_literals, Leniency)\n",
    "agg = (\n",
    "    subset.groupby([\"DNF_literals\", \"Emotion_Leniency\"], as_index=False)\n",
    "          .agg(mean_coop=(\"average_cooperation\", \"mean\"),\n",
    "               std_coop=(\"average_cooperation\", \"std\"),\n",
    "               n=(\"variant_id\", \"nunique\"))\n",
    ")\n",
    "\n",
    "# --- Scatterplot ---\n",
    "chart = alt.Chart(agg).mark_circle(size=200).encode(\n",
    "    x=alt.X(\"DNF_literals:Q\", title=\"DNF complexity (# literals)\"),\n",
    "    y=alt.Y(\"Emotion_Leniency:Q\", title=\"Emotion Leniency\"),\n",
    "    color=alt.Color(\"mean_coop:Q\", title=\"Mean Cooperation\",\n",
    "                    scale=alt.Scale(scheme=\"viridis\", domain=[0,100])),\n",
    "    size=alt.Size(\"n:Q\", title=\"# Variants\"),\n",
    "    tooltip=[\n",
    "        \"DNF_literals:Q\",\n",
    "        \"Emotion_Leniency:Q\",\n",
    "        alt.Tooltip(\"mean_coop:Q\", format=\".2f\", title=\"Mean coop\"),\n",
    "        alt.Tooltip(\"std_coop:Q\", format=\".2f\", title=\"Std\"),\n",
    "        \"n:Q\"\n",
    "    ]\n",
    ").properties(\n",
    "    title=f\"{chosen_norm} â€” Cooperation by Complexity Ã— Leniency (Î³={gamma_value})\",\n",
    "    width=500, height=400\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315cd82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
